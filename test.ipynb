{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f82efbc",
   "metadata": {},
   "source": [
    "## Bankruptcy prediction using neural networks and other ML algorithms\n",
    "This jupyter notebook is a modified version of the project I did during the writing of my Master's thesis called 'Neural netwoks in financial institutions'. My aim was to create a banrkuptcy prediction model using a neural network and consequently compare it with other benchmark ML algorithms used for classification, such as logistic regression, random forests and gradient boosting machines. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02db389",
   "metadata": {},
   "source": [
    "The collected data [(seen here)](https://pubmed.ncbi.nlm.nih.gov/31463350/) has information about ~20 000 small and medium Slovak companies in the manufacture industry. The data holds information about 21 financial ratios for each company that have been calculated from public data, collected over three years before the evaluation period, giving us the final number of 63 predictors. The 64th column is the binary output variable, which indicates whether the given company filed for bankruptcy in the evaluation period."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862f148b",
   "metadata": {},
   "source": [
    "As is the common case with real world data, it is messy and needs some care before we can use it for training algorithms, especially neural networks. The main problems are outliers, missing values and different orders of magnitude of the predictors; therefore, the use of preprocessing steps such as winsorization, scaling and imputation was needed to clean the data before training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c99d3d6",
   "metadata": {},
   "source": [
    "## Setup \n",
    "First, we need to load the data and some modules we will use throughout the whole project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8806bd9a",
   "metadata": {
    "executionInfo": {
     "elapsed": 224,
     "status": "ok",
     "timestamp": 1646129757009,
     "user": {
      "displayName": "Michal Odler",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10321160972572366187"
     },
     "user_tz": -60
    },
    "id": "8806bd9a"
   },
   "outputs": [],
   "source": [
    "# Modules\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cb473d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data \n",
    "manu_test = pd.read_csv(r'data_manu_final.csv', sep = ';', decimal = ',')\n",
    "manu_test = manu_test.drop(columns = ['X'])\n",
    "manu = manu_test.reset_index(drop = True)\n",
    "# Split into output variable and predictors\n",
    "X = manu.drop(columns = ['bankrupt'])\n",
    "y = manu['bankrupt']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794b09e5",
   "metadata": {},
   "source": [
    "## Exploratory analysis \n",
    "EDA, or *exploratory data analysis*, is the first step of analysing data, as we need to take a thorough look at the quality of data we are dealing with. Our main concerns are NA values = missing data, so let us take a look at what proportion of values are missing in each of the financial ratios. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57fd32ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V55</th>\n",
       "      <th>V56</th>\n",
       "      <th>V57</th>\n",
       "      <th>V58</th>\n",
       "      <th>V59</th>\n",
       "      <th>V60</th>\n",
       "      <th>V61</th>\n",
       "      <th>V62</th>\n",
       "      <th>V63</th>\n",
       "      <th>bankrupt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.49</td>\n",
       "      <td>968.52</td>\n",
       "      <td>84.00</td>\n",
       "      <td>429.42</td>\n",
       "      <td>118.00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.36</td>\n",
       "      <td>5.57</td>\n",
       "      <td>57.56</td>\n",
       "      <td>10.59</td>\n",
       "      <td>0.62</td>\n",
       "      <td>9556.27</td>\n",
       "      <td>5.11</td>\n",
       "      <td>11.43</td>\n",
       "      <td>37.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.68</td>\n",
       "      <td>11.08</td>\n",
       "      <td>12.86</td>\n",
       "      <td>3.52</td>\n",
       "      <td>22.25</td>\n",
       "      <td>26.80</td>\n",
       "      <td>438.14</td>\n",
       "      <td>291.31</td>\n",
       "      <td>15.55</td>\n",
       "      <td>71.61</td>\n",
       "      <td>...</td>\n",
       "      <td>3.16</td>\n",
       "      <td>12.92</td>\n",
       "      <td>68.31</td>\n",
       "      <td>14.46</td>\n",
       "      <td>1.07</td>\n",
       "      <td>18127.50</td>\n",
       "      <td>6.56</td>\n",
       "      <td>6.25</td>\n",
       "      <td>29.41</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.46</td>\n",
       "      <td>17.93</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.12</td>\n",
       "      <td>1.12</td>\n",
       "      <td>1.12</td>\n",
       "      <td>39.70</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>8.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>3.58</td>\n",
       "      <td>9.42</td>\n",
       "      <td>72.03</td>\n",
       "      <td>32.39</td>\n",
       "      <td>1.36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.75</td>\n",
       "      <td>1.87</td>\n",
       "      <td>30.91</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36.70</td>\n",
       "      <td>55.67</td>\n",
       "      <td>15.58</td>\n",
       "      <td>4.98</td>\n",
       "      <td>6.91</td>\n",
       "      <td>6.91</td>\n",
       "      <td>154.49</td>\n",
       "      <td>27.95</td>\n",
       "      <td>14.46</td>\n",
       "      <td>0.05</td>\n",
       "      <td>...</td>\n",
       "      <td>5.04</td>\n",
       "      <td>58.06</td>\n",
       "      <td>80.15</td>\n",
       "      <td>15.67</td>\n",
       "      <td>0.64</td>\n",
       "      <td>22078.00</td>\n",
       "      <td>3.14</td>\n",
       "      <td>23.78</td>\n",
       "      <td>77.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.12</td>\n",
       "      <td>1.32</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.16</td>\n",
       "      <td>223.90</td>\n",
       "      <td>108.83</td>\n",
       "      <td>142.77</td>\n",
       "      <td>78.80</td>\n",
       "      <td>...</td>\n",
       "      <td>52.11</td>\n",
       "      <td>30.91</td>\n",
       "      <td>98.08</td>\n",
       "      <td>0.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7989.63</td>\n",
       "      <td>27.19</td>\n",
       "      <td>19.62</td>\n",
       "      <td>98.89</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      V1     V2     V3    V4     V5     V6      V7      V8      V9     V10  \\\n",
       "0   0.03   0.06   0.07  0.06   0.24   0.49  968.52   84.00  429.42  118.00   \n",
       "1  10.68  11.08  12.86  3.52  22.25  26.80  438.14  291.31   15.55   71.61   \n",
       "2   6.46  17.93   0.70  1.12   1.12   1.12   39.70   -0.03    8.33    0.00   \n",
       "3  36.70  55.67  15.58  4.98   6.91   6.91  154.49   27.95   14.46    0.05   \n",
       "4   0.12   1.32   0.07  0.18   0.75   1.16  223.90  108.83  142.77   78.80   \n",
       "\n",
       "   ...    V55    V56    V57    V58   V59       V60    V61    V62    V63  \\\n",
       "0  ...   2.36   5.57  57.56  10.59  0.62   9556.27   5.11  11.43  37.78   \n",
       "1  ...   3.16  12.92  68.31  14.46  1.07  18127.50   6.56   6.25  29.41   \n",
       "2  ...   3.58   9.42  72.03  32.39  1.36       NaN   7.75   1.87  30.91   \n",
       "3  ...   5.04  58.06  80.15  15.67  0.64  22078.00   3.14  23.78  77.75   \n",
       "4  ...  52.11  30.91  98.08   0.03   NaN   7989.63  27.19  19.62  98.89   \n",
       "\n",
       "   bankrupt  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manu.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2680972e",
   "metadata": {
    "id": "251d4a7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. 0, Missing Values: 106 (0.5%)\n",
      ".. 1, Missing Values: 106 (0.5%)\n",
      ".. 2, Missing Values: 838 (4.3%)\n",
      ".. 3, Missing Values: 558 (2.9%)\n",
      ".. 4, Missing Values: 530 (2.7%)\n",
      ".. 5, Missing Values: 543 (2.8%)\n",
      ".. 6, Missing Values: 780 (4.0%)\n",
      ".. 7, Missing Values: 1427 (7.3%)\n",
      ".. 8, Missing Values: 887 (4.6%)\n",
      ".. 9, Missing Values: 4104 (21.1%)\n",
      ".. 10, Missing Values: 425 (2.2%)\n",
      ".. 11, Missing Values: 422 (2.2%)\n",
      ".. 12, Missing Values: 106 (0.5%)\n",
      ".. 13, Missing Values: 106 (0.5%)\n",
      ".. 14, Missing Values: 133 (0.7%)\n",
      ".. 15, Missing Values: 521 (2.7%)\n",
      ".. 16, Missing Values: 3491 (17.9%)\n",
      ".. 17, Missing Values: 9146 (46.9%)\n",
      ".. 18, Missing Values: 262 (1.3%)\n",
      ".. 19, Missing Values: 764 (3.9%)\n",
      ".. 20, Missing Values: 389 (2.0%)\n",
      ".. 21, Missing Values: 123 (0.6%)\n",
      ".. 22, Missing Values: 127 (0.7%)\n",
      ".. 23, Missing Values: 1277 (6.6%)\n",
      ".. 24, Missing Values: 326 (1.7%)\n",
      ".. 25, Missing Values: 295 (1.5%)\n",
      ".. 26, Missing Values: 301 (1.5%)\n",
      ".. 27, Missing Values: 482 (2.5%)\n",
      ".. 28, Missing Values: 1042 (5.3%)\n",
      ".. 29, Missing Values: 529 (2.7%)\n",
      ".. 30, Missing Values: 4038 (20.7%)\n",
      ".. 31, Missing Values: 257 (1.3%)\n",
      ".. 32, Missing Values: 257 (1.3%)\n",
      ".. 33, Missing Values: 127 (0.7%)\n",
      ".. 34, Missing Values: 123 (0.6%)\n",
      ".. 35, Missing Values: 157 (0.8%)\n",
      ".. 36, Missing Values: 310 (1.6%)\n",
      ".. 37, Missing Values: 3018 (15.5%)\n",
      ".. 38, Missing Values: 9968 (51.2%)\n",
      ".. 39, Missing Values: 176 (0.9%)\n",
      ".. 40, Missing Values: 480 (2.5%)\n",
      ".. 41, Missing Values: 313 (1.6%)\n",
      ".. 42, Missing Values: 126 (0.6%)\n",
      ".. 43, Missing Values: 126 (0.6%)\n",
      ".. 44, Missing Values: 1712 (8.8%)\n",
      ".. 45, Missing Values: 250 (1.3%)\n",
      ".. 46, Missing Values: 218 (1.1%)\n",
      ".. 47, Missing Values: 224 (1.1%)\n",
      ".. 48, Missing Values: 347 (1.8%)\n",
      ".. 49, Missing Values: 874 (4.5%)\n",
      ".. 50, Missing Values: 382 (2.0%)\n",
      ".. 51, Missing Values: 4181 (21.5%)\n",
      ".. 52, Missing Values: 200 (1.0%)\n",
      ".. 53, Missing Values: 196 (1.0%)\n",
      ".. 54, Missing Values: 126 (0.6%)\n",
      ".. 55, Missing Values: 126 (0.6%)\n",
      ".. 56, Missing Values: 167 (0.9%)\n",
      ".. 57, Missing Values: 246 (1.3%)\n",
      ".. 58, Missing Values: 2792 (14.3%)\n",
      ".. 59, Missing Values: 11214 (57.5%)\n",
      ".. 60, Missing Values: 167 (0.9%)\n",
      ".. 61, Missing Values: 364 (1.9%)\n",
      ".. 62, Missing Values: 244 (1.3%)\n",
      ".. 63, Missing Values: 0 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "# Proportions of missing values\n",
    "miss = []\n",
    "for i in range(manu.shape[1]):\n",
    "    pocet = manu.iloc[:, i].isna().sum()\n",
    "    pct = 100 * pocet / manu.shape[0]\n",
    "    miss.append(pct)\n",
    "    print('.. %d, Missing Values: %d (%.1f%%)' % (i, pocet, pct))\n",
    "miss = miss[0:63]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fad7f0cc",
   "metadata": {
    "id": "XkOIcOvMdrEB",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 8000x8000 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "plt.figure(figsize = (20, 20), dpi = 400)\n",
    "sns.set(font_scale = 1.4)\n",
    "miss = np.array(miss)\n",
    "miss.shape = [3, 21]\n",
    "df = pd.DataFrame(miss, columns = np.arange(21) + 1, index = np.arange(3) + 1)\n",
    "sns.heatmap(df, vmin = 0, vmax = 100, cmap = \"YlGnBu\", square = True,  \n",
    "            cbar_kws={\"orientation\": \"horizontal\"}, linewidths = 0.2, linecolor = 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1dcce1d",
   "metadata": {},
   "source": [
    "As we can see, the most of the columns were missing up to 5% of values, some of them reached up to 20% and three of the columns had a much higher number of NA values. Let us identify the columns that had at least 30% of values missing: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a25aa5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V18 missing data:  46.9 %.\n",
      "V39 missing data:  51.2 %.\n",
      "V60 missing data:  57.5 %.\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(X.shape[1]):\n",
    "    if X.iloc[:,i].isna().sum() / X.shape[0] >= 0.3:\n",
    "        print('{} missing data:  {:.1f} %.'.format(X.columns[i], X.iloc[:,i].isna().sum() / X.shape[0] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea45fa12",
   "metadata": {},
   "source": [
    "These columns correspond to the same financial ratio, collected during the three consecutive years. As the proportions of missing data are too high, I decided to completely omit these predictors in my analysis and algorithm training. I created some transformers that will help us with selecting our wanted columns and winsorization in a proper machine learning pipeline, so I will load them now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03378fe4",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1646129786147,
     "user": {
      "displayName": "Michal Odler",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10321160972572366187"
     },
     "user_tz": -60
    },
    "id": "oWMMVZamIs9U"
   },
   "outputs": [],
   "source": [
    "# Winsorization function\n",
    "def winsor_dat(df, alpha):\n",
    "    q_low = df.quantile(alpha)\n",
    "    q_hi = df.quantile(1 - alpha)\n",
    "    out_low = (df < q_low)\n",
    "    out_hi = (df > q_hi)\n",
    "    df = df.mask(out_low, q_low, axis = 1)\n",
    "    df = df.mask(out_hi, q_hi, axis = 1)\n",
    "    return df\n",
    "\n",
    "# Winsorization transformer\n",
    "def winsor_mask(df, qlo, qhi):\n",
    "    out_low = (df < qlo)\n",
    "    out_hi = (df > qhi)\n",
    "    df = df.mask(out_low, qlo, axis = 1)\n",
    "    df = df.mask(out_hi, qhi, axis = 1)\n",
    "    return df\n",
    "    \n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import TransformerMixin\n",
    "class WinsorTrans(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, alpha = 0.05):\n",
    "        # Initialization\n",
    "        self.alpha = alpha\n",
    "        print('\\n > init() called.\\n')\n",
    "    \n",
    "    def fit(self, X, y = None):\n",
    "        # Fit lower and upper quantiles, as transformer attributes\n",
    "        self.qlow = X.quantile(self.alpha)\n",
    "        self.qhi = X.quantile(1 - self.alpha)\n",
    "        return self \n",
    "    \n",
    "    def transform(self, X, y = None):\n",
    "        X_cop = X.copy()\n",
    "        X_cop = winsor_mask(X_cop, self.qlow, self.qhi)\n",
    "        return X_cop\n",
    "    \n",
    "# Column selection transformer\n",
    "class SelectCols(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cutoff = 0.3):\n",
    "        # Initialization\n",
    "        print('\\n > init() called.\\n')\n",
    "        self.cutoff = cutoff\n",
    "        \n",
    "    def fit(self, X, y = None):\n",
    "        # Fit = get indices of columns to be deleted\n",
    "        drops = []\n",
    "        for i in range(X.shape[1]):\n",
    "            rate = X.iloc[:, i].isna().sum() / manu.shape[0]\n",
    "            if rate >= self.cutoff: drops.append(i)\n",
    "        self.drop = X.columns[drops]\n",
    "        self.numcols = len(drops)\n",
    "        return self \n",
    "\n",
    "    def transform(self, X, y = None):\n",
    "        X_cop = X.copy()\n",
    "        X_cop = X_cop.drop(self.drop, axis = 1)\n",
    "        return X_cop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46ea22a",
   "metadata": {},
   "source": [
    "Next up, let's have a look at some boxplots: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ac86bed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(10, 5))\n",
    "axe = ax.ravel()\n",
    "manu.iloc[:,10].plot.box(ax=axe[0])\n",
    "manu.iloc[:,20].plot.box(ax=axe[1])\n",
    "manu.iloc[:,30].plot.box(ax=axe[2])\n",
    "manu.iloc[:,40].plot.box(ax=axe[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf14b9d2",
   "metadata": {},
   "source": [
    "The boxplots indicate a large number of outliers that we will need to deal with during the preprocessing phase. Another useful information is the correlation among the financial ratios. The correlation among predictiors in one given year looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63f270bb",
   "metadata": {
    "id": "EY4w9FJxud-l"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " > init() called.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 6000x6000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Correlation matrix\n",
    "wins = WinsorTrans(alpha = 0.05)\n",
    "X_winsor = wins.fit_transform(X)\n",
    "plt.figure(figsize = (15, 15), dpi = 400)\n",
    "sns.set(font_scale = 1)\n",
    "cor1 = X_winsor.iloc[:, np.arange(21)].corr()\n",
    "sns.heatmap(cor1, vmin = -1, vmax = 1, square = True,  linewidths = 0.2, linecolor = 'white', cmap = 'coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21587c6",
   "metadata": {},
   "source": [
    "As expected, some of the financial ratios are highly correlated, either positively or negaitvely. Although this is an interesting information, we will fortunately not need to deal with the correlation, as neural networks can create their own (possibly uncorrelated) transformations of the data and other ML algorithms, such as those based on decision trees, are also robust to highly correlated data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d6b22e",
   "metadata": {},
   "source": [
    "Next up, we can execute the main split into training and testing data. I opted to do a 80%/20% train/test split. Another problem is the large discrepancy between the negative class (financially healthy companies) and the positive class (the companies that filed for bankruptcy): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0f32cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive class: 19386 observations, (99.49% of data)\n",
      "Negative class: 100 observations, (0.51% of data)\n"
     ]
    }
   ],
   "source": [
    "a = manu.iloc[:,63].value_counts()\n",
    "print('Positive class: %d observations, (%.2f%% of data)' % (a[0], 100 *  a[0] / (a.sum())))\n",
    "print('Negative class: %d observations, (%.2f%% of data)' % (a[1], 100 *  a[1] / (a.sum())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4725820b",
   "metadata": {},
   "source": [
    "Since this is a highly imbalanced dataset, we need to stratify the train/test split by the output variable. We will also need to deal with the imbalance during training, by either undersampling the negative class or oversampling the positive class (dupliacation or SMOTE). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ffbc7e03",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 204,
     "status": "ok",
     "timestamp": 1646129812470,
     "user": {
      "displayName": "Michal Odler",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10321160972572366187"
     },
     "user_tz": -60
    },
    "id": "ffbc7e03",
    "outputId": "592f75e9-77fa-4274-fda4-099e70260033",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " > init() called.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(15588,), (3898,)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select columns & Train test split \n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "col_selector = SelectCols(cutoff = 0.3)\n",
    "X = col_selector.fit_transform(X)\n",
    "X_tr, X_ts, y_tr, y_ts = tts(X, y, \n",
    "                             test_size = 0.2, \n",
    "                             stratify = y, \n",
    "                             random_state = 10)\n",
    "[y_tr.shape, y_ts.shape] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926195da",
   "metadata": {},
   "source": [
    "After the split, I decided to divide the hyperparameter optimalization for my neural network into 2 steps: The preprocessing hyperparameters, and the neural network hyperparameters. Ideally, we would do this in one go, but since I will be using grid search cross-validation to find the optimal values of these hyperparameters, such process would take too much time. I therefore assumed that the optimal data cleaning process is independent from the neural network design process. \n",
    "\n",
    "In the next cell, I designed the metric by which I will evaluate the quality of my classifiers. I opted for the partial AUC criterion; for brevity, I will not describe the topic of evaluating binary classifiers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4819d8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing hyperparameter tuning\n",
    "# List for pAUC metric\n",
    "first = list(range(31))\n",
    "xseq = [x / 100 for x in first] # max_fpr = (0, 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366a772c",
   "metadata": {},
   "source": [
    "For the first step (optimalization of preprocessing hyperparameters), I designed a simple neural network with one hidden layer with 20 neurons. I chose the relu activation function for hidden neurons and otherwise the default setting for a binary classifier neural net. The net is also regularized by the dropout method. \n",
    "\n",
    "I want to add the neural net at the end of my machine learning pipeline, therefore I created this *create_net()* function which creates a Keras model, which is then wrapped in a KerasClassifier wrapper. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "194ecd0e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2365,
     "status": "ok",
     "timestamp": 1645972394790,
     "user": {
      "displayName": "Michal Odler",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10321160972572366187"
     },
     "user_tz": -60
    },
    "id": "194ecd0e",
    "outputId": "19d89f39-b0d8-4ac1-8bf7-f15b9e512277"
   },
   "outputs": [],
   "source": [
    "# Neural network creator function \n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.metrics import AUC\n",
    "def create_net():\n",
    "    net = Sequential()\n",
    "    net.add(Dropout(0.3, input_shape = (60, )))\n",
    "    net.add(Dense(20, activation = 'relu'))\n",
    "    net.add(Dropout(0.5))\n",
    "    net.add(Dense(1, activation = 'sigmoid'))\n",
    "    net.compile(loss = 'binary_crossentropy', \n",
    "                optimizer = 'adam', \n",
    "                metrics = AUC(thresholds = xseq))\n",
    "    return net\n",
    "keras_est = KerasClassifier(build_fn = create_net, \n",
    "                            verbose = 1, epochs = 90, batch_size = 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b1c844",
   "metadata": {},
   "source": [
    "In the next step I created the grid of possible hyperparameters setting for preprocessing. The individual steps are then ordered in the *imbpipeline*, which is a Pipeline imported from the *imbalanced-learn* module, which allows me to add undersampling and oversampling to the pipe. This is essential for working with heavily imbalanced datasets, as I am allowing the pipeline to find the best combination of oversampling the positive class (via SMOTE or random oversampling) and undersampling the negative class (via random undersampling, although other techniques can be used).\n",
    "\n",
    "The imputation will be done by the k-nearest neighbors algorithm, as imputation by the mean showed poor results in previous runs. As described earlier, winsorization will be used to deal with the outliers. Scaling of the data will be done by min-max scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ad3df48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from imblearn.pipeline import Pipeline as imbpipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.under_sampling import OneSidedSelection\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "preproc_grid = [{\n",
    "    'outs__alpha' : [0.02, 0.05, 0.1],\n",
    "    'scaler' : [MinMaxScaler()],\n",
    "    'imputer' : [KNNImputer()],\n",
    "    'imputer__n_neighbors' : [3, 5, 7],\n",
    "    'us' : [RandomUnderSampler()],\n",
    "    'os' : [RandomOverSampler(), SMOTE()],\n",
    "    'us__sampling_strategy' :  [0.01, 0.02, 0.05],\n",
    "    'os__sampling_strategy' : [0.75, 1],\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d85c2fd6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 210,
     "status": "ok",
     "timestamp": 1645712482991,
     "user": {
      "displayName": "Michal Odler",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10321160972572366187"
     },
     "user_tz": -60
    },
    "id": "d85c2fd6",
    "outputId": "7863e44f-166a-45fb-8da2-42589f44b5f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " > init() called.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing pipeline\n",
    "pp = imbpipeline(steps = [['outs', WinsorTrans()], \n",
    "                          ['scaler', MinMaxScaler()],\n",
    "                          ['imputer', KNNImputer()], \n",
    "                          ['us', RandomUnderSampler()],\n",
    "                          ['os', SMOTE()], \n",
    "                          ['net', keras_est]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0083a86e",
   "metadata": {},
   "source": [
    "After our pipline with its grid has been defined, we can continue to use the *GridSearchCV* function that will repeatedly train the predefined neural net with various hyperparameter settings and test its quality of predictions via cross-validation. This took a very long time (over 15-20 hours if I remember correctly), so it is important to save the .csv file that contains the results of our grid search cross-validaiton, as well as the final model trained on the whole training set.\n",
    "\n",
    "Since this is just a notebook example of my project and I already have all my results saved, I will not run any code that would either cause training new models to begin or try to save these models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3c452215",
   "metadata": {
    "id": "3c452215"
   },
   "outputs": [],
   "source": [
    "# Grid search CV for preprocessing hyperparameters\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, roc_auc_score\n",
    "part_auc = make_scorer(roc_auc_score, max_fpr = 0.3) # define new scoring metric \n",
    "grid_pre = GridSearchCV(estimator = pp, verbose = 4, scoring = part_auc, param_grid = preproc_grid, cv = 4,\n",
    "                       return_train_score = True)\n",
    "#grid_pre.fit(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec793bd",
   "metadata": {},
   "source": [
    "The reason why we added all the preprocessing steps into a pipeline rather than conducted the tranformation before training, is to avoid data leakage. Data leakage is a rather complex problem to mathematically describe and therefore I will not get into details. Basically, we need to execute the same transformation on the training sets as on the validation sets, otherwise we would get (optimistically) skewed results of our final classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ca9f88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(grid_pre.cv_results_).to_csv('preprocess_end.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "11c968f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model \n",
    "#preprocess_mod = grid_pre.best_estimator_.steps[5][1].model.to_json()\n",
    "#open('preprocess_net_konec', 'w').write(preprocess_mod)\n",
    "# And its weights \n",
    "#grid_pre.best_estimator_.steps[5][1].model.save_weights('preprocess_net_konec_weights.h5', overwrite = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f877d4bb",
   "metadata": {},
   "source": [
    "We can now move up to the second stage; setting the hyperparameters of the actual neural network. We have saved the best results for our preprocessing steps and we will 'hardcode' them into our next pipeline. I defined a new function to create a general neural net with various number of hidden layers, hidden neurons, various choice of activation funciton, regularization etc.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8cbf84b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network creator function with dropout/L1/L2 regularizations \n",
    "from keras import regularizers \n",
    "def create_net_reg(layer_sizes = [60], optimizer = 'adam',\n",
    "                   activ_hidden = 'relu', lamb = 0.01,\n",
    "                   typ = 'drop', dropout_input = 0.3, \n",
    "                   dropout_dense = 0.5):\n",
    "    net = Sequential()\n",
    "    if typ == 'l2': \n",
    "        reg = regularizers.l2(lamb)\n",
    "        net.add(Dense(layer_sizes[0], input_dim = 60, \n",
    "                      activation = activ_hidden, \n",
    "                      kernel_regularizer = reg,\n",
    "                      bias_regularizer = reg))\n",
    "        for layer_size in layer_sizes[1:]:\n",
    "            net.add(Dense(layer_size, activation = activ_hidden, \n",
    "                          kernel_regularizer = reg,\n",
    "                          bias_regularizer = reg))\n",
    "    if typ == 'l1': \n",
    "        reg = regularizers.l1(lamb)\n",
    "        net.add(Dense(layer_sizes[0], input_dim = 60, \n",
    "                      activation = activ_hidden,\n",
    "                      kernel_regularizer = reg,\n",
    "                      bias_regularizer = reg))\n",
    "        for layer_size in layer_sizes[1:]:\n",
    "            net.add(Dense(layer_size, activation = activ_hidden,\n",
    "                          kernel_regularizer = reg,\n",
    "                          bias_regularizer = reg))\n",
    "    if typ == 'drop':\n",
    "        net.add(Dropout(dropout_input, input_shape = (60, )))\n",
    "        for layer_size in layer_sizes:\n",
    "            net.add(Dense(layer_size, activation = activ_hidden))\n",
    "            net.add(Dropout(dropout_dense))\n",
    "    net.add(Dense(1, activation = 'sigmoid'))\n",
    "    net.compile(loss = 'binary_crossentropy', optimizer = optimizer, metrics = AUC(thresholds = xseq))\n",
    "    return net\n",
    "keras_est_reg = KerasClassifier(build_fn = create_net_reg, verbose = 1, epochs = 60, batch_size = 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2fc243",
   "metadata": {},
   "source": [
    "The process is very similar to the previous case, except we will define the exact preprocessing steps and define a new grid of possible hyperparameter combinations for the actual neural network. The *RandomizedSearchCV* function is used to find the best combinations of hyperparameters by evaluating the models on the validation datasets via cross-validation. The only differnce from *GridSearchCV* is our ability to choose the number of hyperparameter combinations we will choose. I settled for 200 combinations, which already comes to training 800 neural nets combined with the rather lengthy preprocessing steps to avoid data leakage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8zi4h4vVqNcp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 908,
     "status": "ok",
     "timestamp": 1646129833393,
     "user": {
      "displayName": "Michal Odler",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10321160972572366187"
     },
     "user_tz": -60
    },
    "id": "8zi4h4vVqNcp",
    "outputId": "4e668b5d-69ed-4161-a427-cc4a3fe914f2",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " > init() called.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define pipelines\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.pipeline import Pipeline as imbpipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.under_sampling import OneSidedSelection\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "net = imbpipeline(steps = [['outs', WinsorTrans(alpha = 0.05)], \n",
    "                           ['scaler', MinMaxScaler()],\n",
    "                           ['imputer', KNNImputer(n_neighbors = 5)], \n",
    "                           ['us', RandomUnderSampler(sampling_strategy = 0.02)], \n",
    "                           ['os', SMOTE(sampling_strategy = 0.75)], \n",
    "                           ['net', keras_est_reg]])\n",
    "fin_grid = [\n",
    "    {\n",
    "    'net__layer_sizes' : [[20], [40], [60], [30, 10], \n",
    "                          [50, 30], [20, 10, 5]],\n",
    "    'net__optimizer' : ['adam', 'rmsprop'], \n",
    "    'net__activ_hidden' : ['relu', 'tanh'],\n",
    "    'net__lamb' : [0.01, 0.001, 0.0001], \n",
    "    'net__typ' : ['l2']\n",
    "},\n",
    "    {\n",
    "    'net__layer_sizes' : [[20], [40], [60], [30, 10], \n",
    "                          [50, 30], [20, 10, 5]],\n",
    "    'net__optimizer' : ['adam', 'rmsprop'], \n",
    "    'net__activ_hidden' : ['relu', 'tanh'],\n",
    "    'net__dropout_input' : [0.1, 0.3, 0.5],\n",
    "    'net__dropout_dense' : [0.3, 0.5, 0.7],\n",
    "    'net__typ' : ['drop']  \n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ce6c88",
   "metadata": {},
   "source": [
    "This learning process also takes a really long time (over 24 hours), so it is important that I saved the results after executing these blocks of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "29cbef1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, roc_auc_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "part_auc = make_scorer(roc_auc_score, max_fpr = 0.3)\n",
    "grid_net = RandomizedSearchCV(estimator = net, verbose = 4, scoring = part_auc, param_distributions = fin_grid, cv = 4,\n",
    "                              n_iter = 200, return_train_score = True)\n",
    "#grid_net.fit(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bdab4c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results\n",
    "#pd.DataFrame(grid_final.cv_results_).to_csv('net_konec.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5fa92120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model \n",
    "#final_mod = grid_final.best_estimator_.steps[5][1].model.to_json()\n",
    "#open('konec_net3.json', 'w').write(final_mod)\n",
    "# And its weights \n",
    "#grid_final.best_estimator_.steps[5][1].model.save_weights('konec_net_weights3.h5', overwrite = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708f58ec",
   "metadata": {},
   "source": [
    "Since I already trained and saved the best neural network model as well as the other ML algorithms used (logistic regression, random forest and gradient boosting machine), we can simply load the models and compare them. The process of optimalization for the other algortihms was very similar that of the neural network and the code blocks are shown lower in the project.\n",
    "\n",
    "Let us move on and finally compare the models; I will load the already trained models and their predictions. Since the neural network is loaded in a different format, I need to do the preprocessing step manually on the test dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e487b097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final evalutaion of benchmark models/neural net, loading finished models\n",
    "import joblib \n",
    "rf = joblib.load('rf_upraveny.pkl')\n",
    "logreg = joblib.load('logreg_konec.pkl')\n",
    "gbm = joblib.load('gbm_konec.pkl')\n",
    "rf_probs = rf.predict_proba(X_ts)\n",
    "logreg_probs = logreg.predict_proba(X_ts)\n",
    "gbm_probs = gbm.predict_proba(X_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cbd904cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " > init() called.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Final evaluaiton, ANN\n",
    "from sklearn.pipeline import Pipeline\n",
    "from keras.models import model_from_json\n",
    "ann = model_from_json(open('konec_net3.json').read())\n",
    "ann.load_weights('konec_net_weights3.h5')\n",
    "\n",
    "# Create pipeline again \n",
    "preprocess = Pipeline(steps = [['outs', WinsorTrans(alpha = 0.05)], \n",
    "                               ['scaler', MinMaxScaler()],\n",
    "                               ['imputer', KNNImputer(n_neighbors = 5)]])\n",
    "preprocess.fit(X_tr)\n",
    "X_ts_pp = preprocess.transform(X_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8c0f5ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN predictions\n",
    "ann_probs = ann.predict(X_ts_pp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12da6308",
   "metadata": {},
   "source": [
    "The best and robust way to compare several binary classifiers is arguably the Receiver operating characteristic (ROC curve). This [curve](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) plots the true positive rate (TPR) agianst the false positive rate (FPR) for various cut-off values of a binary classifier. Remember, the output of our algorithm is not the predicted category; the output is merely a *probability* our model thinks that the given observation belongs to the positive class. It is then up to the analyst to choose the cut-off value to suit the needs of a problem we are trying to solve by training these machine learning algorithms. Depending on the nature of our problem, a type I error (false positive) might have way worse implications in real life than a type II error (false negative), or vice versa. \n",
    "\n",
    "The ROC curve always starts in the origin and ends in the (1,1) point. The better the classifier, the closer its ROC curve is to the upper left corner (or (0, 1) point), which implies that the classifier is able to predict all observations in the test set correcly, for some cut-off value. In real life, it is very rare to encounter data for which a perfect classifer can be created. The *Area Under Curve* (AUC) is therefore used to compare several models by a single metric. This value between 0 and 1 literally means the area under the ROC curve. A model that randomly guesses the category of observations will have AUC around 0.5 and models close to 1 are those that are very good at predicting the correct category. Hence, the higher the AUC, the more precise our model is. \n",
    "\n",
    "This is very important especially in our case, as we are dealing with a highly imbalanced dataset. Some simpler metrics, such as accuracy, are going to be misleading, as a pseudomodel which predicts only negative class for all observations will achieve about 99.5% accuracy, which may seem great, while in reality the model is completely useless.  \n",
    "\n",
    "In this project, I used the *partial* AUC metric, which uses a standardized area under a part of the ROC curve. For example, I looked at the curve at the parts where false positive rate was less than 30%, as I am less interested in how the models performed with such a high FPR. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "21e5b929",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'TPR')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1080 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ROC curve\n",
    "import sklearn.metrics as metrics\n",
    "f = plt.figure()\n",
    "plt.rcParams[\"figure.figsize\"] = (20,15)\n",
    "fpr_rf, tpr_rf, threshold_rf = metrics.roc_curve(y_ts, rf_probs[:,1])\n",
    "fpr_logreg, tpr_logreg, threshold_logreg = metrics.roc_curve(y_ts, logreg_probs[:,1])\n",
    "fpr_gbm, tpr_gbm, threshold_gbm = metrics.roc_curve(y_ts, gbm_probs[:,1])\n",
    "fpr_ann, tpr_ann, threshold_ann = metrics.roc_curve(y_ts, ann_probs)\n",
    "roc_auc_rf = metrics.roc_auc_score(y_ts, rf_probs[:,1], max_fpr = 0.3)\n",
    "roc_auc_logreg = metrics.roc_auc_score(y_ts, logreg_probs[:,1], max_fpr = 0.3)\n",
    "roc_auc_gbm = metrics.roc_auc_score(y_ts, gbm_probs[:,1], max_fpr = 0.3)\n",
    "roc_auc_ann = metrics.roc_auc_score(y_ts, ann_probs, max_fpr = 0.3)\n",
    "plt.plot(fpr_rf, tpr_rf, label = 'RF: pAUC = %0.4f' % roc_auc_rf, color = 'blue')\n",
    "plt.plot(fpr_logreg, tpr_logreg, label = 'LogReg: pAUC = %0.4f' % roc_auc_logreg, color = 'red')\n",
    "plt.plot(fpr_gbm, tpr_gbm, label = 'GBM: pAUC = %0.4f' % roc_auc_gbm, color = 'gold')\n",
    "plt.plot(fpr_ann, tpr_ann, label = 'ANN: pAUC = %0.4f' % roc_auc_ann, color = 'green')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc = 'lower right', prop={'size': 15})\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58da383",
   "metadata": {},
   "source": [
    "We may take a look at the pAUC/AUC scores our final models achieved on the test data. The partial AUC was calculated on the part of the ROC curve where the false positive rate was less than 30%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f152eb22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network pAUC on test data: 0.84848.\n",
      "Random forest pAUC on test data: 0.83635.\n",
      "Logistic regression pAUC on test data: 0.80422.\n",
      "Gradient boosting machine pAUC on test data: 0.86884.\n"
     ]
    }
   ],
   "source": [
    "# pAUC, test data\n",
    "print('Neural network pAUC on test data: %.5f.' % (metrics.roc_auc_score(y_ts, ann_probs, max_fpr = 0.3)))\n",
    "print('Random forest pAUC on test data: %.5f.' % (metrics.roc_auc_score(y_ts, rf_probs[:,1], max_fpr = 0.3)))\n",
    "print('Logistic regression pAUC on test data: %.5f.' % (metrics.roc_auc_score(y_ts, logreg_probs[:,1], max_fpr = 0.3)))\n",
    "print('Gradient boosting machine pAUC on test data: %.5f.' % (metrics.roc_auc_score(y_ts, gbm_probs[:,1], max_fpr = 0.3)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b46cb5ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network AUC on test data: 0.87762.\n",
      "Random forest AUC on test data: 0.88348.\n",
      "Logistic regression AUC on test data: 0.83908.\n",
      "Gradient boosting machine AUC on test data: 0.91741.\n"
     ]
    }
   ],
   "source": [
    "# AUC, test data\n",
    "print('Neural network AUC on test data: %.5f.' % (metrics.roc_auc_score(y_ts, ann_probs)))\n",
    "print('Random forest AUC on test data: %.5f.' % (metrics.roc_auc_score(y_ts, rf_probs[:,1])))\n",
    "print('Logistic regression AUC on test data: %.5f.' % (metrics.roc_auc_score(y_ts, logreg_probs[:,1])))\n",
    "print('Gradient boosting machine AUC on test data: %.5f.' % (metrics.roc_auc_score(y_ts, gbm_probs[:,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90f20ef",
   "metadata": {},
   "source": [
    "As we can see, the neural network fell short of decision tree-based algortihms such as random forest or GBM. However, it had the best performance at the true positive rate equal to 80%, meaning it achieved the smallest false positive rate among the trained algorithms. \n",
    "\n",
    "The actual choice of the cut-off point depends on how risky we want to be when choosing which companies we want to invest in. A lower cut-off point ensures that most of the bankrupt companies will be labeled correctly, but a lot of financially healthy companies will be also incorreclty labeled as going banrkupt. On the other hand, higher cut-off point lowers the value of incorrectly labeled healthy companies, but raises the risk that some of the companies predicted as healthy were, in reality, going bankrupt. This choice wholly relies on the business decision. \n",
    "\n",
    "In this project, I chose the 80% true positive rate boundary and its corresponding cut-off value. We can look at the *confusion matrices*, which tell us how many observations from the positive/negative class were labeled correctly (elements on the diagonal) and how many of them were labeled incorrectly (elements not on the diagonal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6c792b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrices\n",
    "from sklearn.metrics import confusion_matrix \n",
    "rf_p = threshold_rf[tpr_rf == 0.8][0]\n",
    "logreg_p = threshold_logreg[tpr_logreg == 0.8][0]\n",
    "gbm_p = threshold_gbm[tpr_gbm == 0.8][0]\n",
    "ann_p = threshold_ann[tpr_ann == 0.8][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c5b2fb59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "[[3238  640]\n",
      " [   4   16]]\n"
     ]
    }
   ],
   "source": [
    "print('Random Forest:')\n",
    "print(confusion_matrix(y_ts, (rf_probs[:,1] >= rf_p).astype('int')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4e3a161a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "[[2658 1220]\n",
      " [   4   16]]\n"
     ]
    }
   ],
   "source": [
    "print('Logistic Regression:')\n",
    "print(confusion_matrix(y_ts, (logreg_probs[:,1] >= logreg_p).astype('int')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "83f0970d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM:\n",
      "[[3487  391]\n",
      " [   4   16]]\n"
     ]
    }
   ],
   "source": [
    "print('GBM:')\n",
    "print(confusion_matrix(y_ts, (gbm_probs[:,1] >= gbm_p).astype('int')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ffd6c567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANN:\n",
      "[[3573  305]\n",
      " [   4   16]]\n"
     ]
    }
   ],
   "source": [
    "print('ANN:')\n",
    "print(confusion_matrix(y_ts, (ann_probs >= ann_p).astype('int')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7109d5f",
   "metadata": {},
   "source": [
    "The price we pay so at least 80% of banrkupt companies are labeled correctly, is pretty high. The artificial neural network, which was the best performer at this TPR level, incorrectly predicted 305 companies as bankrupt, even though in reality, they were financially healthy. This might seem as a high number, but since predicting bankruptcy solely from financial ratios is a rather complex problem, this model did a pretty okay job. \n",
    "\n",
    "Next up, we may look at the cut-off values for each model that correspond to the TPR = 0.8 level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8829b204",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal cut-off point, random forest: 0.524.\n",
      "Optimal cut-off point, logistic regression: 0.009.\n",
      "Optimal cut-off point, GBM: 0.397.\n",
      "Optimal cut-off point, neural net: 0.464.\n"
     ]
    }
   ],
   "source": [
    "# Cut-off points for TPR = 0.8\n",
    "print('Optimal cut-off point, random forest: %.3f.' % round(threshold_rf[tpr_rf == 0.8][0], 3))\n",
    "print('Optimal cut-off point, logistic regression: %.3f.' % round(threshold_logreg[tpr_logreg == 0.8][0], 3))\n",
    "print('Optimal cut-off point, GBM: %.3f.' % round(threshold_gbm[tpr_gbm == 0.8][0], 3))\n",
    "print('Optimal cut-off point, neural net: %.3f.' % round(threshold_ann[tpr_ann == 0.8][0], 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f05aff",
   "metadata": {},
   "source": [
    "The following code illustrates the definition and training of benchmark ML models used in this project: A random forest, logistic regression and gradient boosting machine. In the name of consistency, I used the same preprocessing paradigm as I did for the neural network. In reality, decision tree-based models allow us to skip some of the steps (such as winsorization) as they might even hurt the performance of these models via loss of information. I wanted to maintain 'fairness' so I evaluated the performance of these models on the same data, hence I kept the same preprocessing steps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "NJQyDqC6W6s8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 248,
     "status": "ok",
     "timestamp": 1645986618648,
     "user": {
      "displayName": "Michal Odler",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10321160972572366187"
     },
     "user_tz": -60
    },
    "id": "NJQyDqC6W6s8",
    "outputId": "248c6b62-d387-49c3-fcb0-02c3dea8a8c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " > init() called.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Benchmark models\n",
    "# Random Forest \n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "rf = imbpipeline(steps = [['outs', WinsorTrans()],\n",
    "                          ['scaler', MinMaxScaler()],\n",
    "                          ['imputer', KNNImputer()], \n",
    "                          ['us', RandomUnderSampler()], \n",
    "                          ['os', RandomOverSampler()], \n",
    "                          ['clf', RFC()]])\n",
    "params = {\n",
    "    'outs__alpha' : [0.05],\n",
    "    'imputer' : [KNNImputer(n_neighbors = 5)],\n",
    "    'os' : [SMOTE(sampling_strategy = 0.75)],\n",
    "    'us' : [RandomUnderSampler(sampling_strategy = 0.02)],\n",
    "    'clf__n_estimators' : [600, 800, 1000],\n",
    "    'clf__max_depth' : [2, 3, 4 , 5],\n",
    "    'clf__max_features' : [8, 10, 12]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c57b6891",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "part_auc = make_scorer(roc_auc_score, max_fpr = 0.3)\n",
    "forest = GridSearchCV(estimator = rf, \n",
    "                      verbose = 4,\n",
    "                      scoring = part_auc,\n",
    "                      param_grid = params,\n",
    "                      cv = 4,\n",
    "                      return_train_score = True)\n",
    "#forest.fit(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1bec3c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib \n",
    "#joblib.dump(forest.best_estimator_, 'rf_konec.pkl')\n",
    "#pd.DataFrame(forest.cv_results_).to_csv('rf_konec.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3b48e7d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " > init() called.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Retrained RF \n",
    "rf_final = imbpipeline(steps = [['outs', WinsorTrans()],\n",
    "                                ['scaler', MinMaxScaler()],\n",
    "                                ['imputer', KNNImputer()], \n",
    "                                ['us', RandomUnderSampler()], \n",
    "                                ['os', RandomOverSampler()], \n",
    "                                ['clf', RFC(n_estimators = 600,\n",
    "                                            max_depth = 3,\n",
    "                                            max_features = 12)]])\n",
    "#rf_final.fit(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1b3af3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#joblib.dump(rf_final, 'rf_upraveny.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9143174e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " > init() called.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "logreg = imbpipeline(steps = [['outs', WinsorTrans()],\n",
    "                              ['scaler', MinMaxScaler()],\n",
    "                              ['imputer', KNNImputer()], \n",
    "                              ['clf', LogisticRegression(solver = 'liblinear',\n",
    "                                                         max_iter = 10000,\n",
    "                                                         class_weight = 'balanced')]])\n",
    "params = {\n",
    "    'outs__alpha' : [0.05],\n",
    "    'imputer' : [KNNImputer(n_neighbors = 5)],\n",
    "    'clf__penalty' : ['l2', 'l1'],\n",
    "    'clf__C': [0.01, 0.1, 1, 10, 100, 1000]\n",
    "}\n",
    "# C = 1/lambda, 1 - 1000, penalty l1/l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1440433e",
   "metadata": {},
   "outputs": [],
   "source": [
    "regres = GridSearchCV(estimator = logreg, \n",
    "                      verbose = 4,\n",
    "                      scoring = part_auc,\n",
    "                      param_grid = params,\n",
    "                      cv = 4,\n",
    "                      return_train_score = True)\n",
    "#regres.fit(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9b2f0477",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(regres.cv_results_).to_csv('logreg_konec.csv')\n",
    "#joblib.dump(regres.best_estimator_, 'logreg_konec.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2ecabc2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " > init() called.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting Machine \n",
    "from sklearn.ensemble import GradientBoostingClassifier as GBC\n",
    "gbm = imbpipeline(steps = [['outs', WinsorTrans()],\n",
    "                             ['scaler', MinMaxScaler()],\n",
    "                             ['imputer', KNNImputer()], \n",
    "                             ['us', RandomUnderSampler()], \n",
    "                             ['os', RandomOverSampler()], \n",
    "                             ['clf', GBC()]])\n",
    "params = {\n",
    "    'outs__alpha' : [0.05],\n",
    "    'imputer' : [KNNImputer(n_neighbors = 5)],\n",
    "    'os' : [SMOTE(sampling_strategy = 0.75)],\n",
    "    'us' : [RandomUnderSampler(sampling_strategy = 0.02)],\n",
    "    'clf__n_estimators' : [50, 100, 300, 500],\n",
    "    'clf__max_depth' : [2, 3, 4],\n",
    "    'clf__learning_rate' : [1, 0.1, 0.01, 0.001]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "31fa6bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradboost = GridSearchCV(estimator = gbm, \n",
    "                         verbose = 4,\n",
    "                         scoring = part_auc,\n",
    "                         param_grid = params,\n",
    "                         cv = 4,\n",
    "                         return_train_score = True)\n",
    "#gradboost.fit(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "612c5e15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gbm_konec.pkl']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pd.DataFrame(gradboost.cv_results_).to_csv('gbm_konec.csv')\n",
    "#joblib.dump(gradboost.best_estimator_, 'gbm_konec.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c454650",
   "metadata": {},
   "source": [
    "## Saliency\n",
    "In the last part, I tried to define the *saliency* variable for each of the predictors according to an article written by duJardin [(link here)](https://www.sciencedirect.com/science/article/abs/pii/S0925231210001098). Since neural networks are a *black-box* algorithm, it is fairly difficult to determine which of the predictors were important in predicting the output variable. However, there have been some methods developed in the previous decade. They are usually described under the umbrella term *sensitivity analysis*. \n",
    "\n",
    "My main aim was to create a simple neural network with one hidden layer and simple architecture. I repeatedly trained this simple network and computed the saliency variable for each of the predictors, defined by duJardin. Then I looked at the predictors that repeatedly scored among the top in saliency, for various splits of the data. This is a very heuristic way of looking at the variable importance, but it might give us some insight into which of the features were more imporant that others.\n",
    "\n",
    "I will not get into details of the definition of saliency and my results; they can be found in my Master's thesis which is on my github page (unfortunately, it is written in Slovak). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e2010d37",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35511,
     "status": "ok",
     "timestamp": 1645539334969,
     "user": {
      "displayName": "Michal Odler",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10321160972572366187"
     },
     "user_tz": -60
    },
    "id": "6im72fI_9kYo",
    "outputId": "c1d2dc8d-3581-46cb-c31e-0036d96a30e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " > init() called.\n",
      "\n",
      "\n",
      " > init() called.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Saliency \n",
    "from sklearn.pipeline import Pipeline \n",
    "sampler = imbpipeline(steps = [['outs', WinsorTrans(alpha = 0.05)],\n",
    "                           ['scaler', MinMaxScaler()],\n",
    "                           ['imputer', KNNImputer(n_neighbors = 5)],\n",
    "                           ['us', RandomUnderSampler(sampling_strategy = 0.02)],\n",
    "                           ['os', SMOTE(sampling_strategy = 0.75)]])\n",
    "transformer = Pipeline(steps = [['outs', WinsorTrans(alpha = 0.05)], \n",
    "                       ['scaler', MinMaxScaler()],\n",
    "                       ['imputer', KNNImputer(n_neighbors = 5)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ab6666c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_net_sal():\n",
    "    net = Sequential()\n",
    "    net.add(Dense(20, input_dim = 60, activation = 'relu'))\n",
    "    net.add(Dense(1, activation = 'sigmoid'))\n",
    "    net.compile(loss = 'binary_crossentropy', \n",
    "                optimizer = 'adam', \n",
    "                metrics = AUC(thresholds = xseq))\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "37d79fb2",
   "metadata": {
    "id": "COLK-vTTsZfh"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "# Code test\n",
    "X_tra, X_val, y_tra, y_val = tts(X_tr, y_tr, test_size = 0.25, stratify = y_tr)\n",
    "X_tra_pp = sampler.fit_resample(X_tra, y_tra)\n",
    "transformer.fit(X_tra)\n",
    "X_val_pp = transformer.transform(X_val)\n",
    "X_val = (X_val_pp, y_val)\n",
    "callback = EarlyStopping(monitor = 'val_loss', patience = 10)\n",
    "net = create_net_sal()\n",
    "#net.fit(X_tra_pp[0], X_tra_pp[1], validation_data = X_val, epochs = 300, verbose = 1, batch_size = 128,\n",
    "#                callbacks = [callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0b6cca1e",
   "metadata": {
    "id": "GnRDQFFy079l"
   },
   "outputs": [],
   "source": [
    "def saliency(model):\n",
    "  k = model.layers[0].get_weights()[0].shape[0]\n",
    "  sal = [0] * k\n",
    "  abs1 = abs(model.layers[0].get_weights()[0])\n",
    "  abs2 = abs(model.layers[1].get_weights()[0])\n",
    "  sec = abs2 / abs2.sum()\n",
    "  fir = abs1.sum(axis = 0)\n",
    "  for i in np.arange(k):\n",
    "    sal[i] = float(np.dot(abs1[i,:] / fir, sec))\n",
    "  return(pd.Series(sal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "88460b3c",
   "metadata": {
    "collapsed": true,
    "id": "ZxMFwzBu9wbJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "42/42 [==============================] - 2s 22ms/step - loss: 0.5771 - auc_1: 0.5635 - val_loss: 0.4770 - val_auc_1: 0.6494\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.4343 - auc_1: 0.7325 - val_loss: 0.4005 - val_auc_1: 0.7228\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3513 - auc_1: 0.8032 - val_loss: 0.3236 - val_auc_1: 0.7822\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3053 - auc_1: 0.8481 - val_loss: 0.2644 - val_auc_1: 0.8136\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2783 - auc_1: 0.8753 - val_loss: 0.2597 - val_auc_1: 0.8282\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2591 - auc_1: 0.8887 - val_loss: 0.2333 - val_auc_1: 0.8388\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2450 - auc_1: 0.9003 - val_loss: 0.2454 - val_auc_1: 0.8427\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2328 - auc_1: 0.9029 - val_loss: 0.2603 - val_auc_1: 0.8410\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2275 - auc_1: 0.9030 - val_loss: 0.2380 - val_auc_1: 0.8513\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2168 - auc_1: 0.9128 - val_loss: 0.2326 - val_auc_1: 0.8540\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2094 - auc_1: 0.9175 - val_loss: 0.2141 - val_auc_1: 0.8624\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2034 - auc_1: 0.9215 - val_loss: 0.2160 - val_auc_1: 0.8646\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1982 - auc_1: 0.9269 - val_loss: 0.2028 - val_auc_1: 0.8724\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1932 - auc_1: 0.9301 - val_loss: 0.2168 - val_auc_1: 0.8688\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1883 - auc_1: 0.9290 - val_loss: 0.2012 - val_auc_1: 0.8752\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1833 - auc_1: 0.9306 - val_loss: 0.2011 - val_auc_1: 0.8750\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1791 - auc_1: 0.9336 - val_loss: 0.1872 - val_auc_1: 0.8815\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1751 - auc_1: 0.9356 - val_loss: 0.1766 - val_auc_1: 0.8888\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1700 - auc_1: 0.9362 - val_loss: 0.2019 - val_auc_1: 0.8798\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1672 - auc_1: 0.9376 - val_loss: 0.1697 - val_auc_1: 0.8799\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1631 - auc_1: 0.9416 - val_loss: 0.2077 - val_auc_1: 0.8814\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1599 - auc_1: 0.9421 - val_loss: 0.1996 - val_auc_1: 0.8852\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1556 - auc_1: 0.9405 - val_loss: 0.1730 - val_auc_1: 0.8664\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1521 - auc_1: 0.9455 - val_loss: 0.1956 - val_auc_1: 0.8892\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1517 - auc_1: 0.9413 - val_loss: 0.1742 - val_auc_1: 0.8688\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1460 - auc_1: 0.9472 - val_loss: 0.1601 - val_auc_1: 0.8761\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1420 - auc_1: 0.9464 - val_loss: 0.1763 - val_auc_1: 0.8697\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1393 - auc_1: 0.9487 - val_loss: 0.1577 - val_auc_1: 0.8750\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1356 - auc_1: 0.9507 - val_loss: 0.1723 - val_auc_1: 0.8697\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1328 - auc_1: 0.9518 - val_loss: 0.1815 - val_auc_1: 0.8662\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1300 - auc_1: 0.9525 - val_loss: 0.1614 - val_auc_1: 0.8737\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1270 - auc_1: 0.9539 - val_loss: 0.1599 - val_auc_1: 0.8751\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1247 - auc_1: 0.9548 - val_loss: 0.1454 - val_auc_1: 0.8810\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1218 - auc_1: 0.9563 - val_loss: 0.1531 - val_auc_1: 0.8779\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1196 - auc_1: 0.9581 - val_loss: 0.1463 - val_auc_1: 0.8817\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1210 - auc_1: 0.9612 - val_loss: 0.1532 - val_auc_1: 0.8800\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1159 - auc_1: 0.9578 - val_loss: 0.1412 - val_auc_1: 0.8839\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1133 - auc_1: 0.9588 - val_loss: 0.1463 - val_auc_1: 0.8835\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1104 - auc_1: 0.9591 - val_loss: 0.1566 - val_auc_1: 0.8798\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1128 - auc_1: 0.9565 - val_loss: 0.1499 - val_auc_1: 0.8805\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1066 - auc_1: 0.9603 - val_loss: 0.1484 - val_auc_1: 0.8819\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1062 - auc_1: 0.9591 - val_loss: 0.1463 - val_auc_1: 0.8836\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1030 - auc_1: 0.9614 - val_loss: 0.1455 - val_auc_1: 0.8844\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1012 - auc_1: 0.9631 - val_loss: 0.1358 - val_auc_1: 0.8877\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0992 - auc_1: 0.9631 - val_loss: 0.1462 - val_auc_1: 0.8850\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0980 - auc_1: 0.9634 - val_loss: 0.1443 - val_auc_1: 0.8851\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0973 - auc_1: 0.9650 - val_loss: 0.1444 - val_auc_1: 0.8866\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0945 - auc_1: 0.9661 - val_loss: 0.1268 - val_auc_1: 0.8935\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0949 - auc_1: 0.9682 - val_loss: 0.1301 - val_auc_1: 0.8921\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0916 - auc_1: 0.9683 - val_loss: 0.1477 - val_auc_1: 0.8865\n",
      "Epoch 51/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0900 - auc_1: 0.9675 - val_loss: 0.1413 - val_auc_1: 0.8889\n",
      "Epoch 52/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0889 - auc_1: 0.9684 - val_loss: 0.1386 - val_auc_1: 0.8875\n",
      "Epoch 53/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0880 - auc_1: 0.9674 - val_loss: 0.1371 - val_auc_1: 0.8885\n",
      "Epoch 54/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0861 - auc_1: 0.9685 - val_loss: 0.1331 - val_auc_1: 0.8908\n",
      "Epoch 55/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0847 - auc_1: 0.9706 - val_loss: 0.1235 - val_auc_1: 0.8936\n",
      "Epoch 56/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0892 - auc_1: 0.9707 - val_loss: 0.1052 - val_auc_1: 0.8960\n",
      "Epoch 57/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0954 - auc_1: 0.9720 - val_loss: 0.1244 - val_auc_1: 0.8929\n",
      "Epoch 58/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0826 - auc_1: 0.9726 - val_loss: 0.1314 - val_auc_1: 0.8924\n",
      "Epoch 59/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0806 - auc_1: 0.9723 - val_loss: 0.1390 - val_auc_1: 0.8895\n",
      "Epoch 60/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0797 - auc_1: 0.9725 - val_loss: 0.1258 - val_auc_1: 0.8941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0785 - auc_1: 0.9730 - val_loss: 0.1273 - val_auc_1: 0.8933\n",
      "Epoch 62/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0777 - auc_1: 0.9738 - val_loss: 0.1224 - val_auc_1: 0.8946\n",
      "Epoch 63/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0765 - auc_1: 0.9733 - val_loss: 0.1337 - val_auc_1: 0.8915\n",
      "Epoch 64/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.0760 - auc_1: 0.9725 - val_loss: 0.1345 - val_auc_1: 0.8917\n",
      "Epoch 65/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.0754 - auc_1: 0.9737 - val_loss: 0.1304 - val_auc_1: 0.8915\n",
      "Epoch 66/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0737 - auc_1: 0.9735 - val_loss: 0.1178 - val_auc_1: 0.8951\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 2s 22ms/step - loss: 0.6762 - auc_2: 0.5110 - val_loss: 0.5101 - val_auc_2: 0.6322\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.4989 - auc_2: 0.6910 - val_loss: 0.3762 - val_auc_2: 0.7380\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.4073 - auc_2: 0.7836 - val_loss: 0.3379 - val_auc_2: 0.7519\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3480 - auc_2: 0.8222 - val_loss: 0.2750 - val_auc_2: 0.7993\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.3070 - auc_2: 0.8610 - val_loss: 0.2759 - val_auc_2: 0.8060\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2795 - auc_2: 0.8728 - val_loss: 0.2373 - val_auc_2: 0.8293\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.2602 - auc_2: 0.8850 - val_loss: 0.2345 - val_auc_2: 0.8340\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2445 - auc_2: 0.8952 - val_loss: 0.2422 - val_auc_2: 0.8422\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2328 - auc_2: 0.9018 - val_loss: 0.2404 - val_auc_2: 0.8469\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2217 - auc_2: 0.9099 - val_loss: 0.2323 - val_auc_2: 0.8517\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2123 - auc_2: 0.9116 - val_loss: 0.2062 - val_auc_2: 0.8644\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2051 - auc_2: 0.9200 - val_loss: 0.1969 - val_auc_2: 0.8678\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1975 - auc_2: 0.9200 - val_loss: 0.2309 - val_auc_2: 0.8586\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1911 - auc_2: 0.9245 - val_loss: 0.1967 - val_auc_2: 0.8728\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1855 - auc_2: 0.9275 - val_loss: 0.2016 - val_auc_2: 0.8725\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1796 - auc_2: 0.9311 - val_loss: 0.1698 - val_auc_2: 0.8839\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1783 - auc_2: 0.9353 - val_loss: 0.1586 - val_auc_2: 0.8912\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1697 - auc_2: 0.9367 - val_loss: 0.1809 - val_auc_2: 0.8828\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1646 - auc_2: 0.9371 - val_loss: 0.1724 - val_auc_2: 0.8884\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1609 - auc_2: 0.9407 - val_loss: 0.1663 - val_auc_2: 0.8905\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1562 - auc_2: 0.9409 - val_loss: 0.1583 - val_auc_2: 0.8799\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1523 - auc_2: 0.9442 - val_loss: 0.1759 - val_auc_2: 0.8900\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1484 - auc_2: 0.9441 - val_loss: 0.1655 - val_auc_2: 0.8789\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1443 - auc_2: 0.9462 - val_loss: 0.1775 - val_auc_2: 0.8746\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1409 - auc_2: 0.9477 - val_loss: 0.1639 - val_auc_2: 0.8796\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1378 - auc_2: 0.9507 - val_loss: 0.1518 - val_auc_2: 0.8863\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1344 - auc_2: 0.9508 - val_loss: 0.1409 - val_auc_2: 0.8922\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1313 - auc_2: 0.9527 - val_loss: 0.1337 - val_auc_2: 0.8791\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1318 - auc_2: 0.9555 - val_loss: 0.1287 - val_auc_2: 0.8816\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1275 - auc_2: 0.9567 - val_loss: 0.1548 - val_auc_2: 0.8884\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1242 - auc_2: 0.9530 - val_loss: 0.1449 - val_auc_2: 0.8919\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1238 - auc_2: 0.9591 - val_loss: 0.1340 - val_auc_2: 0.8786\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1203 - auc_2: 0.9588 - val_loss: 0.1337 - val_auc_2: 0.8771\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1185 - auc_2: 0.9602 - val_loss: 0.1324 - val_auc_2: 0.8775\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1144 - auc_2: 0.9617 - val_loss: 0.1389 - val_auc_2: 0.8758\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1131 - auc_2: 0.9614 - val_loss: 0.1461 - val_auc_2: 0.8723\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1090 - auc_2: 0.9597 - val_loss: 0.1351 - val_auc_2: 0.8780\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1068 - auc_2: 0.9628 - val_loss: 0.1504 - val_auc_2: 0.8719\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1050 - auc_2: 0.9599 - val_loss: 0.1294 - val_auc_2: 0.8821\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 2s 23ms/step - loss: 0.6504 - auc_3: 0.5418 - val_loss: 0.4423 - val_auc_3: 0.6279\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.5098 - auc_3: 0.6969 - val_loss: 0.3605 - val_auc_3: 0.7009\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3961 - auc_3: 0.7966 - val_loss: 0.3040 - val_auc_3: 0.7619\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3362 - auc_3: 0.8420 - val_loss: 0.2672 - val_auc_3: 0.7936\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2999 - auc_3: 0.8637 - val_loss: 0.2548 - val_auc_3: 0.8074\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2754 - auc_3: 0.8777 - val_loss: 0.2450 - val_auc_3: 0.8198\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2608 - auc_3: 0.8904 - val_loss: 0.2464 - val_auc_3: 0.8222\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2469 - auc_3: 0.8989 - val_loss: 0.2631 - val_auc_3: 0.8243\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.2395 - auc_3: 0.8944 - val_loss: 0.2398 - val_auc_3: 0.8337\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2276 - auc_3: 0.9104 - val_loss: 0.2520 - val_auc_3: 0.8333\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2194 - auc_3: 0.9107 - val_loss: 0.2169 - val_auc_3: 0.8485\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2122 - auc_3: 0.9157 - val_loss: 0.2101 - val_auc_3: 0.8533\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.2106 - auc_3: 0.9232 - val_loss: 0.2023 - val_auc_3: 0.8582\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2040 - auc_3: 0.9268 - val_loss: 0.2260 - val_auc_3: 0.8546\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1970 - auc_3: 0.9226 - val_loss: 0.2222 - val_auc_3: 0.8577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1926 - auc_3: 0.9236 - val_loss: 0.2127 - val_auc_3: 0.8630\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1872 - auc_3: 0.9279 - val_loss: 0.2165 - val_auc_3: 0.8629\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1832 - auc_3: 0.9278 - val_loss: 0.1952 - val_auc_3: 0.8713\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1779 - auc_3: 0.9313 - val_loss: 0.1743 - val_auc_3: 0.8661\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.1788 - auc_3: 0.9363 - val_loss: 0.1678 - val_auc_3: 0.8701\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1731 - auc_3: 0.9391 - val_loss: 0.1809 - val_auc_3: 0.8641\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1665 - auc_3: 0.9375 - val_loss: 0.1816 - val_auc_3: 0.8651\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1627 - auc_3: 0.9390 - val_loss: 0.1985 - val_auc_3: 0.8592\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1588 - auc_3: 0.9391 - val_loss: 0.1705 - val_auc_3: 0.8727\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1552 - auc_3: 0.9415 - val_loss: 0.1870 - val_auc_3: 0.8674\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1516 - auc_3: 0.9423 - val_loss: 0.1558 - val_auc_3: 0.8453\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.1501 - auc_3: 0.9455 - val_loss: 0.1585 - val_auc_3: 0.8449\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.1459 - auc_3: 0.9485 - val_loss: 0.1571 - val_auc_3: 0.8454\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 0.1482 - auc_3: 0.9494 - val_loss: 0.1576 - val_auc_3: 0.8438\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.1392 - auc_3: 0.9488 - val_loss: 0.1615 - val_auc_3: 0.8432\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.1357 - auc_3: 0.9502 - val_loss: 0.1692 - val_auc_3: 0.8415\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.1329 - auc_3: 0.9501 - val_loss: 0.1743 - val_auc_3: 0.8391\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.1311 - auc_3: 0.9482 - val_loss: 0.1635 - val_auc_3: 0.8435\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.1277 - auc_3: 0.9509 - val_loss: 0.1636 - val_auc_3: 0.8426\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.1244 - auc_3: 0.9526 - val_loss: 0.1506 - val_auc_3: 0.8492\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.1261 - auc_3: 0.9564 - val_loss: 0.1508 - val_auc_3: 0.8480\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1189 - auc_3: 0.9553 - val_loss: 0.1539 - val_auc_3: 0.8474\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1164 - auc_3: 0.9562 - val_loss: 0.1589 - val_auc_3: 0.8460\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1211 - auc_3: 0.9505 - val_loss: 0.1480 - val_auc_3: 0.8500\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1132 - auc_3: 0.9573 - val_loss: 0.1306 - val_auc_3: 0.8586\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.1168 - auc_3: 0.9590 - val_loss: 0.1280 - val_auc_3: 0.8588\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1090 - auc_3: 0.9602 - val_loss: 0.1419 - val_auc_3: 0.8542\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1065 - auc_3: 0.9593 - val_loss: 0.1347 - val_auc_3: 0.8582\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1043 - auc_3: 0.9600 - val_loss: 0.1351 - val_auc_3: 0.8585\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1025 - auc_3: 0.9611 - val_loss: 0.1388 - val_auc_3: 0.8564\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1005 - auc_3: 0.9619 - val_loss: 0.1227 - val_auc_3: 0.8630\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0996 - auc_3: 0.9629 - val_loss: 0.1253 - val_auc_3: 0.8628\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0970 - auc_3: 0.9642 - val_loss: 0.1220 - val_auc_3: 0.8642\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0949 - auc_3: 0.9656 - val_loss: 0.1433 - val_auc_3: 0.8565\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0931 - auc_3: 0.9652 - val_loss: 0.1354 - val_auc_3: 0.8601\n",
      "Epoch 51/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0919 - auc_3: 0.9639 - val_loss: 0.1280 - val_auc_3: 0.8626\n",
      "Epoch 52/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0899 - auc_3: 0.9668 - val_loss: 0.1209 - val_auc_3: 0.8630\n",
      "Epoch 53/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0888 - auc_3: 0.9674 - val_loss: 0.1128 - val_auc_3: 0.8660\n",
      "Epoch 54/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0881 - auc_3: 0.9709 - val_loss: 0.1217 - val_auc_3: 0.8637\n",
      "Epoch 55/300\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.0851 - auc_3: 0.9688 - val_loss: 0.1261 - val_auc_3: 0.8615\n",
      "Epoch 56/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0834 - auc_3: 0.9684 - val_loss: 0.1200 - val_auc_3: 0.8648\n",
      "Epoch 57/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0821 - auc_3: 0.9676 - val_loss: 0.1212 - val_auc_3: 0.8637\n",
      "Epoch 58/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0802 - auc_3: 0.9697 - val_loss: 0.1218 - val_auc_3: 0.8642\n",
      "Epoch 59/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0791 - auc_3: 0.9716 - val_loss: 0.1283 - val_auc_3: 0.8619\n",
      "Epoch 60/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0783 - auc_3: 0.9684 - val_loss: 0.1294 - val_auc_3: 0.8614\n",
      "Epoch 61/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0759 - auc_3: 0.9716 - val_loss: 0.1218 - val_auc_3: 0.8635\n",
      "Epoch 62/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0745 - auc_3: 0.9713 - val_loss: 0.1201 - val_auc_3: 0.8629\n",
      "Epoch 63/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0734 - auc_3: 0.9720 - val_loss: 0.1218 - val_auc_3: 0.8622\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 2s 22ms/step - loss: 0.6732 - auc_4: 0.4916 - val_loss: 0.4727 - val_auc_4: 0.6392\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.4928 - auc_4: 0.7167 - val_loss: 0.3683 - val_auc_4: 0.7368\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3792 - auc_4: 0.8043 - val_loss: 0.3309 - val_auc_4: 0.7834\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3162 - auc_4: 0.8455 - val_loss: 0.2652 - val_auc_4: 0.8141\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2803 - auc_4: 0.8759 - val_loss: 0.2609 - val_auc_4: 0.8288\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2575 - auc_4: 0.8919 - val_loss: 0.2616 - val_auc_4: 0.8319\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2456 - auc_4: 0.8912 - val_loss: 0.2321 - val_auc_4: 0.8457\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2356 - auc_4: 0.9081 - val_loss: 0.2366 - val_auc_4: 0.8457\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2252 - auc_4: 0.9086 - val_loss: 0.2372 - val_auc_4: 0.8473\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2177 - auc_4: 0.9101 - val_loss: 0.2195 - val_auc_4: 0.8555\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2101 - auc_4: 0.9163 - val_loss: 0.2172 - val_auc_4: 0.8587\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2036 - auc_4: 0.9191 - val_loss: 0.2022 - val_auc_4: 0.8646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1979 - auc_4: 0.9215 - val_loss: 0.1875 - val_auc_4: 0.8698\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1931 - auc_4: 0.9244 - val_loss: 0.1830 - val_auc_4: 0.8722\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1885 - auc_4: 0.9294 - val_loss: 0.2113 - val_auc_4: 0.8636\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1835 - auc_4: 0.9272 - val_loss: 0.2411 - val_auc_4: 0.8572\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1872 - auc_4: 0.9198 - val_loss: 0.1970 - val_auc_4: 0.8718\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1747 - auc_4: 0.9339 - val_loss: 0.1895 - val_auc_4: 0.8640\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1703 - auc_4: 0.9343 - val_loss: 0.1868 - val_auc_4: 0.8636\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1666 - auc_4: 0.9361 - val_loss: 0.1964 - val_auc_4: 0.8605\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.1632 - auc_4: 0.9379 - val_loss: 0.2147 - val_auc_4: 0.8682\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1633 - auc_4: 0.9334 - val_loss: 0.1772 - val_auc_4: 0.8689\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1555 - auc_4: 0.9436 - val_loss: 0.1920 - val_auc_4: 0.8641\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1550 - auc_4: 0.9407 - val_loss: 0.1797 - val_auc_4: 0.8706\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1482 - auc_4: 0.9453 - val_loss: 0.1675 - val_auc_4: 0.8772\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1449 - auc_4: 0.9453 - val_loss: 0.1783 - val_auc_4: 0.8728\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1420 - auc_4: 0.9460 - val_loss: 0.1648 - val_auc_4: 0.8631\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1385 - auc_4: 0.9483 - val_loss: 0.1570 - val_auc_4: 0.8673\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1359 - auc_4: 0.9499 - val_loss: 0.1670 - val_auc_4: 0.8643\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1327 - auc_4: 0.9516 - val_loss: 0.1629 - val_auc_4: 0.8672\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1298 - auc_4: 0.9526 - val_loss: 0.1700 - val_auc_4: 0.8649\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1299 - auc_4: 0.9479 - val_loss: 0.1555 - val_auc_4: 0.8709\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1244 - auc_4: 0.9542 - val_loss: 0.1641 - val_auc_4: 0.8691\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1219 - auc_4: 0.9545 - val_loss: 0.1507 - val_auc_4: 0.8730\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1195 - auc_4: 0.9571 - val_loss: 0.1530 - val_auc_4: 0.8705\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.1166 - auc_4: 0.9561 - val_loss: 0.1319 - val_auc_4: 0.8800\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1149 - auc_4: 0.9593 - val_loss: 0.1536 - val_auc_4: 0.8709\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1121 - auc_4: 0.9584 - val_loss: 0.1483 - val_auc_4: 0.8728\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1103 - auc_4: 0.9581 - val_loss: 0.1443 - val_auc_4: 0.8750\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1073 - auc_4: 0.9616 - val_loss: 0.1310 - val_auc_4: 0.8625\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1051 - auc_4: 0.9621 - val_loss: 0.1428 - val_auc_4: 0.8756\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1030 - auc_4: 0.9635 - val_loss: 0.1371 - val_auc_4: 0.8607\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1021 - auc_4: 0.9625 - val_loss: 0.1271 - val_auc_4: 0.8651\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0982 - auc_4: 0.9655 - val_loss: 0.1411 - val_auc_4: 0.8595\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0969 - auc_4: 0.9645 - val_loss: 0.1371 - val_auc_4: 0.8612\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.0943 - auc_4: 0.9667 - val_loss: 0.1278 - val_auc_4: 0.8646\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0925 - auc_4: 0.9677 - val_loss: 0.1275 - val_auc_4: 0.8640\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0906 - auc_4: 0.9691 - val_loss: 0.1416 - val_auc_4: 0.8597\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.0892 - auc_4: 0.9669 - val_loss: 0.1275 - val_auc_4: 0.8644\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0873 - auc_4: 0.9690 - val_loss: 0.1262 - val_auc_4: 0.8652\n",
      "Epoch 51/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0869 - auc_4: 0.9686 - val_loss: 0.1244 - val_auc_4: 0.8646\n",
      "Epoch 52/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0834 - auc_4: 0.9707 - val_loss: 0.1163 - val_auc_4: 0.8674\n",
      "Epoch 53/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0818 - auc_4: 0.9717 - val_loss: 0.1112 - val_auc_4: 0.8708\n",
      "Epoch 54/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0803 - auc_4: 0.9726 - val_loss: 0.1034 - val_auc_4: 0.8718\n",
      "Epoch 55/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0843 - auc_4: 0.9734 - val_loss: 0.1054 - val_auc_4: 0.8715\n",
      "Epoch 56/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0791 - auc_4: 0.9740 - val_loss: 0.1110 - val_auc_4: 0.8694\n",
      "Epoch 57/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.0759 - auc_4: 0.9744 - val_loss: 0.1134 - val_auc_4: 0.8696\n",
      "Epoch 58/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0742 - auc_4: 0.9742 - val_loss: 0.1180 - val_auc_4: 0.8683\n",
      "Epoch 59/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.0732 - auc_4: 0.9736 - val_loss: 0.1184 - val_auc_4: 0.8682\n",
      "Epoch 60/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0719 - auc_4: 0.9746 - val_loss: 0.1230 - val_auc_4: 0.8664\n",
      "Epoch 61/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0761 - auc_4: 0.9713 - val_loss: 0.1276 - val_auc_4: 0.8628\n",
      "Epoch 62/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.0700 - auc_4: 0.9763 - val_loss: 0.1101 - val_auc_4: 0.8658\n",
      "Epoch 63/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0697 - auc_4: 0.9746 - val_loss: 0.1181 - val_auc_4: 0.8666\n",
      "Epoch 64/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0675 - auc_4: 0.9760 - val_loss: 0.1130 - val_auc_4: 0.8673\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 2s 22ms/step - loss: 0.5866 - auc_5: 0.5618 - val_loss: 0.4207 - val_auc_5: 0.6507\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.4566 - auc_5: 0.7311 - val_loss: 0.3585 - val_auc_5: 0.7328\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.3725 - auc_5: 0.7996 - val_loss: 0.3146 - val_auc_5: 0.7758\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 0.3211 - auc_5: 0.8360 - val_loss: 0.2846 - val_auc_5: 0.8027\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.2877 - auc_5: 0.8639 - val_loss: 0.2372 - val_auc_5: 0.8301\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.2651 - auc_5: 0.8838 - val_loss: 0.2204 - val_auc_5: 0.8407\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.2485 - auc_5: 0.9010 - val_loss: 0.2405 - val_auc_5: 0.8376\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2342 - auc_5: 0.9035 - val_loss: 0.2089 - val_auc_5: 0.8548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2236 - auc_5: 0.9126 - val_loss: 0.2223 - val_auc_5: 0.8526\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2132 - auc_5: 0.9157 - val_loss: 0.2279 - val_auc_5: 0.8545\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2094 - auc_5: 0.9150 - val_loss: 0.2205 - val_auc_5: 0.8591\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1989 - auc_5: 0.9219 - val_loss: 0.2158 - val_auc_5: 0.8603\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.1926 - auc_5: 0.9235 - val_loss: 0.1872 - val_auc_5: 0.8734\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.1868 - auc_5: 0.9314 - val_loss: 0.1861 - val_auc_5: 0.8768\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.1807 - auc_5: 0.9302 - val_loss: 0.1793 - val_auc_5: 0.8799\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.1753 - auc_5: 0.9331 - val_loss: 0.1849 - val_auc_5: 0.8790\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.1701 - auc_5: 0.9362 - val_loss: 0.1876 - val_auc_5: 0.8819\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.1653 - auc_5: 0.9382 - val_loss: 0.1905 - val_auc_5: 0.8818- loss: 0.1660 - auc_5: 0.93 - ETA: 0s - loss: 0.1652 - auc_5: 0.938\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1626 - auc_5: 0.9369 - val_loss: 0.1745 - val_auc_5: 0.8857\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1568 - auc_5: 0.9431 - val_loss: 0.1942 - val_auc_5: 0.8810\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.1532 - auc_5: 0.9415 - val_loss: 0.1789 - val_auc_5: 0.8897\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.1481 - auc_5: 0.9446 - val_loss: 0.1558 - val_auc_5: 0.8834\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1445 - auc_5: 0.9476 - val_loss: 0.1585 - val_auc_5: 0.8824\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1407 - auc_5: 0.9470 - val_loss: 0.1472 - val_auc_5: 0.8713\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.1384 - auc_5: 0.9486 - val_loss: 0.1817 - val_auc_5: 0.8765\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.1355 - auc_5: 0.9482 - val_loss: 0.1656 - val_auc_5: 0.8822\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1309 - auc_5: 0.9517 - val_loss: 0.1664 - val_auc_5: 0.8684\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1275 - auc_5: 0.9522 - val_loss: 0.1634 - val_auc_5: 0.8699\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1247 - auc_5: 0.9538 - val_loss: 0.1527 - val_auc_5: 0.8716\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1221 - auc_5: 0.9539 - val_loss: 0.1483 - val_auc_5: 0.8716\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1195 - auc_5: 0.9569 - val_loss: 0.1510 - val_auc_5: 0.8707\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1178 - auc_5: 0.9548 - val_loss: 0.1455 - val_auc_5: 0.8732\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1141 - auc_5: 0.9591 - val_loss: 0.1478 - val_auc_5: 0.8720\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1118 - auc_5: 0.9593 - val_loss: 0.1493 - val_auc_5: 0.8720\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1100 - auc_5: 0.9600 - val_loss: 0.1527 - val_auc_5: 0.8682\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1132 - auc_5: 0.9578 - val_loss: 0.1379 - val_auc_5: 0.8745\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.1074 - auc_5: 0.9601 - val_loss: 0.1291 - val_auc_5: 0.8789\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.1052 - auc_5: 0.9617 - val_loss: 0.1263 - val_auc_5: 0.8793\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1030 - auc_5: 0.9626 - val_loss: 0.1437 - val_auc_5: 0.8726\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.1012 - auc_5: 0.9638 - val_loss: 0.1339 - val_auc_5: 0.8762: 0s - loss: 0.1025 - auc\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.0994 - auc_5: 0.9638 - val_loss: 0.1428 - val_auc_5: 0.8720\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.0978 - auc_5: 0.9633 - val_loss: 0.1224 - val_auc_5: 0.8807\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.0964 - auc_5: 0.9655 - val_loss: 0.1280 - val_auc_5: 0.8784\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.0946 - auc_5: 0.9655 - val_loss: 0.1400 - val_auc_5: 0.8737\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0932 - auc_5: 0.9667 - val_loss: 0.1198 - val_auc_5: 0.8812\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0990 - auc_5: 0.9695 - val_loss: 0.1179 - val_auc_5: 0.8813\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.0935 - auc_5: 0.9685 - val_loss: 0.1176 - val_auc_5: 0.8794\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.0902 - auc_5: 0.9694 - val_loss: 0.1275 - val_auc_5: 0.8769\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.0894 - auc_5: 0.9672 - val_loss: 0.1215 - val_auc_5: 0.8801\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.0923 - auc_5: 0.9704 - val_loss: 0.1153 - val_auc_5: 0.8788\n",
      "Epoch 51/300\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.0869 - auc_5: 0.9703 - val_loss: 0.1263 - val_auc_5: 0.8768\n",
      "Epoch 52/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.0855 - auc_5: 0.9700 - val_loss: 0.1325 - val_auc_5: 0.8747\n",
      "Epoch 53/300\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.0843 - auc_5: 0.9692 - val_loss: 0.1198 - val_auc_5: 0.8805\n",
      "Epoch 54/300\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.0829 - auc_5: 0.9714 - val_loss: 0.1162 - val_auc_5: 0.8816\n",
      "Epoch 55/300\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.0817 - auc_5: 0.9713 - val_loss: 0.1134 - val_auc_5: 0.8817\n",
      "Epoch 56/300\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.0807 - auc_5: 0.9729 - val_loss: 0.1247 - val_auc_5: 0.8788\n",
      "Epoch 57/300\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 0.0799 - auc_5: 0.9713 - val_loss: 0.1141 - val_auc_5: 0.8827\n",
      "Epoch 58/300\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.0794 - auc_5: 0.9729 - val_loss: 0.1101 - val_auc_5: 0.8623\n",
      "Epoch 59/300\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.0779 - auc_5: 0.9732 - val_loss: 0.1219 - val_auc_5: 0.8796\n",
      "Epoch 60/300\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.0770 - auc_5: 0.9734 - val_loss: 0.1211 - val_auc_5: 0.8797\n",
      "Epoch 61/300\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.0757 - auc_5: 0.9738 - val_loss: 0.1130 - val_auc_5: 0.8814\n",
      "Epoch 62/300\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.0748 - auc_5: 0.9740 - val_loss: 0.1058 - val_auc_5: 0.8847\n",
      "Epoch 63/300\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.0739 - auc_5: 0.9753 - val_loss: 0.1196 - val_auc_5: 0.8793\n",
      "Epoch 64/300\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.0732 - auc_5: 0.9741 - val_loss: 0.1158 - val_auc_5: 0.8819\n",
      "Epoch 65/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.0720 - auc_5: 0.9751 - val_loss: 0.1085 - val_auc_5: 0.8843\n",
      "Epoch 66/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.0710 - auc_5: 0.9761 - val_loss: 0.1182 - val_auc_5: 0.8803\n",
      "Epoch 67/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.0701 - auc_5: 0.9758 - val_loss: 0.1123 - val_auc_5: 0.8633\n",
      "Epoch 68/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 19ms/step - loss: 0.0692 - auc_5: 0.9765 - val_loss: 0.1161 - val_auc_5: 0.8621\n",
      "Epoch 69/300\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.0682 - auc_5: 0.9766 - val_loss: 0.1120 - val_auc_5: 0.8650\n",
      "Epoch 70/300\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.0672 - auc_5: 0.9776 - val_loss: 0.1110 - val_auc_5: 0.8646\n",
      "Epoch 71/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.0663 - auc_5: 0.9773 - val_loss: 0.1032 - val_auc_5: 0.8671\n",
      "Epoch 72/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.0654 - auc_5: 0.9778 - val_loss: 0.1079 - val_auc_5: 0.8653\n",
      "Epoch 73/300\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 0.0643 - auc_5: 0.9776 - val_loss: 0.1193 - val_auc_5: 0.8623\n",
      "Epoch 74/300\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0711 - auc_5: 0.9718 - val_loss: 0.1171 - val_auc_5: 0.86170s - loss: 0.0733 - auc_5: 0.96 - ETA: 0s - loss: 0.0720 - auc_5: 0.970 - ETA: 0s - loss: 0.0717 - auc_5: 0.9\n",
      "Epoch 75/300\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.0634 - auc_5: 0.9783 - val_loss: 0.1025 - val_auc_5: 0.8651\n",
      "Epoch 76/300\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0617 - auc_5: 0.9795 - val_loss: 0.1104 - val_auc_5: 0.8652\n",
      "Epoch 77/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.0607 - auc_5: 0.9787 - val_loss: 0.1010 - val_auc_5: 0.8680\n",
      "Epoch 78/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.0615 - auc_5: 0.9793 - val_loss: 0.1228 - val_auc_5: 0.8608\n",
      "Epoch 79/300\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0598 - auc_5: 0.9790 - val_loss: 0.1107 - val_auc_5: 0.8655\n",
      "Epoch 80/300\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0583 - auc_5: 0.9798 - val_loss: 0.1066 - val_auc_5: 0.8677\n",
      "Epoch 81/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.0574 - auc_5: 0.9805 - val_loss: 0.1000 - val_auc_5: 0.8489\n",
      "Epoch 82/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.0568 - auc_5: 0.9805 - val_loss: 0.1077 - val_auc_5: 0.8676\n",
      "Epoch 83/300\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0560 - auc_5: 0.9808 - val_loss: 0.1050 - val_auc_5: 0.8692\n",
      "Epoch 84/300\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0554 - auc_5: 0.9800 - val_loss: 0.1003 - val_auc_5: 0.8492\n",
      "Epoch 85/300\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0544 - auc_5: 0.9813 - val_loss: 0.0971 - val_auc_5: 0.8305\n",
      "Epoch 86/300\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0537 - auc_5: 0.9818 - val_loss: 0.1124 - val_auc_5: 0.8682\n",
      "Epoch 87/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.0548 - auc_5: 0.9807 - val_loss: 0.0978 - val_auc_5: 0.8499\n",
      "Epoch 88/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.0525 - auc_5: 0.9825 - val_loss: 0.0968 - val_auc_5: 0.8313\n",
      "Epoch 89/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.0553 - auc_5: 0.9831 - val_loss: 0.1027 - val_auc_5: 0.8718\n",
      "Epoch 90/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.0524 - auc_5: 0.9810 - val_loss: 0.0949 - val_auc_5: 0.8338\n",
      "Epoch 91/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.0501 - auc_5: 0.9830 - val_loss: 0.1009 - val_auc_5: 0.8329\n",
      "Epoch 92/300\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0497 - auc_5: 0.9838 - val_loss: 0.0985 - val_auc_5: 0.8322\n",
      "Epoch 93/300\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0494 - auc_5: 0.9825 - val_loss: 0.1014 - val_auc_5: 0.8331\n",
      "Epoch 94/300\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0484 - auc_5: 0.9832 - val_loss: 0.0907 - val_auc_5: 0.8350\n",
      "Epoch 95/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.0478 - auc_5: 0.9835 - val_loss: 0.1006 - val_auc_5: 0.8326\n",
      "Epoch 96/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.0473 - auc_5: 0.9848 - val_loss: 0.1057 - val_auc_5: 0.8327\n",
      "Epoch 97/300\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0465 - auc_5: 0.9843 - val_loss: 0.0921 - val_auc_5: 0.8356\n",
      "Epoch 98/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.0457 - auc_5: 0.9845 - val_loss: 0.0908 - val_auc_5: 0.8360\n",
      "Epoch 99/300\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.0453 - auc_5: 0.9850 - val_loss: 0.0906 - val_auc_5: 0.8361\n",
      "Epoch 100/300\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0448 - auc_5: 0.9853 - val_loss: 0.0957 - val_auc_5: 0.8345\n",
      "Epoch 101/300\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.0447 - auc_5: 0.9850 - val_loss: 0.0925 - val_auc_5: 0.8358\n",
      "Epoch 102/300\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0438 - auc_5: 0.9855 - val_loss: 0.0970 - val_auc_5: 0.8351\n",
      "Epoch 103/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.0432 - auc_5: 0.9848 - val_loss: 0.0928 - val_auc_5: 0.8360\n",
      "Epoch 104/300\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0427 - auc_5: 0.9858 - val_loss: 0.0875 - val_auc_5: 0.8383\n",
      "Epoch 105/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.0423 - auc_5: 0.9855 - val_loss: 0.0903 - val_auc_5: 0.8374\n",
      "Epoch 106/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.0414 - auc_5: 0.9862 - val_loss: 0.0939 - val_auc_5: 0.8362\n",
      "Epoch 107/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.0409 - auc_5: 0.9865 - val_loss: 0.0865 - val_auc_5: 0.8393\n",
      "Epoch 108/300\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0405 - auc_5: 0.9872 - val_loss: 0.0950 - val_auc_5: 0.8367\n",
      "Epoch 109/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.0401 - auc_5: 0.9863 - val_loss: 0.0896 - val_auc_5: 0.8388\n",
      "Epoch 110/300\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0406 - auc_5: 0.9858 - val_loss: 0.0880 - val_auc_5: 0.8396\n",
      "Epoch 111/300\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0390 - auc_5: 0.9875 - val_loss: 0.0921 - val_auc_5: 0.8378\n",
      "Epoch 112/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.0389 - auc_5: 0.9867 - val_loss: 0.0963 - val_auc_5: 0.8372\n",
      "Epoch 113/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.0390 - auc_5: 0.9872 - val_loss: 0.0899 - val_auc_5: 0.8395\n",
      "Epoch 114/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.0378 - auc_5: 0.9868 - val_loss: 0.0871 - val_auc_5: 0.8406\n",
      "Epoch 115/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.0371 - auc_5: 0.9877 - val_loss: 0.0913 - val_auc_5: 0.8389\n",
      "Epoch 116/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.0365 - auc_5: 0.9877 - val_loss: 0.0821 - val_auc_5: 0.8419\n",
      "Epoch 117/300\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0366 - auc_5: 0.9872 - val_loss: 0.0800 - val_auc_5: 0.8421\n",
      "Epoch 118/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.0361 - auc_5: 0.9878 - val_loss: 0.0859 - val_auc_5: 0.8411\n",
      "Epoch 119/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.0353 - auc_5: 0.9877 - val_loss: 0.0835 - val_auc_5: 0.8423\n",
      "Epoch 120/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.0351 - auc_5: 0.9888 - val_loss: 0.0897 - val_auc_5: 0.8401\n",
      "Epoch 121/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.0348 - auc_5: 0.9882 - val_loss: 0.0857 - val_auc_5: 0.8422\n",
      "Epoch 122/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.0342 - auc_5: 0.9883 - val_loss: 0.0934 - val_auc_5: 0.8395\n",
      "Epoch 123/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.0365 - auc_5: 0.9870 - val_loss: 0.0905 - val_auc_5: 0.8403\n",
      "Epoch 124/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.0335 - auc_5: 0.9888 - val_loss: 0.0837 - val_auc_5: 0.8424\n",
      "Epoch 125/300\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0329 - auc_5: 0.9887 - val_loss: 0.0910 - val_auc_5: 0.8408\n",
      "Epoch 126/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 34ms/step - loss: 0.0324 - auc_5: 0.9890 - val_loss: 0.0898 - val_auc_5: 0.8412\n",
      "Epoch 127/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.0320 - auc_5: 0.9893 - val_loss: 0.0817 - val_auc_5: 0.8426\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6129 - auc_6: 0.5540 - val_loss: 0.4967 - val_auc_6: 0.6395\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.4587 - auc_6: 0.7170 - val_loss: 0.4092 - val_auc_6: 0.7232\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.3772 - auc_6: 0.7985 - val_loss: 0.3572 - val_auc_6: 0.7727\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.3288 - auc_6: 0.8302 - val_loss: 0.2958 - val_auc_6: 0.8074\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.2929 - auc_6: 0.8617 - val_loss: 0.2963 - val_auc_6: 0.8174\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.2661 - auc_6: 0.8749 - val_loss: 0.2682 - val_auc_6: 0.8332\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.2499 - auc_6: 0.8808 - val_loss: 0.2378 - val_auc_6: 0.8487\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.2341 - auc_6: 0.8980 - val_loss: 0.2205 - val_auc_6: 0.8622\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.2231 - auc_6: 0.9076 - val_loss: 0.2303 - val_auc_6: 0.8556\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.2137 - auc_6: 0.9115 - val_loss: 0.2188 - val_auc_6: 0.8647\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.2056 - auc_6: 0.9167 - val_loss: 0.2019 - val_auc_6: 0.8731\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1992 - auc_6: 0.9235 - val_loss: 0.2080 - val_auc_6: 0.8724\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1933 - auc_6: 0.9222 - val_loss: 0.2010 - val_auc_6: 0.8745\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.1880 - auc_6: 0.9312 - val_loss: 0.2006 - val_auc_6: 0.8768\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.1822 - auc_6: 0.9285 - val_loss: 0.1933 - val_auc_6: 0.8803\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1775 - auc_6: 0.9327 - val_loss: 0.1952 - val_auc_6: 0.8829\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1744 - auc_6: 0.9322 - val_loss: 0.1805 - val_auc_6: 0.8797\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1688 - auc_6: 0.9381 - val_loss: 0.1839 - val_auc_6: 0.8796\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.1661 - auc_6: 0.9364 - val_loss: 0.1813 - val_auc_6: 0.8805\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.1615 - auc_6: 0.9404 - val_loss: 0.1825 - val_auc_6: 0.8843\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.1596 - auc_6: 0.9387 - val_loss: 0.1996 - val_auc_6: 0.8817\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1548 - auc_6: 0.9410 - val_loss: 0.1778 - val_auc_6: 0.8696\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1513 - auc_6: 0.9439 - val_loss: 0.1643 - val_auc_6: 0.8715\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.1483 - auc_6: 0.9473 - val_loss: 0.1646 - val_auc_6: 0.8721\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1456 - auc_6: 0.9450 - val_loss: 0.1652 - val_auc_6: 0.8732\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1426 - auc_6: 0.9494 - val_loss: 0.1691 - val_auc_6: 0.8723\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1396 - auc_6: 0.9488 - val_loss: 0.1498 - val_auc_6: 0.8775\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1424 - auc_6: 0.9562 - val_loss: 0.1471 - val_auc_6: 0.8725\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1346 - auc_6: 0.9535 - val_loss: 0.1562 - val_auc_6: 0.8755\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1325 - auc_6: 0.9540 - val_loss: 0.1601 - val_auc_6: 0.8747\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.1299 - auc_6: 0.9545 - val_loss: 0.1420 - val_auc_6: 0.8727\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1317 - auc_6: 0.9569 - val_loss: 0.1467 - val_auc_6: 0.8693\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1260 - auc_6: 0.9572 - val_loss: 0.1497 - val_auc_6: 0.8722\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.1242 - auc_6: 0.9555 - val_loss: 0.1402 - val_auc_6: 0.8578\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1216 - auc_6: 0.9575 - val_loss: 0.1397 - val_auc_6: 0.8580\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1199 - auc_6: 0.9582 - val_loss: 0.1504 - val_auc_6: 0.8746\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1176 - auc_6: 0.9585 - val_loss: 0.1206 - val_auc_6: 0.8474\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1200 - auc_6: 0.9634 - val_loss: 0.1524 - val_auc_6: 0.8585\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1149 - auc_6: 0.9593 - val_loss: 0.1314 - val_auc_6: 0.8624\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1129 - auc_6: 0.9621 - val_loss: 0.1449 - val_auc_6: 0.8594\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1111 - auc_6: 0.9614 - val_loss: 0.1423 - val_auc_6: 0.8607\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1092 - auc_6: 0.9618 - val_loss: 0.1349 - val_auc_6: 0.8633\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.1077 - auc_6: 0.9618 - val_loss: 0.1366 - val_auc_6: 0.8635\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.1059 - auc_6: 0.9635 - val_loss: 0.1476 - val_auc_6: 0.8610\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1049 - auc_6: 0.9606 - val_loss: 0.1286 - val_auc_6: 0.8477\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.1029 - auc_6: 0.9630 - val_loss: 0.1337 - val_auc_6: 0.8659\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.1009 - auc_6: 0.9644 - val_loss: 0.1197 - val_auc_6: 0.8515\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.1023 - auc_6: 0.9674 - val_loss: 0.1333 - val_auc_6: 0.8638\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0988 - auc_6: 0.9640 - val_loss: 0.1296 - val_auc_6: 0.8465\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0967 - auc_6: 0.9661 - val_loss: 0.1344 - val_auc_6: 0.8457\n",
      "Epoch 51/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.0953 - auc_6: 0.9651 - val_loss: 0.1200 - val_auc_6: 0.8503\n",
      "Epoch 52/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.0938 - auc_6: 0.9671 - val_loss: 0.1438 - val_auc_6: 0.8645\n",
      "Epoch 53/300\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0970 - auc_6: 0.9619 - val_loss: 0.1197 - val_auc_6: 0.8495\n",
      "Epoch 54/300\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0916 - auc_6: 0.9645 - val_loss: 0.1201 - val_auc_6: 0.8507\n",
      "Epoch 55/300\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0895 - auc_6: 0.9688 - val_loss: 0.1235 - val_auc_6: 0.8499\n",
      "Epoch 56/300\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.0883 - auc_6: 0.9673 - val_loss: 0.1082 - val_auc_6: 0.8526\n",
      "Epoch 57/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.0870 - auc_6: 0.9683 - val_loss: 0.1123 - val_auc_6: 0.8515\n",
      "Epoch 58/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.0856 - auc_6: 0.9700 - val_loss: 0.1239 - val_auc_6: 0.8492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.0842 - auc_6: 0.9698 - val_loss: 0.1147 - val_auc_6: 0.8517\n",
      "Epoch 60/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.0833 - auc_6: 0.9700 - val_loss: 0.1180 - val_auc_6: 0.8516\n",
      "Epoch 61/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.0823 - auc_6: 0.9705 - val_loss: 0.1163 - val_auc_6: 0.8523\n",
      "Epoch 62/300\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0805 - auc_6: 0.9707 - val_loss: 0.1046 - val_auc_6: 0.8562\n",
      "Epoch 63/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.0794 - auc_6: 0.9722 - val_loss: 0.1151 - val_auc_6: 0.8525\n",
      "Epoch 64/300\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0784 - auc_6: 0.9724 - val_loss: 0.1238 - val_auc_6: 0.8509\n",
      "Epoch 65/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.0785 - auc_6: 0.9721 - val_loss: 0.1139 - val_auc_6: 0.8535\n",
      "Epoch 66/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.0759 - auc_6: 0.9723 - val_loss: 0.1114 - val_auc_6: 0.8538\n",
      "Epoch 67/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.0750 - auc_6: 0.9744 - val_loss: 0.1123 - val_auc_6: 0.8541\n",
      "Epoch 68/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.0736 - auc_6: 0.9741 - val_loss: 0.1102 - val_auc_6: 0.8548\n",
      "Epoch 69/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.0724 - auc_6: 0.9749 - val_loss: 0.1050 - val_auc_6: 0.8569\n",
      "Epoch 70/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.0714 - auc_6: 0.9754 - val_loss: 0.1138 - val_auc_6: 0.8549\n",
      "Epoch 71/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.0703 - auc_6: 0.9760 - val_loss: 0.1086 - val_auc_6: 0.8565\n",
      "Epoch 72/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.0692 - auc_6: 0.9761 - val_loss: 0.1063 - val_auc_6: 0.8574\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 3s 37ms/step - loss: 0.5929 - auc_7: 0.5836 - val_loss: 0.4513 - val_auc_7: 0.6686\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.4320 - auc_7: 0.7545 - val_loss: 0.3769 - val_auc_7: 0.7501\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.3485 - auc_7: 0.8189 - val_loss: 0.3094 - val_auc_7: 0.7866\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.3025 - auc_7: 0.8600 - val_loss: 0.3192 - val_auc_7: 0.7962\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.2735 - auc_7: 0.8674 - val_loss: 0.2555 - val_auc_7: 0.8216\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.2532 - auc_7: 0.8898 - val_loss: 0.2447 - val_auc_7: 0.8321\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.2369 - auc_7: 0.8968 - val_loss: 0.2589 - val_auc_7: 0.8393\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.2226 - auc_7: 0.9083 - val_loss: 0.2229 - val_auc_7: 0.8529\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.2115 - auc_7: 0.9140 - val_loss: 0.2015 - val_auc_7: 0.8605\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.2011 - auc_7: 0.9191 - val_loss: 0.2095 - val_auc_7: 0.8553\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1946 - auc_7: 0.9254 - val_loss: 0.1934 - val_auc_7: 0.8623\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1875 - auc_7: 0.9239 - val_loss: 0.2130 - val_auc_7: 0.8590\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1813 - auc_7: 0.9257 - val_loss: 0.2011 - val_auc_7: 0.8597\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1745 - auc_7: 0.9322 - val_loss: 0.2042 - val_auc_7: 0.8610\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1691 - auc_7: 0.9372 - val_loss: 0.1890 - val_auc_7: 0.8678\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1645 - auc_7: 0.9378 - val_loss: 0.1830 - val_auc_7: 0.8701\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1600 - auc_7: 0.9412 - val_loss: 0.1784 - val_auc_7: 0.8727\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1555 - auc_7: 0.9451 - val_loss: 0.1742 - val_auc_7: 0.8583\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1517 - auc_7: 0.9468 - val_loss: 0.1615 - val_auc_7: 0.8627\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.1512 - auc_7: 0.9503 - val_loss: 0.1639 - val_auc_7: 0.8617\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.1456 - auc_7: 0.9498 - val_loss: 0.1667 - val_auc_7: 0.8631\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1421 - auc_7: 0.9497 - val_loss: 0.1804 - val_auc_7: 0.8596\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1394 - auc_7: 0.9496 - val_loss: 0.1532 - val_auc_7: 0.8515\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1359 - auc_7: 0.9545 - val_loss: 0.1519 - val_auc_7: 0.8529\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.1329 - auc_7: 0.9554 - val_loss: 0.1537 - val_auc_7: 0.8543\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1307 - auc_7: 0.9555 - val_loss: 0.1492 - val_auc_7: 0.8540\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1287 - auc_7: 0.9543 - val_loss: 0.1479 - val_auc_7: 0.8525\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1249 - auc_7: 0.9572 - val_loss: 0.1460 - val_auc_7: 0.8574\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1223 - auc_7: 0.9586 - val_loss: 0.1535 - val_auc_7: 0.8563\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1196 - auc_7: 0.9585 - val_loss: 0.1619 - val_auc_7: 0.8550\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1283 - auc_7: 0.9502 - val_loss: 0.1519 - val_auc_7: 0.8422\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1151 - auc_7: 0.9586 - val_loss: 0.1246 - val_auc_7: 0.8475\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.1182 - auc_7: 0.9639 - val_loss: 0.1375 - val_auc_7: 0.8451\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.1113 - auc_7: 0.9631 - val_loss: 0.1333 - val_auc_7: 0.8471\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1100 - auc_7: 0.9656 - val_loss: 0.1438 - val_auc_7: 0.8458\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1081 - auc_7: 0.9637 - val_loss: 0.1382 - val_auc_7: 0.8472\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1056 - auc_7: 0.9650 - val_loss: 0.1273 - val_auc_7: 0.8496\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1038 - auc_7: 0.9659 - val_loss: 0.1293 - val_auc_7: 0.8500\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1020 - auc_7: 0.9661 - val_loss: 0.1291 - val_auc_7: 0.8508loss: 0.1020 - auc_7: 0.966\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1002 - auc_7: 0.9664 - val_loss: 0.1263 - val_auc_7: 0.8519\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.0987 - auc_7: 0.9674 - val_loss: 0.1308 - val_auc_7: 0.8514\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.0969 - auc_7: 0.9669 - val_loss: 0.1107 - val_auc_7: 0.8566\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1013 - auc_7: 0.9676 - val_loss: 0.1156 - val_auc_7: 0.8540\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0946 - auc_7: 0.9682 - val_loss: 0.1229 - val_auc_7: 0.8547\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.0924 - auc_7: 0.9687 - val_loss: 0.1179 - val_auc_7: 0.8550\n",
      "Epoch 46/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 27ms/step - loss: 0.0909 - auc_7: 0.9689 - val_loss: 0.1178 - val_auc_7: 0.8556\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.0892 - auc_7: 0.9698 - val_loss: 0.1242 - val_auc_7: 0.8552\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.0876 - auc_7: 0.9690 - val_loss: 0.1101 - val_auc_7: 0.8582\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0864 - auc_7: 0.9707 - val_loss: 0.1172 - val_auc_7: 0.8567\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.0848 - auc_7: 0.9704 - val_loss: 0.1210 - val_auc_7: 0.8577\n",
      "Epoch 51/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.0834 - auc_7: 0.9704 - val_loss: 0.1099 - val_auc_7: 0.8570\n",
      "Epoch 52/300\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0824 - auc_7: 0.9731 - val_loss: 0.1128 - val_auc_7: 0.8569\n",
      "Epoch 53/300\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0806 - auc_7: 0.9720 - val_loss: 0.1152 - val_auc_7: 0.8560\n",
      "Epoch 54/300\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0789 - auc_7: 0.9730 - val_loss: 0.1238 - val_auc_7: 0.8568\n",
      "Epoch 55/300\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0777 - auc_7: 0.9725 - val_loss: 0.1019 - val_auc_7: 0.8604\n",
      "Epoch 56/300\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0763 - auc_7: 0.9737 - val_loss: 0.1033 - val_auc_7: 0.8605\n",
      "Epoch 57/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.0751 - auc_7: 0.9736 - val_loss: 0.1096 - val_auc_7: 0.8591\n",
      "Epoch 58/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.0746 - auc_7: 0.9719 - val_loss: 0.1044 - val_auc_7: 0.8613\n",
      "Epoch 59/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.0723 - auc_7: 0.9756 - val_loss: 0.1081 - val_auc_7: 0.8599\n",
      "Epoch 60/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.0718 - auc_7: 0.9759 - val_loss: 0.1056 - val_auc_7: 0.8610\n",
      "Epoch 61/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.0696 - auc_7: 0.9758 - val_loss: 0.1110 - val_auc_7: 0.8593\n",
      "Epoch 62/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.0680 - auc_7: 0.9766 - val_loss: 0.1088 - val_auc_7: 0.8602\n",
      "Epoch 63/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.0673 - auc_7: 0.9759 - val_loss: 0.1060 - val_auc_7: 0.8612\n",
      "Epoch 64/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.0655 - auc_7: 0.9773 - val_loss: 0.1025 - val_auc_7: 0.8620\n",
      "Epoch 65/300\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0641 - auc_7: 0.9782 - val_loss: 0.0996 - val_auc_7: 0.8629\n",
      "Epoch 66/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.0628 - auc_7: 0.9785 - val_loss: 0.1150 - val_auc_7: 0.8597\n",
      "Epoch 67/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.0624 - auc_7: 0.9782 - val_loss: 0.1129 - val_auc_7: 0.8602\n",
      "Epoch 68/300\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0623 - auc_7: 0.9767 - val_loss: 0.1121 - val_auc_7: 0.8609\n",
      "Epoch 69/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.0604 - auc_7: 0.9788 - val_loss: 0.1002 - val_auc_7: 0.8643\n",
      "Epoch 70/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.0588 - auc_7: 0.9802 - val_loss: 0.0962 - val_auc_7: 0.8653\n",
      "Epoch 71/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.0607 - auc_7: 0.9802 - val_loss: 0.0859 - val_auc_7: 0.8653\n",
      "Epoch 72/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.0566 - auc_7: 0.9803 - val_loss: 0.0963 - val_auc_7: 0.8649\n",
      "Epoch 73/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.0554 - auc_7: 0.9803 - val_loss: 0.1050 - val_auc_7: 0.8631\n",
      "Epoch 74/300\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0541 - auc_7: 0.9800 - val_loss: 0.0920 - val_auc_7: 0.8673\n",
      "Epoch 75/300\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0528 - auc_7: 0.9812 - val_loss: 0.0919 - val_auc_7: 0.8675\n",
      "Epoch 76/300\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0518 - auc_7: 0.9812 - val_loss: 0.0940 - val_auc_7: 0.8672\n",
      "Epoch 77/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.0508 - auc_7: 0.9817 - val_loss: 0.0895 - val_auc_7: 0.8675: 0s - loss: 0.0479 - auc_7: 0.\n",
      "Epoch 78/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.0500 - auc_7: 0.9810 - val_loss: 0.0909 - val_auc_7: 0.8666\n",
      "Epoch 79/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.0491 - auc_7: 0.9823 - val_loss: 0.0826 - val_auc_7: 0.8684\n",
      "Epoch 80/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.0482 - auc_7: 0.9825 - val_loss: 0.0876 - val_auc_7: 0.8680\n",
      "Epoch 81/300\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.0471 - auc_7: 0.9828 - val_loss: 0.0858 - val_auc_7: 0.8685\n",
      "Epoch 82/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.0463 - auc_7: 0.9830 - val_loss: 0.0805 - val_auc_7: 0.8692\n",
      "Epoch 83/300\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0528 - auc_7: 0.9835 - val_loss: 0.0820 - val_auc_7: 0.8694\n",
      "Epoch 84/300\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0462 - auc_7: 0.9840 - val_loss: 0.0857 - val_auc_7: 0.8682\n",
      "Epoch 85/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.0441 - auc_7: 0.9835 - val_loss: 0.0912 - val_auc_7: 0.8687\n",
      "Epoch 86/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.0431 - auc_7: 0.9840 - val_loss: 0.0874 - val_auc_7: 0.8681\n",
      "Epoch 87/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.0424 - auc_7: 0.9843 - val_loss: 0.0887 - val_auc_7: 0.8692\n",
      "Epoch 88/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.0417 - auc_7: 0.9843 - val_loss: 0.0843 - val_auc_7: 0.8689\n",
      "Epoch 89/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.0409 - auc_7: 0.9847 - val_loss: 0.0883 - val_auc_7: 0.8694\n",
      "Epoch 90/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.0403 - auc_7: 0.9845 - val_loss: 0.0784 - val_auc_7: 0.8506\n",
      "Epoch 91/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.0399 - auc_7: 0.9852 - val_loss: 0.0821 - val_auc_7: 0.8496\n",
      "Epoch 92/300\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0390 - auc_7: 0.9843 - val_loss: 0.0891 - val_auc_7: 0.8690\n",
      "Epoch 93/300\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.0384 - auc_7: 0.9855 - val_loss: 0.0841 - val_auc_7: 0.8485\n",
      "Epoch 94/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.0378 - auc_7: 0.9855 - val_loss: 0.0881 - val_auc_7: 0.8700\n",
      "Epoch 95/300\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.0372 - auc_7: 0.9855 - val_loss: 0.0783 - val_auc_7: 0.8516\n",
      "Epoch 96/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.0385 - auc_7: 0.9870 - val_loss: 0.0844 - val_auc_7: 0.8493\n",
      "Epoch 97/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.0361 - auc_7: 0.9865 - val_loss: 0.0824 - val_auc_7: 0.8509\n",
      "Epoch 98/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.0351 - auc_7: 0.9863 - val_loss: 0.0766 - val_auc_7: 0.8529\n",
      "Epoch 99/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.0476 - auc_7: 0.9851 - val_loss: 0.0699 - val_auc_7: 0.8322\n",
      "Epoch 100/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.0353 - auc_7: 0.9875 - val_loss: 0.0798 - val_auc_7: 0.8522\n",
      "Epoch 101/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.0343 - auc_7: 0.9863 - val_loss: 0.0815 - val_auc_7: 0.8524\n",
      "Epoch 102/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.0334 - auc_7: 0.9872 - val_loss: 0.0838 - val_auc_7: 0.8521\n",
      "Epoch 103/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.0328 - auc_7: 0.9868 - val_loss: 0.0811 - val_auc_7: 0.8316\n",
      "Epoch 104/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.0327 - auc_7: 0.9872 - val_loss: 0.0865 - val_auc_7: 0.8523 0s - loss: 0.0347 - auc_7: \n",
      "Epoch 105/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 27ms/step - loss: 0.0331 - auc_7: 0.9872 - val_loss: 0.0782 - val_auc_7: 0.8333\n",
      "Epoch 106/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.0320 - auc_7: 0.9877 - val_loss: 0.0775 - val_auc_7: 0.8342\n",
      "Epoch 107/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.0310 - auc_7: 0.9873 - val_loss: 0.0785 - val_auc_7: 0.8339\n",
      "Epoch 108/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.0310 - auc_7: 0.9883 - val_loss: 0.0809 - val_auc_7: 0.8336\n",
      "Epoch 109/300\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0304 - auc_7: 0.9877 - val_loss: 0.0807 - val_auc_7: 0.8340\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6059 - auc_8: 0.5312 - val_loss: 0.5472 - val_auc_8: 0.6103\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.4459 - auc_8: 0.7150 - val_loss: 0.4183 - val_auc_8: 0.7333\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.3597 - auc_8: 0.8037 - val_loss: 0.3259 - val_auc_8: 0.7979\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.3076 - auc_8: 0.8583 - val_loss: 0.3250 - val_auc_8: 0.8145\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.2743 - auc_8: 0.8722 - val_loss: 0.2895 - val_auc_8: 0.8370\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.2506 - auc_8: 0.8940 - val_loss: 0.2635 - val_auc_8: 0.8541\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.2351 - auc_8: 0.9044 - val_loss: 0.2349 - val_auc_8: 0.8643\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.2227 - auc_8: 0.9094 - val_loss: 0.2317 - val_auc_8: 0.8688\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.2132 - auc_8: 0.9171 - val_loss: 0.2278 - val_auc_8: 0.8733\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.2053 - auc_8: 0.9211 - val_loss: 0.1995 - val_auc_8: 0.8747\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.1991 - auc_8: 0.9278 - val_loss: 0.2054 - val_auc_8: 0.8759\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1927 - auc_8: 0.9270 - val_loss: 0.2016 - val_auc_8: 0.8794\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1876 - auc_8: 0.9305 - val_loss: 0.1859 - val_auc_8: 0.8873\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1820 - auc_8: 0.9357 - val_loss: 0.1873 - val_auc_8: 0.8848\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1774 - auc_8: 0.9375 - val_loss: 0.2006 - val_auc_8: 0.8859\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.1733 - auc_8: 0.9404 - val_loss: 0.1862 - val_auc_8: 0.8891\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1687 - auc_8: 0.9420 - val_loss: 0.2010 - val_auc_8: 0.8880\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1652 - auc_8: 0.9428 - val_loss: 0.1994 - val_auc_8: 0.8885\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1614 - auc_8: 0.9446 - val_loss: 0.1813 - val_auc_8: 0.8954\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.1575 - auc_8: 0.9463 - val_loss: 0.1574 - val_auc_8: 0.8979\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 0.1547 - auc_8: 0.9493 - val_loss: 0.1621 - val_auc_8: 0.8970\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 0.1508 - auc_8: 0.9500 - val_loss: 0.1530 - val_auc_8: 0.9009\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.1474 - auc_8: 0.9512 - val_loss: 0.1724 - val_auc_8: 0.8978\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.1443 - auc_8: 0.9523 - val_loss: 0.1689 - val_auc_8: 0.8984\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.1415 - auc_8: 0.9539 - val_loss: 0.1679 - val_auc_8: 0.8991\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.1397 - auc_8: 0.9527 - val_loss: 0.1745 - val_auc_8: 0.9000\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.1390 - auc_8: 0.9528 - val_loss: 0.1805 - val_auc_8: 0.8996\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.1334 - auc_8: 0.9549 - val_loss: 0.1634 - val_auc_8: 0.9017\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1307 - auc_8: 0.9567 - val_loss: 0.1549 - val_auc_8: 0.9062\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1286 - auc_8: 0.9584 - val_loss: 0.1722 - val_auc_8: 0.9019\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1264 - auc_8: 0.9590 - val_loss: 0.1433 - val_auc_8: 0.9062\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.1236 - auc_8: 0.9611 - val_loss: 0.1609 - val_auc_8: 0.9054\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.1217 - auc_8: 0.9606 - val_loss: 0.1427 - val_auc_8: 0.9046\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.1218 - auc_8: 0.9638 - val_loss: 0.1328 - val_auc_8: 0.9043\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1237 - auc_8: 0.9616 - val_loss: 0.1139 - val_auc_8: 0.9109\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.1212 - auc_8: 0.9641 - val_loss: 0.1386 - val_auc_8: 0.9038\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1148 - auc_8: 0.9632 - val_loss: 0.1582 - val_auc_8: 0.9046\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.1130 - auc_8: 0.9626 - val_loss: 0.1449 - val_auc_8: 0.9037\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1125 - auc_8: 0.9627 - val_loss: 0.1441 - val_auc_8: 0.9080\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 0.1098 - auc_8: 0.9647 - val_loss: 0.1391 - val_auc_8: 0.9072\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1093 - auc_8: 0.9651 - val_loss: 0.1550 - val_auc_8: 0.9057\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1082 - auc_8: 0.9641 - val_loss: 0.1343 - val_auc_8: 0.9107\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1060 - auc_8: 0.9657 - val_loss: 0.1456 - val_auc_8: 0.9074\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1056 - auc_8: 0.9646 - val_loss: 0.1460 - val_auc_8: 0.9078\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1039 - auc_8: 0.9662 - val_loss: 0.1525 - val_auc_8: 0.9062\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.6272 - auc_9: 0.5393 - val_loss: 0.5277 - val_auc_9: 0.6166\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.4504 - auc_9: 0.7102 - val_loss: 0.3939 - val_auc_9: 0.7408\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.3588 - auc_9: 0.8094 - val_loss: 0.3189 - val_auc_9: 0.8024\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.3091 - auc_9: 0.8491 - val_loss: 0.2812 - val_auc_9: 0.8280\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 0.2769 - auc_9: 0.8677 - val_loss: 0.2420 - val_auc_9: 0.8472\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.2554 - auc_9: 0.8898 - val_loss: 0.2416 - val_auc_9: 0.85300s - loss: 0.2575 - auc_9: 0.8\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.2400 - auc_9: 0.9033 - val_loss: 0.2280 - val_auc_9: 0.8473\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.2301 - auc_9: 0.9121 - val_loss: 0.2144 - val_auc_9: 0.8546\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.2183 - auc_9: 0.9164 - val_loss: 0.2382 - val_auc_9: 0.8570\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 0.2102 - auc_9: 0.9155 - val_loss: 0.1876 - val_auc_9: 0.8651\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.2081 - auc_9: 0.9281 - val_loss: 0.2255 - val_auc_9: 0.8563\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.1992 - auc_9: 0.9231 - val_loss: 0.2016 - val_auc_9: 0.8619\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.1934 - auc_9: 0.9283 - val_loss: 0.1898 - val_auc_9: 0.8649\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.1898 - auc_9: 0.9327 - val_loss: 0.1900 - val_auc_9: 0.8688\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.1847 - auc_9: 0.9352 - val_loss: 0.2068 - val_auc_9: 0.8645\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.1808 - auc_9: 0.9368 - val_loss: 0.2097 - val_auc_9: 0.8649\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 0.1771 - auc_9: 0.9374 - val_loss: 0.2014 - val_auc_9: 0.8676\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1750 - auc_9: 0.9356 - val_loss: 0.1852 - val_auc_9: 0.8695\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1698 - auc_9: 0.9399 - val_loss: 0.1729 - val_auc_9: 0.8743\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1668 - auc_9: 0.9424 - val_loss: 0.1978 - val_auc_9: 0.8696\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1671 - auc_9: 0.9389 - val_loss: 0.1995 - val_auc_9: 0.8680\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1607 - auc_9: 0.9429 - val_loss: 0.1715 - val_auc_9: 0.8747\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.1574 - auc_9: 0.9459 - val_loss: 0.1838 - val_auc_9: 0.8731\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1540 - auc_9: 0.9478 - val_loss: 0.1827 - val_auc_9: 0.8745\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1514 - auc_9: 0.9483 - val_loss: 0.1615 - val_auc_9: 0.8771\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.1489 - auc_9: 0.9500 - val_loss: 0.1779 - val_auc_9: 0.8765\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1464 - auc_9: 0.9489 - val_loss: 0.1751 - val_auc_9: 0.8759\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.1431 - auc_9: 0.9515 - val_loss: 0.1608 - val_auc_9: 0.8810\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1405 - auc_9: 0.9528 - val_loss: 0.1714 - val_auc_9: 0.8773\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1423 - auc_9: 0.9477 - val_loss: 0.1701 - val_auc_9: 0.8789\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1349 - auc_9: 0.9537 - val_loss: 0.1676 - val_auc_9: 0.8630\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.1333 - auc_9: 0.9548 - val_loss: 0.1627 - val_auc_9: 0.8644\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1296 - auc_9: 0.9562 - val_loss: 0.1564 - val_auc_9: 0.8641\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1271 - auc_9: 0.9595 - val_loss: 0.1622 - val_auc_9: 0.8642\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1248 - auc_9: 0.9576 - val_loss: 0.1453 - val_auc_9: 0.8683\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1226 - auc_9: 0.9576 - val_loss: 0.1467 - val_auc_9: 0.8669\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.1279 - auc_9: 0.9604 - val_loss: 0.1375 - val_auc_9: 0.8720\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.1185 - auc_9: 0.9606 - val_loss: 0.1404 - val_auc_9: 0.8729\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1159 - auc_9: 0.9599 - val_loss: 0.1298 - val_auc_9: 0.8415\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.1139 - auc_9: 0.9615 - val_loss: 0.1319 - val_auc_9: 0.8420\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.1116 - auc_9: 0.9618 - val_loss: 0.1352 - val_auc_9: 0.8408\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.1102 - auc_9: 0.9635 - val_loss: 0.1304 - val_auc_9: 0.8431\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1077 - auc_9: 0.9647 - val_loss: 0.1407 - val_auc_9: 0.8415\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1060 - auc_9: 0.9630 - val_loss: 0.1488 - val_auc_9: 0.8427\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1049 - auc_9: 0.9631 - val_loss: 0.1319 - val_auc_9: 0.8440\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1019 - auc_9: 0.9660 - val_loss: 0.1135 - val_auc_9: 0.8471\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1004 - auc_9: 0.9668 - val_loss: 0.1462 - val_auc_9: 0.8445\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1012 - auc_9: 0.9637 - val_loss: 0.1357 - val_auc_9: 0.8457\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.0961 - auc_9: 0.9661 - val_loss: 0.1204 - val_auc_9: 0.8470\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.0949 - auc_9: 0.9679 - val_loss: 0.1323 - val_auc_9: 0.8456\n",
      "Epoch 51/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.0931 - auc_9: 0.9684 - val_loss: 0.1260 - val_auc_9: 0.8466\n",
      "Epoch 52/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.0952 - auc_9: 0.9703 - val_loss: 0.1075 - val_auc_9: 0.8513\n",
      "Epoch 53/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.0967 - auc_9: 0.9714 - val_loss: 0.1182 - val_auc_9: 0.8501\n",
      "Epoch 54/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.0885 - auc_9: 0.9697 - val_loss: 0.1269 - val_auc_9: 0.8477\n",
      "Epoch 55/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.0876 - auc_9: 0.9707 - val_loss: 0.1107 - val_auc_9: 0.8513\n",
      "Epoch 56/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.0857 - auc_9: 0.9698 - val_loss: 0.1218 - val_auc_9: 0.8493\n",
      "Epoch 57/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.0849 - auc_9: 0.9708 - val_loss: 0.1194 - val_auc_9: 0.8502\n",
      "Epoch 58/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.0832 - auc_9: 0.9720 - val_loss: 0.1328 - val_auc_9: 0.8483\n",
      "Epoch 59/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.0836 - auc_9: 0.9688 - val_loss: 0.1280 - val_auc_9: 0.8482\n",
      "Epoch 60/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.0810 - auc_9: 0.9733 - val_loss: 0.1229 - val_auc_9: 0.8514\n",
      "Epoch 61/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.0794 - auc_9: 0.9730 - val_loss: 0.1186 - val_auc_9: 0.8526\n",
      "Epoch 62/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.0794 - auc_9: 0.9727 - val_loss: 0.1097 - val_auc_9: 0.8543\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.6472 - auc_10: 0.5090 - val_loss: 0.5786 - val_auc_10: 0.5607\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.4768 - auc_10: 0.6778 - val_loss: 0.4349 - val_auc_10: 0.7440\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.3762 - auc_10: 0.7976 - val_loss: 0.3675 - val_auc_10: 0.7875\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.3234 - auc_10: 0.8457 - val_loss: 0.3070 - val_auc_10: 0.8144\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.2902 - auc_10: 0.8684 - val_loss: 0.2959 - val_auc_10: 0.8276\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.2675 - auc_10: 0.8811 - val_loss: 0.2565 - val_auc_10: 0.8477\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.2506 - auc_10: 0.8869 - val_loss: 0.2465 - val_auc_10: 0.8566\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.2370 - auc_10: 0.8973 - val_loss: 0.2477 - val_auc_10: 0.8599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.2264 - auc_10: 0.9063 - val_loss: 0.2274 - val_auc_10: 0.8637\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.2176 - auc_10: 0.9095 - val_loss: 0.2160 - val_auc_10: 0.8662\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.2102 - auc_10: 0.9217 - val_loss: 0.2314 - val_auc_10: 0.8673\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.2033 - auc_10: 0.9209 - val_loss: 0.2177 - val_auc_10: 0.8686\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1987 - auc_10: 0.9186 - val_loss: 0.2044 - val_auc_10: 0.8693\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1925 - auc_10: 0.9283 - val_loss: 0.2039 - val_auc_10: 0.8730\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1899 - auc_10: 0.9324 - val_loss: 0.2126 - val_auc_10: 0.8717\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1843 - auc_10: 0.9311 - val_loss: 0.1854 - val_auc_10: 0.8770\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1811 - auc_10: 0.9376 - val_loss: 0.2035 - val_auc_10: 0.8783\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1770 - auc_10: 0.9367 - val_loss: 0.1996 - val_auc_10: 0.8771\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1736 - auc_10: 0.9363 - val_loss: 0.1773 - val_auc_10: 0.8754\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1712 - auc_10: 0.9421 - val_loss: 0.1939 - val_auc_10: 0.8808\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1682 - auc_10: 0.9401 - val_loss: 0.1689 - val_auc_10: 0.8775\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1650 - auc_10: 0.9402 - val_loss: 0.1749 - val_auc_10: 0.8772\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1620 - auc_10: 0.9426 - val_loss: 0.1784 - val_auc_10: 0.8782\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1590 - auc_10: 0.9447 - val_loss: 0.2036 - val_auc_10: 0.8810\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1583 - auc_10: 0.9412 - val_loss: 0.1825 - val_auc_10: 0.8777\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1534 - auc_10: 0.9460 - val_loss: 0.1693 - val_auc_10: 0.8798\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1516 - auc_10: 0.9460 - val_loss: 0.1841 - val_auc_10: 0.8844\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1481 - auc_10: 0.9456 - val_loss: 0.1755 - val_auc_10: 0.8820\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1456 - auc_10: 0.9487 - val_loss: 0.1649 - val_auc_10: 0.8820\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1429 - auc_10: 0.9513 - val_loss: 0.1724 - val_auc_10: 0.8809\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1405 - auc_10: 0.9511 - val_loss: 0.1776 - val_auc_10: 0.8804\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1378 - auc_10: 0.9514 - val_loss: 0.1581 - val_auc_10: 0.8833\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1355 - auc_10: 0.9522 - val_loss: 0.1504 - val_auc_10: 0.8859\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1332 - auc_10: 0.9539 - val_loss: 0.1589 - val_auc_10: 0.8847\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1310 - auc_10: 0.9555 - val_loss: 0.1560 - val_auc_10: 0.8869\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1293 - auc_10: 0.9565 - val_loss: 0.1422 - val_auc_10: 0.8734\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1264 - auc_10: 0.9565 - val_loss: 0.1614 - val_auc_10: 0.8887\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1249 - auc_10: 0.9561 - val_loss: 0.1626 - val_auc_10: 0.8902\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1219 - auc_10: 0.9584 - val_loss: 0.1658 - val_auc_10: 0.8892\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1197 - auc_10: 0.9585 - val_loss: 0.1732 - val_auc_10: 0.8884\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.1188 - auc_10: 0.9569 - val_loss: 0.1312 - val_auc_10: 0.8442\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1168 - auc_10: 0.9611 - val_loss: 0.1370 - val_auc_10: 0.8435\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1140 - auc_10: 0.9616 - val_loss: 0.1456 - val_auc_10: 0.8423\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1124 - auc_10: 0.9606 - val_loss: 0.1454 - val_auc_10: 0.8447\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1100 - auc_10: 0.9613 - val_loss: 0.1430 - val_auc_10: 0.8438\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1082 - auc_10: 0.9623 - val_loss: 0.1533 - val_auc_10: 0.8439 0s - loss: 0.1082 - auc_10: 0.96\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1066 - auc_10: 0.9632 - val_loss: 0.1562 - val_auc_10: 0.8466\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1046 - auc_10: 0.9630 - val_loss: 0.1392 - val_auc_10: 0.8461\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1030 - auc_10: 0.9631 - val_loss: 0.1466 - val_auc_10: 0.8451\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1024 - auc_10: 0.9624 - val_loss: 0.1438 - val_auc_10: 0.8458\n",
      "Epoch 51/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.0992 - auc_10: 0.9649 - val_loss: 0.1173 - val_auc_10: 0.8536\n",
      "Epoch 52/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.0983 - auc_10: 0.9656 - val_loss: 0.1145 - val_auc_10: 0.8547\n",
      "Epoch 53/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1004 - auc_10: 0.9665 - val_loss: 0.1147 - val_auc_10: 0.8542\n",
      "Epoch 54/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.0958 - auc_10: 0.9680 - val_loss: 0.1256 - val_auc_10: 0.8524\n",
      "Epoch 55/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.0937 - auc_10: 0.9681 - val_loss: 0.1267 - val_auc_10: 0.8527\n",
      "Epoch 56/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.0919 - auc_10: 0.9669 - val_loss: 0.1301 - val_auc_10: 0.8526\n",
      "Epoch 57/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.0904 - auc_10: 0.9673 - val_loss: 0.1295 - val_auc_10: 0.8530\n",
      "Epoch 58/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.0892 - auc_10: 0.9678 - val_loss: 0.1147 - val_auc_10: 0.8570\n",
      "Epoch 59/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.0912 - auc_10: 0.9700 - val_loss: 0.1131 - val_auc_10: 0.8587\n",
      "Epoch 60/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.0869 - auc_10: 0.9693 - val_loss: 0.1258 - val_auc_10: 0.8553\n",
      "Epoch 61/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.0870 - auc_10: 0.9675 - val_loss: 0.1319 - val_auc_10: 0.8530\n",
      "Epoch 62/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.0846 - auc_10: 0.9702 - val_loss: 0.1307 - val_auc_10: 0.8546\n",
      "Epoch 63/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.0836 - auc_10: 0.9697 - val_loss: 0.1275 - val_auc_10: 0.8556\n",
      "Epoch 64/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.0815 - auc_10: 0.9707 - val_loss: 0.1159 - val_auc_10: 0.8594\n",
      "Epoch 65/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.0807 - auc_10: 0.9720 - val_loss: 0.1191 - val_auc_10: 0.8588\n",
      "Epoch 66/300\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0792 - auc_10: 0.9720 - val_loss: 0.1232 - val_auc_10: 0.8572\n",
      "Epoch 67/300\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0787 - auc_10: 0.9707 - val_loss: 0.1151 - val_auc_10: 0.8615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.0771 - auc_10: 0.9727 - val_loss: 0.1285 - val_auc_10: 0.8573\n",
      "Epoch 69/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.0761 - auc_10: 0.9735 - val_loss: 0.1203 - val_auc_10: 0.8602\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 2s 34ms/step - loss: 0.6410 - auc_11: 0.5163 - val_loss: 0.5129 - val_auc_11: 0.5816s - loss: 0.6674 - auc_11\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.4773 - auc_11: 0.6792 - val_loss: 0.3707 - val_auc_11: 0.7735\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.3887 - auc_11: 0.7907 - val_loss: 0.3307 - val_auc_11: 0.8213\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.3448 - auc_11: 0.8359 - val_loss: 0.3028 - val_auc_11: 0.8496\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.3169 - auc_11: 0.8487 - val_loss: 0.2975 - val_auc_11: 0.8558\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.2978 - auc_11: 0.8628 - val_loss: 0.2458 - val_auc_11: 0.8877\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.2840 - auc_11: 0.8764 - val_loss: 0.2446 - val_auc_11: 0.8888\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.2699 - auc_11: 0.8844 - val_loss: 0.2130 - val_auc_11: 0.9059\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.2594 - auc_11: 0.8947 - val_loss: 0.2237 - val_auc_11: 0.9028\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.2480 - auc_11: 0.8978 - val_loss: 0.2193 - val_auc_11: 0.9068\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.2387 - auc_11: 0.9006 - val_loss: 0.1934 - val_auc_11: 0.9220\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.2308 - auc_11: 0.9093 - val_loss: 0.2171 - val_auc_11: 0.9106\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.2236 - auc_11: 0.9096 - val_loss: 0.2084 - val_auc_11: 0.9151\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.2165 - auc_11: 0.9165 - val_loss: 0.2034 - val_auc_11: 0.9204\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.2107 - auc_11: 0.9208 - val_loss: 0.1962 - val_auc_11: 0.9252\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.2049 - auc_11: 0.9202 - val_loss: 0.1915 - val_auc_11: 0.9284\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1989 - auc_11: 0.9248 - val_loss: 0.1853 - val_auc_11: 0.9319\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1937 - auc_11: 0.9296 - val_loss: 0.1877 - val_auc_11: 0.9306\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1896 - auc_11: 0.9272 - val_loss: 0.1881 - val_auc_11: 0.9304\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1835 - auc_11: 0.9344 - val_loss: 0.1988 - val_auc_11: 0.9271\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1797 - auc_11: 0.9328 - val_loss: 0.1861 - val_auc_11: 0.9333\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.1755 - auc_11: 0.9372 - val_loss: 0.1611 - val_auc_11: 0.9448\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1709 - auc_11: 0.9383 - val_loss: 0.1797 - val_auc_11: 0.9368 0s - loss: 0.1717 - auc_11: 0.\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1672 - auc_11: 0.9379 - val_loss: 0.1584 - val_auc_11: 0.9467\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.1635 - auc_11: 0.9433 - val_loss: 0.1488 - val_auc_11: 0.9518\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.1594 - auc_11: 0.9429 - val_loss: 0.1372 - val_auc_11: 0.9540\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1589 - auc_11: 0.9463 - val_loss: 0.1369 - val_auc_11: 0.9545\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1532 - auc_11: 0.9465 - val_loss: 0.1352 - val_auc_11: 0.9545\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1498 - auc_11: 0.9494 - val_loss: 0.1471 - val_auc_11: 0.9506\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1464 - auc_11: 0.9485 - val_loss: 0.1562 - val_auc_11: 0.9506\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1444 - auc_11: 0.9523 - val_loss: 0.1634 - val_auc_11: 0.9475\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1407 - auc_11: 0.9500 - val_loss: 0.1522 - val_auc_11: 0.9499\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1372 - auc_11: 0.9533 - val_loss: 0.1510 - val_auc_11: 0.9499\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1354 - auc_11: 0.9518 - val_loss: 0.1414 - val_auc_11: 0.9531\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1320 - auc_11: 0.9547 - val_loss: 0.1453 - val_auc_11: 0.9517\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1297 - auc_11: 0.9544 - val_loss: 0.1374 - val_auc_11: 0.9542\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1272 - auc_11: 0.9553 - val_loss: 0.1315 - val_auc_11: 0.9557\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1244 - auc_11: 0.9582 - val_loss: 0.1359 - val_auc_11: 0.9542\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1222 - auc_11: 0.9581 - val_loss: 0.1427 - val_auc_11: 0.9524\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1201 - auc_11: 0.9576 - val_loss: 0.1209 - val_auc_11: 0.9588\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.1177 - auc_11: 0.9611 - val_loss: 0.1252 - val_auc_11: 0.9575\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.1154 - auc_11: 0.9615 - val_loss: 0.1202 - val_auc_11: 0.9564\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1143 - auc_11: 0.9616 - val_loss: 0.1329 - val_auc_11: 0.9526\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1112 - auc_11: 0.9618 - val_loss: 0.1109 - val_auc_11: 0.9573\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1091 - auc_11: 0.9628 - val_loss: 0.1060 - val_auc_11: 0.9583\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1138 - auc_11: 0.9665 - val_loss: 0.1130 - val_auc_11: 0.9543\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.1059 - auc_11: 0.9650 - val_loss: 0.1186 - val_auc_11: 0.9527\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.1037 - auc_11: 0.9643 - val_loss: 0.1166 - val_auc_11: 0.9531\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1016 - auc_11: 0.9650 - val_loss: 0.1127 - val_auc_11: 0.9542\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.0996 - auc_11: 0.9660 - val_loss: 0.1054 - val_auc_11: 0.9557\n",
      "Epoch 51/300\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.1001 - auc_11: 0.9692 - val_loss: 0.1032 - val_auc_11: 0.9518\n",
      "Epoch 52/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.0964 - auc_11: 0.9672 - val_loss: 0.1214 - val_auc_11: 0.9493\n",
      "Epoch 53/300\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0949 - auc_11: 0.9683 - val_loss: 0.1081 - val_auc_11: 0.9506\n",
      "Epoch 54/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.0933 - auc_11: 0.9682 - val_loss: 0.1106 - val_auc_11: 0.9496\n",
      "Epoch 55/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.0914 - auc_11: 0.9693 - val_loss: 0.1081 - val_auc_11: 0.9497\n",
      "Epoch 56/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.0900 - auc_11: 0.9688 - val_loss: 0.1003 - val_auc_11: 0.9516\n",
      "Epoch 57/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 28ms/step - loss: 0.0888 - auc_11: 0.9700 - val_loss: 0.1071 - val_auc_11: 0.9491\n",
      "Epoch 58/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.0869 - auc_11: 0.9702 - val_loss: 0.1067 - val_auc_11: 0.9484\n",
      "Epoch 59/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.0857 - auc_11: 0.9703 - val_loss: 0.1077 - val_auc_11: 0.9484\n",
      "Epoch 60/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.0842 - auc_11: 0.9710 - val_loss: 0.1025 - val_auc_11: 0.9478\n",
      "Epoch 61/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.0828 - auc_11: 0.9710 - val_loss: 0.1119 - val_auc_11: 0.9469\n",
      "Epoch 62/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.0813 - auc_11: 0.9718 - val_loss: 0.0968 - val_auc_11: 0.9491\n",
      "Epoch 63/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.0801 - auc_11: 0.9727 - val_loss: 0.0912 - val_auc_11: 0.9491\n",
      "Epoch 64/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.0799 - auc_11: 0.9732 - val_loss: 0.1038 - val_auc_11: 0.9475\n",
      "Epoch 65/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.0799 - auc_11: 0.9713 - val_loss: 0.0892 - val_auc_11: 0.9497\n",
      "Epoch 66/300\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0762 - auc_11: 0.9745 - val_loss: 0.0852 - val_auc_11: 0.9503\n",
      "Epoch 67/300\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0752 - auc_11: 0.9745 - val_loss: 0.1000 - val_auc_11: 0.9467\n",
      "Epoch 68/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.0736 - auc_11: 0.9747 - val_loss: 0.0822 - val_auc_11: 0.9503\n",
      "Epoch 69/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.0739 - auc_11: 0.9755 - val_loss: 0.0825 - val_auc_11: 0.9502\n",
      "Epoch 70/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.0713 - auc_11: 0.9748 - val_loss: 0.0869 - val_auc_11: 0.9488\n",
      "Epoch 71/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.0697 - auc_11: 0.9762 - val_loss: 0.0919 - val_auc_11: 0.9470\n",
      "Epoch 72/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.0690 - auc_11: 0.9757 - val_loss: 0.0819 - val_auc_11: 0.9497\n",
      "Epoch 73/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.0701 - auc_11: 0.9775 - val_loss: 0.0828 - val_auc_11: 0.9504\n",
      "Epoch 74/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.0666 - auc_11: 0.9765 - val_loss: 0.0862 - val_auc_11: 0.9488\n",
      "Epoch 75/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.0654 - auc_11: 0.9778 - val_loss: 0.0867 - val_auc_11: 0.9282\n",
      "Epoch 76/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.0647 - auc_11: 0.9778 - val_loss: 0.0881 - val_auc_11: 0.9272\n",
      "Epoch 77/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.0635 - auc_11: 0.9780 - val_loss: 0.0900 - val_auc_11: 0.9257\n",
      "Epoch 78/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.0633 - auc_11: 0.9768 - val_loss: 0.0798 - val_auc_11: 0.9283\n",
      "Epoch 79/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.0615 - auc_11: 0.9792 - val_loss: 0.0898 - val_auc_11: 0.9267\n",
      "Epoch 80/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.0624 - auc_11: 0.9780 - val_loss: 0.0879 - val_auc_11: 0.9271\n",
      "Epoch 81/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.0596 - auc_11: 0.9787 - val_loss: 0.0903 - val_auc_11: 0.9261\n",
      "Epoch 82/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.0591 - auc_11: 0.9793 - val_loss: 0.0929 - val_auc_11: 0.9258\n",
      "Epoch 83/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.0586 - auc_11: 0.9788 - val_loss: 0.0792 - val_auc_11: 0.9277\n",
      "Epoch 84/300\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0566 - auc_11: 0.9800 - val_loss: 0.0797 - val_auc_11: 0.9278\n",
      "Epoch 85/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.0559 - auc_11: 0.9807 - val_loss: 0.0775 - val_auc_11: 0.9277\n",
      "Epoch 86/300\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0554 - auc_11: 0.9808 - val_loss: 0.0791 - val_auc_11: 0.9282loss: 0.0557 - \n",
      "Epoch 87/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.0542 - auc_11: 0.9815 - val_loss: 0.0891 - val_auc_11: 0.9247\n",
      "Epoch 88/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.0534 - auc_11: 0.9810 - val_loss: 0.0746 - val_auc_11: 0.9079\n",
      "Epoch 89/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.0527 - auc_11: 0.9808 - val_loss: 0.0807 - val_auc_11: 0.9266\n",
      "Epoch 90/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.0522 - auc_11: 0.9813 - val_loss: 0.0815 - val_auc_11: 0.9073\n",
      "Epoch 91/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.0514 - auc_11: 0.9810 - val_loss: 0.0788 - val_auc_11: 0.9059\n",
      "Epoch 92/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.0520 - auc_11: 0.9803 - val_loss: 0.0796 - val_auc_11: 0.9056\n",
      "Epoch 93/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.0496 - auc_11: 0.9823 - val_loss: 0.0756 - val_auc_11: 0.9071\n",
      "Epoch 94/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.0488 - auc_11: 0.9822 - val_loss: 0.0778 - val_auc_11: 0.9075\n",
      "Epoch 95/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.0483 - auc_11: 0.9818 - val_loss: 0.0694 - val_auc_11: 0.9095\n",
      "Epoch 96/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.0475 - auc_11: 0.9822 - val_loss: 0.0719 - val_auc_11: 0.9088\n",
      "Epoch 97/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.0469 - auc_11: 0.9832 - val_loss: 0.0607 - val_auc_11: 0.8714\n",
      "Epoch 98/300\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0569 - auc_11: 0.9828 - val_loss: 0.0641 - val_auc_11: 0.8906\n",
      "Epoch 99/300\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0467 - auc_11: 0.9832 - val_loss: 0.0829 - val_auc_11: 0.9057\n",
      "Epoch 100/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.0461 - auc_11: 0.9820 - val_loss: 0.0843 - val_auc_11: 0.9055\n",
      "Epoch 101/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.0451 - auc_11: 0.9832 - val_loss: 0.0754 - val_auc_11: 0.8880\n",
      "Epoch 102/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.0437 - auc_11: 0.9842 - val_loss: 0.0699 - val_auc_11: 0.8902\n",
      "Epoch 103/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.0432 - auc_11: 0.9848 - val_loss: 0.0677 - val_auc_11: 0.8906\n",
      "Epoch 104/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.0444 - auc_11: 0.9848 - val_loss: 0.0692 - val_auc_11: 0.8696\n",
      "Epoch 105/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.0422 - auc_11: 0.9850 - val_loss: 0.0738 - val_auc_11: 0.8900\n",
      "Epoch 106/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.0417 - auc_11: 0.9847 - val_loss: 0.0689 - val_auc_11: 0.8707\n",
      "Epoch 107/300\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0412 - auc_11: 0.9848 - val_loss: 0.0710 - val_auc_11: 0.8907\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.5739 - auc_12: 0.5771 - val_loss: 0.4419 - val_auc_12: 0.6854\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.4507 - auc_12: 0.7466 - val_loss: 0.3868 - val_auc_12: 0.7714\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.3876 - auc_12: 0.8073 - val_loss: 0.3462 - val_auc_12: 0.8072\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.3512 - auc_12: 0.8230 - val_loss: 0.2830 - val_auc_12: 0.8365\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.3267 - auc_12: 0.8492 - val_loss: 0.3054 - val_auc_12: 0.8548\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.3094 - auc_12: 0.8586 - val_loss: 0.2711 - val_auc_12: 0.8702\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.2946 - auc_12: 0.8675 - val_loss: 0.2702 - val_auc_12: 0.8812\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.2827 - auc_12: 0.8796 - val_loss: 0.2325 - val_auc_12: 0.8971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.2740 - auc_12: 0.8865 - val_loss: 0.2247 - val_auc_12: 0.9030\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.2653 - auc_12: 0.8962 - val_loss: 0.2604 - val_auc_12: 0.8936\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.2594 - auc_12: 0.8914 - val_loss: 0.2453 - val_auc_12: 0.9019\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.2508 - auc_12: 0.9007 - val_loss: 0.2309 - val_auc_12: 0.9100\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.2450 - auc_12: 0.9040 - val_loss: 0.2404 - val_auc_12: 0.9064\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.2391 - auc_12: 0.9100 - val_loss: 0.2069 - val_auc_12: 0.9207\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.2340 - auc_12: 0.9133 - val_loss: 0.2260 - val_auc_12: 0.9145\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.2278 - auc_12: 0.9122 - val_loss: 0.1966 - val_auc_12: 0.9218\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.2231 - auc_12: 0.9148 - val_loss: 0.2030 - val_auc_12: 0.9195\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.2237 - auc_12: 0.9086 - val_loss: 0.2146 - val_auc_12: 0.9193\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.2137 - auc_12: 0.9186 - val_loss: 0.1860 - val_auc_12: 0.9303\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.2094 - auc_12: 0.9219 - val_loss: 0.1993 - val_auc_12: 0.9234\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.2052 - auc_12: 0.9188 - val_loss: 0.1883 - val_auc_12: 0.9293\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.2003 - auc_12: 0.9247 - val_loss: 0.2004 - val_auc_12: 0.9248\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.1978 - auc_12: 0.9258 - val_loss: 0.1793 - val_auc_12: 0.9382\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.1924 - auc_12: 0.9316 - val_loss: 0.1892 - val_auc_12: 0.9315\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.1888 - auc_12: 0.9294 - val_loss: 0.1801 - val_auc_12: 0.9358\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 0.1854 - auc_12: 0.9344 - val_loss: 0.1601 - val_auc_12: 0.9429\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1813 - auc_12: 0.9376 - val_loss: 0.1673 - val_auc_12: 0.9400\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.1782 - auc_12: 0.9412 - val_loss: 0.1575 - val_auc_12: 0.9436\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.1734 - auc_12: 0.9403 - val_loss: 0.1685 - val_auc_12: 0.9397\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.1702 - auc_12: 0.9410 - val_loss: 0.1627 - val_auc_12: 0.9416\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.1670 - auc_12: 0.9428 - val_loss: 0.1718 - val_auc_12: 0.9384\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.1651 - auc_12: 0.9461 - val_loss: 0.1681 - val_auc_12: 0.9404\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.1605 - auc_12: 0.9432 - val_loss: 0.1628 - val_auc_12: 0.9423\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.1573 - auc_12: 0.9455 - val_loss: 0.1589 - val_auc_12: 0.9441\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1545 - auc_12: 0.9474 - val_loss: 0.1617 - val_auc_12: 0.9429\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.1538 - auc_12: 0.9429 - val_loss: 0.1610 - val_auc_12: 0.9411\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.1500 - auc_12: 0.9446 - val_loss: 0.1598 - val_auc_12: 0.9424\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.1470 - auc_12: 0.9482 - val_loss: 0.1463 - val_auc_12: 0.9474\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.1435 - auc_12: 0.9514 - val_loss: 0.1253 - val_auc_12: 0.9493\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.1517 - auc_12: 0.9535 - val_loss: 0.1253 - val_auc_12: 0.9449\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.1398 - auc_12: 0.9535 - val_loss: 0.1631 - val_auc_12: 0.9385\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 0.1391 - auc_12: 0.9501 - val_loss: 0.1472 - val_auc_12: 0.9435\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.1355 - auc_12: 0.9537 - val_loss: 0.1468 - val_auc_12: 0.9448\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.1373 - auc_12: 0.9576 - val_loss: 0.1372 - val_auc_12: 0.9459\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 0.1351 - auc_12: 0.9544 - val_loss: 0.1567 - val_auc_12: 0.9438\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.1309 - auc_12: 0.9542 - val_loss: 0.1353 - val_auc_12: 0.9494\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 0.1288 - auc_12: 0.9567 - val_loss: 0.1392 - val_auc_12: 0.9487\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.1267 - auc_12: 0.9565 - val_loss: 0.1454 - val_auc_12: 0.9465\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.1256 - auc_12: 0.9563 - val_loss: 0.1369 - val_auc_12: 0.9458\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 0.1235 - auc_12: 0.9592 - val_loss: 0.1235 - val_auc_12: 0.9498\n",
      "Epoch 51/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.1220 - auc_12: 0.9595 - val_loss: 0.1333 - val_auc_12: 0.9463loss: 0.1226 - auc_12\n",
      "Epoch 52/300\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.1207 - auc_12: 0.9600 - val_loss: 0.1195 - val_auc_12: 0.9505\n",
      "Epoch 53/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1197 - auc_12: 0.9610 - val_loss: 0.1234 - val_auc_12: 0.9494\n",
      "Epoch 54/300\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.1176 - auc_12: 0.9604 - val_loss: 0.1332 - val_auc_12: 0.9459\n",
      "Epoch 55/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.1163 - auc_12: 0.9589 - val_loss: 0.1345 - val_auc_12: 0.9453\n",
      "Epoch 56/300\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.1146 - auc_12: 0.9616 - val_loss: 0.1314 - val_auc_12: 0.9457\n",
      "Epoch 57/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.1130 - auc_12: 0.9626 - val_loss: 0.1346 - val_auc_12: 0.9445\n",
      "Epoch 58/300\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.1118 - auc_12: 0.9621 - val_loss: 0.1234 - val_auc_12: 0.9469\n",
      "Epoch 59/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.1102 - auc_12: 0.9646 - val_loss: 0.1370 - val_auc_12: 0.9438\n",
      "Epoch 60/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1114 - auc_12: 0.9613 - val_loss: 0.1259 - val_auc_12: 0.9457\n",
      "Epoch 61/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1075 - auc_12: 0.9636 - val_loss: 0.1150 - val_auc_12: 0.9482\n",
      "Epoch 62/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1065 - auc_12: 0.9668 - val_loss: 0.1298 - val_auc_12: 0.9447\n",
      "Epoch 63/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1054 - auc_12: 0.9643 - val_loss: 0.1125 - val_auc_12: 0.9466\n",
      "Epoch 64/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1083 - auc_12: 0.9625 - val_loss: 0.1192 - val_auc_12: 0.9459\n",
      "Epoch 65/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1028 - auc_12: 0.9673 - val_loss: 0.1117 - val_auc_12: 0.9476\n",
      "Epoch 66/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1011 - auc_12: 0.9653 - val_loss: 0.1055 - val_auc_12: 0.9492\n",
      "Epoch 67/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1015 - auc_12: 0.9683 - val_loss: 0.1073 - val_auc_12: 0.9485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1001 - auc_12: 0.9671 - val_loss: 0.1132 - val_auc_12: 0.9474\n",
      "Epoch 69/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.0974 - auc_12: 0.9675 - val_loss: 0.1133 - val_auc_12: 0.9460\n",
      "Epoch 70/300\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0963 - auc_12: 0.9683 - val_loss: 0.1128 - val_auc_12: 0.9461\n",
      "Epoch 71/300\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0961 - auc_12: 0.9686 - val_loss: 0.1091 - val_auc_12: 0.9480\n",
      "Epoch 72/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.0941 - auc_12: 0.9686 - val_loss: 0.1211 - val_auc_12: 0.9439\n",
      "Epoch 73/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.0926 - auc_12: 0.9680 - val_loss: 0.1098 - val_auc_12: 0.9473\n",
      "Epoch 74/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.0915 - auc_12: 0.9698 - val_loss: 0.1148 - val_auc_12: 0.9455\n",
      "Epoch 75/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.0905 - auc_12: 0.9687 - val_loss: 0.1130 - val_auc_12: 0.9451\n",
      "Epoch 76/300\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0893 - auc_12: 0.9707 - val_loss: 0.1090 - val_auc_12: 0.9472\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.5806 - auc_13: 0.5673 - val_loss: 0.4557 - val_auc_13: 0.6855\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.4399 - auc_13: 0.7391 - val_loss: 0.3291 - val_auc_13: 0.8135\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.3642 - auc_13: 0.8161 - val_loss: 0.2767 - val_auc_13: 0.8567\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.3244 - auc_13: 0.8481 - val_loss: 0.2593 - val_auc_13: 0.8772\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.3006 - auc_13: 0.8632 - val_loss: 0.2440 - val_auc_13: 0.8922\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.2854 - auc_13: 0.8785 - val_loss: 0.2437 - val_auc_13: 0.8957\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.2728 - auc_13: 0.8872 - val_loss: 0.2349 - val_auc_13: 0.9017\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.2634 - auc_13: 0.8953 - val_loss: 0.2507 - val_auc_13: 0.8972\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.2547 - auc_13: 0.9009 - val_loss: 0.2392 - val_auc_13: 0.9026\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.2472 - auc_13: 0.9024 - val_loss: 0.2223 - val_auc_13: 0.9110\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.2397 - auc_13: 0.9063 - val_loss: 0.2011 - val_auc_13: 0.9216\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 0.2345 - auc_13: 0.9141 - val_loss: 0.2225 - val_auc_13: 0.9135\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.2271 - auc_13: 0.9117 - val_loss: 0.2165 - val_auc_13: 0.9171\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.2213 - auc_13: 0.9129 - val_loss: 0.2064 - val_auc_13: 0.9216\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.2151 - auc_13: 0.9165 - val_loss: 0.2381 - val_auc_13: 0.9092\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.2127 - auc_13: 0.9142 - val_loss: 0.1626 - val_auc_13: 0.9400\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.2062 - auc_13: 0.9245 - val_loss: 0.1767 - val_auc_13: 0.9347\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1999 - auc_13: 0.9227 - val_loss: 0.1752 - val_auc_13: 0.9358\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1956 - auc_13: 0.9294 - val_loss: 0.1761 - val_auc_13: 0.9360\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1905 - auc_13: 0.9308 - val_loss: 0.1821 - val_auc_13: 0.9341\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1860 - auc_13: 0.9313 - val_loss: 0.1738 - val_auc_13: 0.9372\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1856 - auc_13: 0.9357 - val_loss: 0.1856 - val_auc_13: 0.9310\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1779 - auc_13: 0.9338 - val_loss: 0.1834 - val_auc_13: 0.9331\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1746 - auc_13: 0.9323 - val_loss: 0.1847 - val_auc_13: 0.9333\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1693 - auc_13: 0.9387 - val_loss: 0.1793 - val_auc_13: 0.9367\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.1657 - auc_13: 0.9384 - val_loss: 0.1579 - val_auc_13: 0.9467\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1631 - auc_13: 0.9444 - val_loss: 0.1579 - val_auc_13: 0.9466\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1587 - auc_13: 0.9424 - val_loss: 0.1614 - val_auc_13: 0.9456\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1553 - auc_13: 0.9450 - val_loss: 0.1678 - val_auc_13: 0.9433\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.1516 - auc_13: 0.9456 - val_loss: 0.1511 - val_auc_13: 0.9487\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1487 - auc_13: 0.9489 - val_loss: 0.1538 - val_auc_13: 0.9491\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.1457 - auc_13: 0.9486 - val_loss: 0.1454 - val_auc_13: 0.9494\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.1415 - auc_13: 0.9516 - val_loss: 0.1337 - val_auc_13: 0.9540\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1393 - auc_13: 0.9526 - val_loss: 0.1487 - val_auc_13: 0.9488\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.1377 - auc_13: 0.9520 - val_loss: 0.1546 - val_auc_13: 0.9467\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1337 - auc_13: 0.9546 - val_loss: 0.1321 - val_auc_13: 0.9537\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1323 - auc_13: 0.9563 - val_loss: 0.1356 - val_auc_13: 0.9523\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1279 - auc_13: 0.9560 - val_loss: 0.1355 - val_auc_13: 0.9534\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1257 - auc_13: 0.9573 - val_loss: 0.1396 - val_auc_13: 0.9509\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1231 - auc_13: 0.9587 - val_loss: 0.1177 - val_auc_13: 0.9577\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1226 - auc_13: 0.9627 - val_loss: 0.1298 - val_auc_13: 0.9543\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1182 - auc_13: 0.9600 - val_loss: 0.1297 - val_auc_13: 0.9545\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1160 - auc_13: 0.9613 - val_loss: 0.1238 - val_auc_13: 0.9558\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1149 - auc_13: 0.9626 - val_loss: 0.1291 - val_auc_13: 0.9547\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1120 - auc_13: 0.9628 - val_loss: 0.1270 - val_auc_13: 0.9550\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.1099 - auc_13: 0.9632 - val_loss: 0.1207 - val_auc_13: 0.9545\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.1077 - auc_13: 0.9642 - val_loss: 0.1324 - val_auc_13: 0.9531 0s - loss: 0.1\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.1105 - auc_13: 0.9588 - val_loss: 0.1324 - val_auc_13: 0.9527\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1044 - auc_13: 0.9650 - val_loss: 0.1233 - val_auc_13: 0.9513\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1029 - auc_13: 0.9650 - val_loss: 0.1111 - val_auc_13: 0.9546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.1005 - auc_13: 0.9662 - val_loss: 0.1028 - val_auc_13: 0.9558\n",
      "Epoch 52/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.0988 - auc_13: 0.9665 - val_loss: 0.1177 - val_auc_13: 0.95240.0977 - auc_13: 0.\n",
      "Epoch 53/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.0973 - auc_13: 0.9675 - val_loss: 0.1215 - val_auc_13: 0.9510\n",
      "Epoch 54/300\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0955 - auc_13: 0.9650 - val_loss: 0.1141 - val_auc_13: 0.9528\n",
      "Epoch 55/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.0946 - auc_13: 0.9667 - val_loss: 0.1096 - val_auc_13: 0.9527 0s - loss: 0.0950 - auc_\n",
      "Epoch 56/300\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 0.0922 - auc_13: 0.9683 - val_loss: 0.1154 - val_auc_13: 0.9516\n",
      "Epoch 57/300\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 0.0907 - auc_13: 0.9687 - val_loss: 0.1158 - val_auc_13: 0.9515\n",
      "Epoch 58/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.0896 - auc_13: 0.9692 - val_loss: 0.1050 - val_auc_13: 0.9530\n",
      "Epoch 59/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.0876 - auc_13: 0.9707 - val_loss: 0.1075 - val_auc_13: 0.9523\n",
      "Epoch 60/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.0860 - auc_13: 0.9703 - val_loss: 0.1044 - val_auc_13: 0.9509\n",
      "Epoch 61/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.0848 - auc_13: 0.9710 - val_loss: 0.0967 - val_auc_13: 0.9523\n",
      "Epoch 62/300\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.0842 - auc_13: 0.9717 - val_loss: 0.1052 - val_auc_13: 0.9514\n",
      "Epoch 63/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.0818 - auc_13: 0.9715 - val_loss: 0.1003 - val_auc_13: 0.9507\n",
      "Epoch 64/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.0804 - auc_13: 0.9727 - val_loss: 0.0967 - val_auc_13: 0.9496\n",
      "Epoch 65/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.0792 - auc_13: 0.9730 - val_loss: 0.1016 - val_auc_13: 0.9487\n",
      "Epoch 66/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.0780 - auc_13: 0.9732 - val_loss: 0.1019 - val_auc_13: 0.9476\n",
      "Epoch 67/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.0764 - auc_13: 0.9735 - val_loss: 0.0975 - val_auc_13: 0.9485\n",
      "Epoch 68/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.0752 - auc_13: 0.9748 - val_loss: 0.1064 - val_auc_13: 0.9477\n",
      "Epoch 69/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.0742 - auc_13: 0.9733 - val_loss: 0.0926 - val_auc_13: 0.9484\n",
      "Epoch 70/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.0731 - auc_13: 0.9758 - val_loss: 0.1040 - val_auc_13: 0.9458\n",
      "Epoch 71/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.0732 - auc_13: 0.9732 - val_loss: 0.0864 - val_auc_13: 0.9486\n",
      "Epoch 72/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.0786 - auc_13: 0.9757 - val_loss: 0.0881 - val_auc_13: 0.9468\n",
      "Epoch 73/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.0704 - auc_13: 0.9748 - val_loss: 0.0787 - val_auc_13: 0.9449\n",
      "Epoch 74/300\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0824 - auc_13: 0.9736 - val_loss: 0.0758 - val_auc_13: 0.9462\n",
      "Epoch 75/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.0712 - auc_13: 0.9765 - val_loss: 0.0934 - val_auc_13: 0.9440\n",
      "Epoch 76/300\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0678 - auc_13: 0.9765 - val_loss: 0.0988 - val_auc_13: 0.9430\n",
      "Epoch 77/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.0661 - auc_13: 0.9760 - val_loss: 0.0779 - val_auc_13: 0.9450\n",
      "Epoch 78/300\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.0704 - auc_13: 0.9788 - val_loss: 0.0880 - val_auc_13: 0.9204\n",
      "Epoch 79/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.0650 - auc_13: 0.9767 - val_loss: 0.0886 - val_auc_13: 0.9399\n",
      "Epoch 80/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.0641 - auc_13: 0.9768 - val_loss: 0.0861 - val_auc_13: 0.9415\n",
      "Epoch 81/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.0630 - auc_13: 0.9788 - val_loss: 0.0843 - val_auc_13: 0.9427\n",
      "Epoch 82/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.0619 - auc_13: 0.9780 - val_loss: 0.0897 - val_auc_13: 0.9412\n",
      "Epoch 83/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.0611 - auc_13: 0.9775 - val_loss: 0.0961 - val_auc_13: 0.9384\n",
      "Epoch 84/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.0604 - auc_13: 0.9782 - val_loss: 0.0943 - val_auc_13: 0.9395\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 2s 34ms/step - loss: 0.6176 - auc_14: 0.5267 - val_loss: 0.5312 - val_auc_14: 0.5927\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.4755 - auc_14: 0.6943 - val_loss: 0.4118 - val_auc_14: 0.7621\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.3913 - auc_14: 0.7880 - val_loss: 0.3483 - val_auc_14: 0.8161\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.3489 - auc_14: 0.8278 - val_loss: 0.3242 - val_auc_14: 0.8412\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.3219 - auc_14: 0.8509 - val_loss: 0.2913 - val_auc_14: 0.8638\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.3034 - auc_14: 0.8683 - val_loss: 0.2686 - val_auc_14: 0.8807\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.2899 - auc_14: 0.8733 - val_loss: 0.2506 - val_auc_14: 0.8906\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.2780 - auc_14: 0.8890 - val_loss: 0.2761 - val_auc_14: 0.8819\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.2727 - auc_14: 0.8833 - val_loss: 0.2560 - val_auc_14: 0.8914\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.2602 - auc_14: 0.8967 - val_loss: 0.2452 - val_auc_14: 0.8984\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.2527 - auc_14: 0.9024 - val_loss: 0.2591 - val_auc_14: 0.8936\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.2535 - auc_14: 0.8959 - val_loss: 0.2586 - val_auc_14: 0.8953\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.2405 - auc_14: 0.9065 - val_loss: 0.2235 - val_auc_14: 0.9118\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.2357 - auc_14: 0.9118 - val_loss: 0.2320 - val_auc_14: 0.9097\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.2329 - auc_14: 0.9056 - val_loss: 0.2122 - val_auc_14: 0.9181\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.2268 - auc_14: 0.9124 - val_loss: 0.2321 - val_auc_14: 0.9104\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.2268 - auc_14: 0.9074 - val_loss: 0.2180 - val_auc_14: 0.9172\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.2185 - auc_14: 0.9148 - val_loss: 0.2144 - val_auc_14: 0.9195\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.2132 - auc_14: 0.9173 - val_loss: 0.2181 - val_auc_14: 0.9182\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.2095 - auc_14: 0.9200 - val_loss: 0.2097 - val_auc_14: 0.9239\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.2048 - auc_14: 0.9216 - val_loss: 0.1858 - val_auc_14: 0.9314\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.2010 - auc_14: 0.9258 - val_loss: 0.1768 - val_auc_14: 0.9355\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1981 - auc_14: 0.9270 - val_loss: 0.1842 - val_auc_14: 0.9337\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.1938 - auc_14: 0.9271 - val_loss: 0.1741 - val_auc_14: 0.9377\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1902 - auc_14: 0.9293 - val_loss: 0.1770 - val_auc_14: 0.9368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1867 - auc_14: 0.9301 - val_loss: 0.1729 - val_auc_14: 0.9380\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1837 - auc_14: 0.9330 - val_loss: 0.1743 - val_auc_14: 0.9387\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1801 - auc_14: 0.9335 - val_loss: 0.1729 - val_auc_14: 0.9389\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1770 - auc_14: 0.9348 - val_loss: 0.1903 - val_auc_14: 0.9326\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.1741 - auc_14: 0.9332 - val_loss: 0.1516 - val_auc_14: 0.9483\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1717 - auc_14: 0.9386 - val_loss: 0.1661 - val_auc_14: 0.9422\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1691 - auc_14: 0.9361 - val_loss: 0.1909 - val_auc_14: 0.9326\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1655 - auc_14: 0.9396 - val_loss: 0.1726 - val_auc_14: 0.9399\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1624 - auc_14: 0.9427 - val_loss: 0.1977 - val_auc_14: 0.9313\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.1612 - auc_14: 0.9406 - val_loss: 0.1362 - val_auc_14: 0.9564\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.1582 - auc_14: 0.9449 - val_loss: 0.1643 - val_auc_14: 0.9443\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 0.1559 - auc_14: 0.9428 - val_loss: 0.1620 - val_auc_14: 0.9453\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 0.1521 - auc_14: 0.9445 - val_loss: 0.1393 - val_auc_14: 0.9530\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 0.1508 - auc_14: 0.9468 - val_loss: 0.1356 - val_auc_14: 0.9539\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 0.1488 - auc_14: 0.9490 - val_loss: 0.1345 - val_auc_14: 0.9548\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.1500 - auc_14: 0.9510 - val_loss: 0.1451 - val_auc_14: 0.9490\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.1440 - auc_14: 0.9488 - val_loss: 0.1346 - val_auc_14: 0.9543\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.1424 - auc_14: 0.9498 - val_loss: 0.1424 - val_auc_14: 0.9507\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.1397 - auc_14: 0.9522 - val_loss: 0.1531 - val_auc_14: 0.9475\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.1385 - auc_14: 0.9487 - val_loss: 0.1381 - val_auc_14: 0.9500\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.1392 - auc_14: 0.9552 - val_loss: 0.1406 - val_auc_14: 0.9492\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.1360 - auc_14: 0.9509 - val_loss: 0.1314 - val_auc_14: 0.9507\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.1336 - auc_14: 0.9554 - val_loss: 0.1296 - val_auc_14: 0.9508\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 0.1310 - auc_14: 0.9555 - val_loss: 0.1466 - val_auc_14: 0.9471\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.1296 - auc_14: 0.9562 - val_loss: 0.1323 - val_auc_14: 0.9517\n",
      "Epoch 51/300\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 0.1273 - auc_14: 0.9570 - val_loss: 0.1627 - val_auc_14: 0.9432\n",
      "Epoch 52/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.1273 - auc_14: 0.9549 - val_loss: 0.1363 - val_auc_14: 0.9504\n",
      "Epoch 53/300\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.1247 - auc_14: 0.9583 - val_loss: 0.1390 - val_auc_14: 0.9499\n",
      "Epoch 54/300\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.1239 - auc_14: 0.9580 - val_loss: 0.1415 - val_auc_14: 0.9487\n",
      "Epoch 55/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.1252 - auc_14: 0.9550 - val_loss: 0.1162 - val_auc_14: 0.9576\n",
      "Epoch 56/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.1211 - auc_14: 0.9621 - val_loss: 0.1285 - val_auc_14: 0.9535\n",
      "Epoch 57/300\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.1190 - auc_14: 0.9604 - val_loss: 0.1262 - val_auc_14: 0.9534\n",
      "Epoch 58/300\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.1181 - auc_14: 0.9612 - val_loss: 0.1249 - val_auc_14: 0.9548\n",
      "Epoch 59/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1167 - auc_14: 0.9621 - val_loss: 0.1342 - val_auc_14: 0.9515\n",
      "Epoch 60/300\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.1153 - auc_14: 0.9600 - val_loss: 0.1198 - val_auc_14: 0.9535\n",
      "Epoch 61/300\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.1138 - auc_14: 0.9630 - val_loss: 0.1249 - val_auc_14: 0.9526\n",
      "Epoch 62/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1129 - auc_14: 0.9618 - val_loss: 0.1380 - val_auc_14: 0.9504\n",
      "Epoch 63/300\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.1114 - auc_14: 0.9630 - val_loss: 0.1211 - val_auc_14: 0.9532\n",
      "Epoch 64/300\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.1105 - auc_14: 0.9638 - val_loss: 0.1197 - val_auc_14: 0.9535\n",
      "Epoch 65/300\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.1097 - auc_14: 0.9648 - val_loss: 0.1093 - val_auc_14: 0.9559\n",
      "Epoch 66/300\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.1083 - auc_14: 0.9651 - val_loss: 0.1272 - val_auc_14: 0.9521\n",
      "Epoch 67/300\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.1073 - auc_14: 0.9641 - val_loss: 0.1367 - val_auc_14: 0.9496\n",
      "Epoch 68/300\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.1085 - auc_14: 0.9606 - val_loss: 0.1223 - val_auc_14: 0.9533\n",
      "Epoch 69/300\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.1043 - auc_14: 0.9646 - val_loss: 0.1018 - val_auc_14: 0.9576\n",
      "Epoch 70/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1035 - auc_14: 0.9661 - val_loss: 0.1100 - val_auc_14: 0.9550\n",
      "Epoch 71/300\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.1021 - auc_14: 0.9667 - val_loss: 0.1247 - val_auc_14: 0.9527\n",
      "Epoch 72/300\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.1012 - auc_14: 0.9670 - val_loss: 0.1140 - val_auc_14: 0.9537\n",
      "Epoch 73/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.0999 - auc_14: 0.9678 - val_loss: 0.1309 - val_auc_14: 0.9507\n",
      "Epoch 74/300\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.1002 - auc_14: 0.9670 - val_loss: 0.1207 - val_auc_14: 0.9514\n",
      "Epoch 75/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.0981 - auc_14: 0.9670 - val_loss: 0.1090 - val_auc_14: 0.9549\n",
      "Epoch 76/300\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.0971 - auc_14: 0.9687 - val_loss: 0.1156 - val_auc_14: 0.9529\n",
      "Epoch 77/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.0964 - auc_14: 0.9692 - val_loss: 0.1375 - val_auc_14: 0.9496\n",
      "Epoch 78/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.1025 - auc_14: 0.9631 - val_loss: 0.1195 - val_auc_14: 0.9515\n",
      "Epoch 79/300\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.0946 - auc_14: 0.9688 - val_loss: 0.1120 - val_auc_14: 0.9535\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 3s 33ms/step - loss: 0.6217 - auc_15: 0.5873 - val_loss: 0.4492 - val_auc_15: 0.6904\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.4765 - auc_15: 0.7410 - val_loss: 0.3951 - val_auc_15: 0.7627\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.4021 - auc_15: 0.7851 - val_loss: 0.2982 - val_auc_15: 0.8250\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.3493 - auc_15: 0.8336 - val_loss: 0.2835 - val_auc_15: 0.8434\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.3131 - auc_15: 0.8555 - val_loss: 0.2652 - val_auc_15: 0.8628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.2881 - auc_15: 0.8676 - val_loss: 0.2258 - val_auc_15: 0.8890\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.2696 - auc_15: 0.8815 - val_loss: 0.2249 - val_auc_15: 0.8940\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.2568 - auc_15: 0.8952 - val_loss: 0.2023 - val_auc_15: 0.9071\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.2444 - auc_15: 0.9002 - val_loss: 0.1966 - val_auc_15: 0.9114\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.2381 - auc_15: 0.8969 - val_loss: 0.2217 - val_auc_15: 0.9073\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.2272 - auc_15: 0.9056 - val_loss: 0.2115 - val_auc_15: 0.9133\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.2201 - auc_15: 0.9098 - val_loss: 0.2060 - val_auc_15: 0.9169\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.2159 - auc_15: 0.9181 - val_loss: 0.1949 - val_auc_15: 0.9190\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.2054 - auc_15: 0.9183 - val_loss: 0.1910 - val_auc_15: 0.9216\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.1990 - auc_15: 0.9239 - val_loss: 0.1937 - val_auc_15: 0.9212\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1965 - auc_15: 0.9237 - val_loss: 0.1972 - val_auc_15: 0.9205\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1905 - auc_15: 0.9239 - val_loss: 0.1854 - val_auc_15: 0.9257\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.1838 - auc_15: 0.9298 - val_loss: 0.1699 - val_auc_15: 0.9321\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1806 - auc_15: 0.9299 - val_loss: 0.1891 - val_auc_15: 0.9239\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1765 - auc_15: 0.9324 - val_loss: 0.1770 - val_auc_15: 0.9282\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1709 - auc_15: 0.9353 - val_loss: 0.1804 - val_auc_15: 0.9268\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1708 - auc_15: 0.9317 - val_loss: 0.1713 - val_auc_15: 0.9327\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1624 - auc_15: 0.9402 - val_loss: 0.1766 - val_auc_15: 0.9305\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1594 - auc_15: 0.9420 - val_loss: 0.1666 - val_auc_15: 0.9344\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1548 - auc_15: 0.9439 - val_loss: 0.1595 - val_auc_15: 0.9343\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.1514 - auc_15: 0.9457 - val_loss: 0.1548 - val_auc_15: 0.9360\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1488 - auc_15: 0.9470 - val_loss: 0.1486 - val_auc_15: 0.9377\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1450 - auc_15: 0.9484 - val_loss: 0.1483 - val_auc_15: 0.9382\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.1421 - auc_15: 0.9523 - val_loss: 0.1578 - val_auc_15: 0.9346\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.1392 - auc_15: 0.9541 - val_loss: 0.1508 - val_auc_15: 0.9377\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.1392 - auc_15: 0.9492 - val_loss: 0.1473 - val_auc_15: 0.9385\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1334 - auc_15: 0.9572 - val_loss: 0.1325 - val_auc_15: 0.9439\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1342 - auc_15: 0.9584 - val_loss: 0.1461 - val_auc_15: 0.9399\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1283 - auc_15: 0.9563 - val_loss: 0.1285 - val_auc_15: 0.9464\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.1259 - auc_15: 0.9605 - val_loss: 0.1416 - val_auc_15: 0.9422\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1234 - auc_15: 0.9599 - val_loss: 0.1438 - val_auc_15: 0.9410\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1218 - auc_15: 0.9600 - val_loss: 0.1288 - val_auc_15: 0.9458\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1185 - auc_15: 0.9629 - val_loss: 0.1467 - val_auc_15: 0.9397\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1178 - auc_15: 0.9596 - val_loss: 0.1214 - val_auc_15: 0.9431\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1142 - auc_15: 0.9626 - val_loss: 0.1249 - val_auc_15: 0.9417\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1127 - auc_15: 0.9626 - val_loss: 0.1268 - val_auc_15: 0.9411\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1105 - auc_15: 0.9641 - val_loss: 0.1243 - val_auc_15: 0.9401\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1083 - auc_15: 0.9640 - val_loss: 0.1216 - val_auc_15: 0.9404\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1068 - auc_15: 0.9670 - val_loss: 0.1073 - val_auc_15: 0.9433\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1072 - auc_15: 0.9669 - val_loss: 0.1036 - val_auc_15: 0.9440\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1102 - auc_15: 0.9672 - val_loss: 0.1057 - val_auc_15: 0.9416\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.1055 - auc_15: 0.9680 - val_loss: 0.1168 - val_auc_15: 0.9391\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.0998 - auc_15: 0.9677 - val_loss: 0.1001 - val_auc_15: 0.9424\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1055 - auc_15: 0.9685 - val_loss: 0.1071 - val_auc_15: 0.9407\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.0997 - auc_15: 0.9698 - val_loss: 0.1206 - val_auc_15: 0.9362\n",
      "Epoch 51/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.0956 - auc_15: 0.9683 - val_loss: 0.1199 - val_auc_15: 0.9365\n",
      "Epoch 52/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.0942 - auc_15: 0.9692 - val_loss: 0.1075 - val_auc_15: 0.9397\n",
      "Epoch 53/300\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 0.0928 - auc_15: 0.9698 - val_loss: 0.1077 - val_auc_15: 0.9384\n",
      "Epoch 54/300\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 0.0939 - auc_15: 0.9717 - val_loss: 0.1019 - val_auc_15: 0.9392\n",
      "Epoch 55/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.0903 - auc_15: 0.9707 - val_loss: 0.1087 - val_auc_15: 0.9366\n",
      "Epoch 56/300\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.0889 - auc_15: 0.9712 - val_loss: 0.1078 - val_auc_15: 0.9366\n",
      "Epoch 57/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.0880 - auc_15: 0.9708 - val_loss: 0.1277 - val_auc_15: 0.9298\n",
      "Epoch 58/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.0874 - auc_15: 0.9695 - val_loss: 0.1087 - val_auc_15: 0.9358\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6306 - auc_16: 0.5473 - val_loss: 0.5015 - val_auc_16: 0.6408\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.4753 - auc_16: 0.7243 - val_loss: 0.3995 - val_auc_16: 0.7489\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.3965 - auc_16: 0.7957 - val_loss: 0.3327 - val_auc_16: 0.8019\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.3482 - auc_16: 0.8321 - val_loss: 0.3071 - val_auc_16: 0.8138\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.3161 - auc_16: 0.8521 - val_loss: 0.2938 - val_auc_16: 0.8213\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.2913 - auc_16: 0.8684 - val_loss: 0.2894 - val_auc_16: 0.8276\n",
      "Epoch 7/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 29ms/step - loss: 0.2720 - auc_16: 0.8811 - val_loss: 0.2525 - val_auc_16: 0.8395\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.2562 - auc_16: 0.8907 - val_loss: 0.2738 - val_auc_16: 0.8356\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.2447 - auc_16: 0.8897 - val_loss: 0.2006 - val_auc_16: 0.8592\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.2347 - auc_16: 0.9052 - val_loss: 0.2040 - val_auc_16: 0.8617\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.2268 - auc_16: 0.9094 - val_loss: 0.2342 - val_auc_16: 0.8526\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.2218 - auc_16: 0.9076 - val_loss: 0.2258 - val_auc_16: 0.8437\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.2149 - auc_16: 0.9149 - val_loss: 0.1865 - val_auc_16: 0.8529\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.2101 - auc_16: 0.9208 - val_loss: 0.1914 - val_auc_16: 0.8529\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.2053 - auc_16: 0.9212 - val_loss: 0.1945 - val_auc_16: 0.8537\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.2002 - auc_16: 0.9224 - val_loss: 0.2127 - val_auc_16: 0.8503\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1974 - auc_16: 0.9253 - val_loss: 0.1940 - val_auc_16: 0.8432\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.1937 - auc_16: 0.9266 - val_loss: 0.2300 - val_auc_16: 0.8500\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 0.1943 - auc_16: 0.9219 - val_loss: 0.2041 - val_auc_16: 0.8399\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.1878 - auc_16: 0.9269 - val_loss: 0.1960 - val_auc_16: 0.8443\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1844 - auc_16: 0.9291 - val_loss: 0.1860 - val_auc_16: 0.8474\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.1833 - auc_16: 0.9277 - val_loss: 0.1890 - val_auc_16: 0.8468ss: 0.1875 - auc_\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1793 - auc_16: 0.9307 - val_loss: 0.1887 - val_auc_16: 0.8487\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1788 - auc_16: 0.9314 - val_loss: 0.1950 - val_auc_16: 0.8480\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.1750 - auc_16: 0.9331 - val_loss: 0.1728 - val_auc_16: 0.8546\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.1772 - auc_16: 0.9362 - val_loss: 0.1699 - val_auc_16: 0.8539\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.1713 - auc_16: 0.9360 - val_loss: 0.1791 - val_auc_16: 0.8543\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1694 - auc_16: 0.9376 - val_loss: 0.1709 - val_auc_16: 0.8556\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1673 - auc_16: 0.9379 - val_loss: 0.1812 - val_auc_16: 0.8524\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1654 - auc_16: 0.9383 - val_loss: 0.1925 - val_auc_16: 0.8495\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.1640 - auc_16: 0.9375 - val_loss: 0.1900 - val_auc_16: 0.8510\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.1617 - auc_16: 0.9400 - val_loss: 0.1901 - val_auc_16: 0.8515\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.1601 - auc_16: 0.9388 - val_loss: 0.1812 - val_auc_16: 0.8561\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.1588 - auc_16: 0.9407 - val_loss: 0.1852 - val_auc_16: 0.8554\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1569 - auc_16: 0.9406 - val_loss: 0.1786 - val_auc_16: 0.8580\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1553 - auc_16: 0.9436 - val_loss: 0.2026 - val_auc_16: 0.8513\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.6316 - auc_17: 0.5448 - val_loss: 0.4976 - val_auc_17: 0.6314\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.4659 - auc_17: 0.7073 - val_loss: 0.3926 - val_auc_17: 0.7442\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.3701 - auc_17: 0.8021 - val_loss: 0.3159 - val_auc_17: 0.8161\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.3121 - auc_17: 0.8485 - val_loss: 0.2860 - val_auc_17: 0.8296\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.2828 - auc_17: 0.8738 - val_loss: 0.3023 - val_auc_17: 0.8296\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.2634 - auc_17: 0.8824 - val_loss: 0.2356 - val_auc_17: 0.8570\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.2489 - auc_17: 0.8947 - val_loss: 0.2298 - val_auc_17: 0.8552\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.2383 - auc_17: 0.8966 - val_loss: 0.2252 - val_auc_17: 0.8534\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.2294 - auc_17: 0.9096 - val_loss: 0.1901 - val_auc_17: 0.8570\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.2208 - auc_17: 0.9108 - val_loss: 0.1776 - val_auc_17: 0.8629\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.2150 - auc_17: 0.9175 - val_loss: 0.2035 - val_auc_17: 0.8546\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.2076 - auc_17: 0.9194 - val_loss: 0.1944 - val_auc_17: 0.8581\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.2019 - auc_17: 0.9202 - val_loss: 0.2070 - val_auc_17: 0.8542\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1967 - auc_17: 0.9239 - val_loss: 0.1863 - val_auc_17: 0.8605\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1916 - auc_17: 0.9248 - val_loss: 0.1982 - val_auc_17: 0.8557\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.1874 - auc_17: 0.9285 - val_loss: 0.1733 - val_auc_17: 0.8522\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.1820 - auc_17: 0.9280 - val_loss: 0.1783 - val_auc_17: 0.8503\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1781 - auc_17: 0.9303 - val_loss: 0.1986 - val_auc_17: 0.8454\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1744 - auc_17: 0.9301 - val_loss: 0.1815 - val_auc_17: 0.8519\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1705 - auc_17: 0.9349 - val_loss: 0.1726 - val_auc_17: 0.8555\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1696 - auc_17: 0.9367 - val_loss: 0.1712 - val_auc_17: 0.8576\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.1644 - auc_17: 0.9370 - val_loss: 0.2046 - val_auc_17: 0.8466\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1614 - auc_17: 0.9381 - val_loss: 0.1774 - val_auc_17: 0.8560\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1578 - auc_17: 0.9384 - val_loss: 0.1655 - val_auc_17: 0.8601\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1549 - auc_17: 0.9408 - val_loss: 0.1821 - val_auc_17: 0.8560\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1532 - auc_17: 0.9377 - val_loss: 0.1508 - val_auc_17: 0.8655\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1499 - auc_17: 0.9432 - val_loss: 0.1674 - val_auc_17: 0.8599\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1469 - auc_17: 0.9420 - val_loss: 0.1542 - val_auc_17: 0.8660\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1446 - auc_17: 0.9457 - val_loss: 0.1593 - val_auc_17: 0.8639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1418 - auc_17: 0.9453 - val_loss: 0.1440 - val_auc_17: 0.8693\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.1404 - auc_17: 0.9494 - val_loss: 0.1629 - val_auc_17: 0.8643\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.1370 - auc_17: 0.9472 - val_loss: 0.1515 - val_auc_17: 0.8686\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1377 - auc_17: 0.9500 - val_loss: 0.1399 - val_auc_17: 0.8737\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1337 - auc_17: 0.9488 - val_loss: 0.1661 - val_auc_17: 0.8655\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1300 - auc_17: 0.9507 - val_loss: 0.1502 - val_auc_17: 0.8533\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1279 - auc_17: 0.9510 - val_loss: 0.1557 - val_auc_17: 0.8693\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1267 - auc_17: 0.9502 - val_loss: 0.1437 - val_auc_17: 0.8561\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1239 - auc_17: 0.9504 - val_loss: 0.1422 - val_auc_17: 0.8575\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.1231 - auc_17: 0.9542 - val_loss: 0.1793 - val_auc_17: 0.8631\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.1231 - auc_17: 0.9536 - val_loss: 0.1598 - val_auc_17: 0.8522\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.1196 - auc_17: 0.9572 - val_loss: 0.1508 - val_auc_17: 0.8561\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.1164 - auc_17: 0.9567 - val_loss: 0.1542 - val_auc_17: 0.8556\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.1146 - auc_17: 0.9569 - val_loss: 0.1454 - val_auc_17: 0.8582\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.6212 - auc_18: 0.5430 - val_loss: 0.4769 - val_auc_18: 0.6526\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.4626 - auc_18: 0.7353 - val_loss: 0.3617 - val_auc_18: 0.7760\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.3717 - auc_18: 0.8195 - val_loss: 0.3256 - val_auc_18: 0.8137\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.3254 - auc_18: 0.8411 - val_loss: 0.3025 - val_auc_18: 0.8306\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.2938 - auc_18: 0.8674 - val_loss: 0.2562 - val_auc_18: 0.8442\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.2722 - auc_18: 0.8793 - val_loss: 0.2432 - val_auc_18: 0.8504\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.2556 - auc_18: 0.8898 - val_loss: 0.2429 - val_auc_18: 0.8488\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.2423 - auc_18: 0.9000 - val_loss: 0.2042 - val_auc_18: 0.8540\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.2316 - auc_18: 0.9080 - val_loss: 0.1971 - val_auc_18: 0.8574\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.2227 - auc_18: 0.9136 - val_loss: 0.2026 - val_auc_18: 0.8572\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.2169 - auc_18: 0.9163 - val_loss: 0.1825 - val_auc_18: 0.8629\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.2087 - auc_18: 0.9183 - val_loss: 0.1998 - val_auc_18: 0.8583\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.2025 - auc_18: 0.9178 - val_loss: 0.1897 - val_auc_18: 0.8607\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1971 - auc_18: 0.9218 - val_loss: 0.1817 - val_auc_18: 0.8648\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1917 - auc_18: 0.9245 - val_loss: 0.1798 - val_auc_18: 0.8637\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1868 - auc_18: 0.9293 - val_loss: 0.1972 - val_auc_18: 0.8614\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1831 - auc_18: 0.9287 - val_loss: 0.1711 - val_auc_18: 0.8553\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1785 - auc_18: 0.9327 - val_loss: 0.1712 - val_auc_18: 0.8571\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1751 - auc_18: 0.9346 - val_loss: 0.1992 - val_auc_18: 0.8639\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.1724 - auc_18: 0.9302 - val_loss: 0.1763 - val_auc_18: 0.8566\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1683 - auc_18: 0.9364 - val_loss: 0.1969 - val_auc_18: 0.8681\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.1643 - auc_18: 0.9346 - val_loss: 0.1585 - val_auc_18: 0.8641\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.1668 - auc_18: 0.9401 - val_loss: 0.1441 - val_auc_18: 0.8688\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.1579 - auc_18: 0.9412 - val_loss: 0.1663 - val_auc_18: 0.8606\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.1549 - auc_18: 0.9408 - val_loss: 0.1602 - val_auc_18: 0.8645\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.1528 - auc_18: 0.9428 - val_loss: 0.1418 - val_auc_18: 0.8707\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1484 - auc_18: 0.9445 - val_loss: 0.1633 - val_auc_18: 0.8652\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.1461 - auc_18: 0.9430 - val_loss: 0.1509 - val_auc_18: 0.8698\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1436 - auc_18: 0.9459 - val_loss: 0.1592 - val_auc_18: 0.86681436 - auc_18: 0.94\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1407 - auc_18: 0.9478 - val_loss: 0.1578 - val_auc_18: 0.8671\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1398 - auc_18: 0.9457 - val_loss: 0.1456 - val_auc_18: 0.8715\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1358 - auc_18: 0.9494 - val_loss: 0.1511 - val_auc_18: 0.8720\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1332 - auc_18: 0.9486 - val_loss: 0.1366 - val_auc_18: 0.8765\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1307 - auc_18: 0.9505 - val_loss: 0.1416 - val_auc_18: 0.8750\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.1285 - auc_18: 0.9530 - val_loss: 0.1380 - val_auc_18: 0.8770\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.1269 - auc_18: 0.9546 - val_loss: 0.1326 - val_auc_18: 0.8783\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.1243 - auc_18: 0.9544 - val_loss: 0.1531 - val_auc_18: 0.8715\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.1236 - auc_18: 0.9549 - val_loss: 0.1534 - val_auc_18: 0.8723\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1214 - auc_18: 0.9532 - val_loss: 0.1338 - val_auc_18: 0.8790\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1184 - auc_18: 0.9572 - val_loss: 0.1326 - val_auc_18: 0.8798\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1165 - auc_18: 0.9587 - val_loss: 0.1433 - val_auc_18: 0.8778\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1153 - auc_18: 0.9565 - val_loss: 0.1208 - val_auc_18: 0.8868\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1169 - auc_18: 0.9608 - val_loss: 0.1282 - val_auc_18: 0.8838\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.1113 - auc_18: 0.9595 - val_loss: 0.1405 - val_auc_18: 0.8783\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1095 - auc_18: 0.9604 - val_loss: 0.1253 - val_auc_18: 0.8859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1083 - auc_18: 0.9627 - val_loss: 0.1171 - val_auc_18: 0.8897\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1102 - auc_18: 0.9622 - val_loss: 0.1121 - val_auc_18: 0.8931\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.1046 - auc_18: 0.9636 - val_loss: 0.1395 - val_auc_18: 0.8802\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1043 - auc_18: 0.9616 - val_loss: 0.1233 - val_auc_18: 0.8880\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.1022 - auc_18: 0.9653 - val_loss: 0.1242 - val_auc_18: 0.8886\n",
      "Epoch 51/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1001 - auc_18: 0.9640 - val_loss: 0.1170 - val_auc_18: 0.8925\n",
      "Epoch 52/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.0989 - auc_18: 0.9653 - val_loss: 0.1310 - val_auc_18: 0.8859\n",
      "Epoch 53/300\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0975 - auc_18: 0.9658 - val_loss: 0.1184 - val_auc_18: 0.8922\n",
      "Epoch 54/300\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.1001 - auc_18: 0.9697 - val_loss: 0.1129 - val_auc_18: 0.8952\n",
      "Epoch 55/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.0951 - auc_18: 0.9663 - val_loss: 0.1247 - val_auc_18: 0.8898\n",
      "Epoch 56/300\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.0938 - auc_18: 0.9675 - val_loss: 0.1297 - val_auc_18: 0.8883\n",
      "Epoch 57/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.0927 - auc_18: 0.9670 - val_loss: 0.1196 - val_auc_18: 0.8723\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6398 - auc_19: 0.5496 - val_loss: 0.4364 - val_auc_19: 0.6724\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.5002 - auc_19: 0.7224 - val_loss: 0.3586 - val_auc_19: 0.7418\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.4159 - auc_19: 0.7997 - val_loss: 0.3200 - val_auc_19: 0.7792\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.3546 - auc_19: 0.8248 - val_loss: 0.3016 - val_auc_19: 0.8042\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.3073 - auc_19: 0.8541 - val_loss: 0.2618 - val_auc_19: 0.8263\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.2788 - auc_19: 0.8761 - val_loss: 0.2429 - val_auc_19: 0.8391\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.2591 - auc_19: 0.8868 - val_loss: 0.2369 - val_auc_19: 0.8322\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.2452 - auc_19: 0.8987 - val_loss: 0.2311 - val_auc_19: 0.8352\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.2334 - auc_19: 0.9015 - val_loss: 0.2292 - val_auc_19: 0.8399\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.2246 - auc_19: 0.9024 - val_loss: 0.1943 - val_auc_19: 0.8400\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.2160 - auc_19: 0.9166 - val_loss: 0.2077 - val_auc_19: 0.8359\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.2146 - auc_19: 0.9196 - val_loss: 0.1896 - val_auc_19: 0.8428\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.2056 - auc_19: 0.9201 - val_loss: 0.2008 - val_auc_19: 0.8394\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.1998 - auc_19: 0.9215 - val_loss: 0.1958 - val_auc_19: 0.8431\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1947 - auc_19: 0.9251 - val_loss: 0.1797 - val_auc_19: 0.8497\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.1896 - auc_19: 0.9267 - val_loss: 0.1755 - val_auc_19: 0.8517\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.1848 - auc_19: 0.9289 - val_loss: 0.1743 - val_auc_19: 0.8530\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1810 - auc_19: 0.9327 - val_loss: 0.1804 - val_auc_19: 0.8515\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1764 - auc_19: 0.9329 - val_loss: 0.1797 - val_auc_19: 0.8530\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1722 - auc_19: 0.9346 - val_loss: 0.1609 - val_auc_19: 0.8603\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.1694 - auc_19: 0.9394 - val_loss: 0.1608 - val_auc_19: 0.8608\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1663 - auc_19: 0.9407 - val_loss: 0.1804 - val_auc_19: 0.8553\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1626 - auc_19: 0.9357 - val_loss: 0.1720 - val_auc_19: 0.8587\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1582 - auc_19: 0.9419 - val_loss: 0.1897 - val_auc_19: 0.8532\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.1551 - auc_19: 0.9414 - val_loss: 0.1616 - val_auc_19: 0.8632\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1523 - auc_19: 0.9453 - val_loss: 0.1686 - val_auc_19: 0.8608\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1492 - auc_19: 0.9454 - val_loss: 0.1601 - val_auc_19: 0.8657\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1461 - auc_19: 0.9464 - val_loss: 0.1701 - val_auc_19: 0.8615\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1449 - auc_19: 0.9430 - val_loss: 0.1588 - val_auc_19: 0.8682\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1419 - auc_19: 0.9475 - val_loss: 0.1812 - val_auc_19: 0.8593\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1396 - auc_19: 0.9456 - val_loss: 0.1625 - val_auc_19: 0.8689\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1370 - auc_19: 0.9521 - val_loss: 0.1565 - val_auc_19: 0.8703\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1347 - auc_19: 0.9490 - val_loss: 0.1422 - val_auc_19: 0.8757\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1335 - auc_19: 0.9532 - val_loss: 0.1410 - val_auc_19: 0.8775\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1301 - auc_19: 0.9520 - val_loss: 0.1493 - val_auc_19: 0.8754\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1282 - auc_19: 0.9521 - val_loss: 0.1511 - val_auc_19: 0.8749\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1265 - auc_19: 0.9535 - val_loss: 0.1571 - val_auc_19: 0.8735\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.1260 - auc_19: 0.9529 - val_loss: 0.1559 - val_auc_19: 0.8745\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.1229 - auc_19: 0.9545 - val_loss: 0.1399 - val_auc_19: 0.8799\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.1210 - auc_19: 0.9577 - val_loss: 0.1609 - val_auc_19: 0.8738\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.1202 - auc_19: 0.9540 - val_loss: 0.1378 - val_auc_19: 0.8816\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.1184 - auc_19: 0.9572 - val_loss: 0.1305 - val_auc_19: 0.8848\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1158 - auc_19: 0.9576 - val_loss: 0.1276 - val_auc_19: 0.8847\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.1147 - auc_19: 0.9590 - val_loss: 0.1373 - val_auc_19: 0.8821\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.1128 - auc_19: 0.9590 - val_loss: 0.1230 - val_auc_19: 0.8869\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1125 - auc_19: 0.9617 - val_loss: 0.1353 - val_auc_19: 0.8838\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1104 - auc_19: 0.9591 - val_loss: 0.1267 - val_auc_19: 0.8864\n",
      "Epoch 48/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 31ms/step - loss: 0.1085 - auc_19: 0.9619 - val_loss: 0.1300 - val_auc_19: 0.8871\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1073 - auc_19: 0.9613 - val_loss: 0.1268 - val_auc_19: 0.8865\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1067 - auc_19: 0.9592 - val_loss: 0.1266 - val_auc_19: 0.8856\n",
      "Epoch 51/300\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.1045 - auc_19: 0.9632 - val_loss: 0.1248 - val_auc_19: 0.8874\n",
      "Epoch 52/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1042 - auc_19: 0.9645 - val_loss: 0.1297 - val_auc_19: 0.8859\n",
      "Epoch 53/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.1025 - auc_19: 0.9626 - val_loss: 0.1265 - val_auc_19: 0.8870\n",
      "Epoch 54/300\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.1008 - auc_19: 0.9642 - val_loss: 0.1322 - val_auc_19: 0.8860\n",
      "Epoch 55/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.0994 - auc_19: 0.9659 - val_loss: 0.1259 - val_auc_19: 0.8881\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 2s 34ms/step - loss: 0.6148 - auc_20: 0.5984 - val_loss: 0.4320 - val_auc_20: 0.6548\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.4463 - auc_20: 0.7502 - val_loss: 0.3430 - val_auc_20: 0.7686\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.3638 - auc_20: 0.8220 - val_loss: 0.2891 - val_auc_20: 0.8198\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.3177 - auc_20: 0.8492 - val_loss: 0.2698 - val_auc_20: 0.8286\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.2867 - auc_20: 0.8728 - val_loss: 0.2409 - val_auc_20: 0.8436\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.2681 - auc_20: 0.8879 - val_loss: 0.2454 - val_auc_20: 0.8383\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.2553 - auc_20: 0.8871 - val_loss: 0.2456 - val_auc_20: 0.8424\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.2439 - auc_20: 0.8922 - val_loss: 0.2320 - val_auc_20: 0.8388\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.2338 - auc_20: 0.8997 - val_loss: 0.2235 - val_auc_20: 0.8376\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.2252 - auc_20: 0.9063 - val_loss: 0.2162 - val_auc_20: 0.8422\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 0.2183 - auc_20: 0.9105 - val_loss: 0.2152 - val_auc_20: 0.8434\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.2120 - auc_20: 0.9149 - val_loss: 0.2000 - val_auc_20: 0.8493\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.2058 - auc_20: 0.9154 - val_loss: 0.1723 - val_auc_20: 0.8460\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.2013 - auc_20: 0.9209 - val_loss: 0.1894 - val_auc_20: 0.8534\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.1960 - auc_20: 0.9228 - val_loss: 0.1945 - val_auc_20: 0.8538\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.1912 - auc_20: 0.9239 - val_loss: 0.1814 - val_auc_20: 0.8457\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.1868 - auc_20: 0.9266 - val_loss: 0.2091 - val_auc_20: 0.8505\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.1834 - auc_20: 0.9242 - val_loss: 0.1758 - val_auc_20: 0.8515\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.1790 - auc_20: 0.9296 - val_loss: 0.1980 - val_auc_20: 0.8429\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.1820 - auc_20: 0.9244 - val_loss: 0.1930 - val_auc_20: 0.8604\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 0.1748 - auc_20: 0.9298 - val_loss: 0.1811 - val_auc_20: 0.8500\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 0.1707 - auc_20: 0.9325 - val_loss: 0.1882 - val_auc_20: 0.8476\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.1681 - auc_20: 0.9329 - val_loss: 0.1946 - val_auc_20: 0.8458\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6364 - auc_21: 0.5278 - val_loss: 0.5400 - val_auc_21: 0.5929\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.4964 - auc_21: 0.6609 - val_loss: 0.4046 - val_auc_21: 0.7459\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.4035 - auc_21: 0.7803 - val_loss: 0.3400 - val_auc_21: 0.8211\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.3464 - auc_21: 0.8371 - val_loss: 0.3006 - val_auc_21: 0.8459\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.3125 - auc_21: 0.8582 - val_loss: 0.3040 - val_auc_21: 0.8528\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.2931 - auc_21: 0.8680 - val_loss: 0.2751 - val_auc_21: 0.8639\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.2769 - auc_21: 0.8818 - val_loss: 0.2447 - val_auc_21: 0.8771\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.2713 - auc_21: 0.8923 - val_loss: 0.2175 - val_auc_21: 0.8896\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.2586 - auc_21: 0.8958 - val_loss: 0.2246 - val_auc_21: 0.8879\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.2510 - auc_21: 0.9001 - val_loss: 0.2515 - val_auc_21: 0.8805\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2452 - auc_21: 0.9004 - val_loss: 0.2339 - val_auc_21: 0.8874\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2373 - auc_21: 0.9076 - val_loss: 0.2175 - val_auc_21: 0.8941\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2320 - auc_21: 0.9114 - val_loss: 0.2428 - val_auc_21: 0.8859\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2299 - auc_21: 0.9082 - val_loss: 0.2401 - val_auc_21: 0.8883\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2220 - auc_21: 0.9141 - val_loss: 0.2197 - val_auc_21: 0.8960\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2192 - auc_21: 0.9137 - val_loss: 0.2329 - val_auc_21: 0.8914\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2134 - auc_21: 0.9167 - val_loss: 0.2275 - val_auc_21: 0.8944\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2088 - auc_21: 0.9186 - val_loss: 0.2068 - val_auc_21: 0.9011\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2044 - auc_21: 0.9215 - val_loss: 0.2086 - val_auc_21: 0.9003\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2000 - auc_21: 0.9254 - val_loss: 0.2141 - val_auc_21: 0.8994\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1963 - auc_21: 0.9247 - val_loss: 0.1832 - val_auc_21: 0.9099\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1935 - auc_21: 0.9286 - val_loss: 0.2195 - val_auc_21: 0.8992\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1885 - auc_21: 0.9295 - val_loss: 0.1722 - val_auc_21: 0.9137\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1872 - auc_21: 0.9340 - val_loss: 0.2110 - val_auc_21: 0.9015\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1861 - auc_21: 0.9262 - val_loss: 0.1880 - val_auc_21: 0.9052\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1812 - auc_21: 0.9367 - val_loss: 0.1871 - val_auc_21: 0.9101\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1759 - auc_21: 0.9358 - val_loss: 0.1796 - val_auc_21: 0.9078\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1729 - auc_21: 0.9361 - val_loss: 0.1783 - val_auc_21: 0.9084\n",
      "Epoch 29/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1714 - auc_21: 0.9409 - val_loss: 0.1849 - val_auc_21: 0.9055\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1665 - auc_21: 0.9392 - val_loss: 0.1819 - val_auc_21: 0.9060\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1636 - auc_21: 0.9400 - val_loss: 0.1582 - val_auc_21: 0.9134\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1681 - auc_21: 0.9445 - val_loss: 0.1667 - val_auc_21: 0.9079\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1583 - auc_21: 0.9408 - val_loss: 0.1626 - val_auc_21: 0.9095\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1558 - auc_21: 0.9422 - val_loss: 0.1741 - val_auc_21: 0.9080\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1531 - auc_21: 0.9442 - val_loss: 0.1679 - val_auc_21: 0.9098\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1507 - auc_21: 0.9445 - val_loss: 0.1544 - val_auc_21: 0.9143\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1541 - auc_21: 0.9459 - val_loss: 0.1568 - val_auc_21: 0.9117\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1465 - auc_21: 0.9455 - val_loss: 0.1617 - val_auc_21: 0.9127\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1443 - auc_21: 0.9458 - val_loss: 0.1593 - val_auc_21: 0.9136\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1424 - auc_21: 0.9472 - val_loss: 0.1571 - val_auc_21: 0.9143\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1411 - auc_21: 0.9493 - val_loss: 0.1556 - val_auc_21: 0.9153\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1377 - auc_21: 0.9478 - val_loss: 0.1552 - val_auc_21: 0.9143\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1372 - auc_21: 0.9487 - val_loss: 0.1255 - val_auc_21: 0.9244\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1340 - auc_21: 0.9505 - val_loss: 0.1340 - val_auc_21: 0.9208\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1326 - auc_21: 0.9507 - val_loss: 0.1422 - val_auc_21: 0.9204\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1295 - auc_21: 0.9515 - val_loss: 0.1305 - val_auc_21: 0.9238\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1331 - auc_21: 0.9534 - val_loss: 0.1239 - val_auc_21: 0.9256\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1267 - auc_21: 0.9533 - val_loss: 0.1392 - val_auc_21: 0.9200\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1241 - auc_21: 0.9543 - val_loss: 0.1464 - val_auc_21: 0.9194\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1232 - auc_21: 0.9533 - val_loss: 0.1516 - val_auc_21: 0.9180\n",
      "Epoch 51/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1217 - auc_21: 0.9568 - val_loss: 0.1382 - val_auc_21: 0.9210\n",
      "Epoch 52/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1193 - auc_21: 0.9553 - val_loss: 0.1401 - val_auc_21: 0.9210\n",
      "Epoch 53/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1167 - auc_21: 0.9555 - val_loss: 0.1239 - val_auc_21: 0.9265\n",
      "Epoch 54/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1159 - auc_21: 0.9562 - val_loss: 0.1295 - val_auc_21: 0.9240\n",
      "Epoch 55/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1164 - auc_21: 0.9592 - val_loss: 0.1435 - val_auc_21: 0.9174\n",
      "Epoch 56/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1130 - auc_21: 0.9565 - val_loss: 0.1448 - val_auc_21: 0.9180\n",
      "Epoch 57/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1105 - auc_21: 0.9577 - val_loss: 0.1189 - val_auc_21: 0.9105\n",
      "Epoch 58/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1098 - auc_21: 0.9583 - val_loss: 0.1179 - val_auc_21: 0.9119\n",
      "Epoch 59/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1075 - auc_21: 0.9598 - val_loss: 0.1315 - val_auc_21: 0.9255\n",
      "Epoch 60/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1058 - auc_21: 0.9600 - val_loss: 0.1442 - val_auc_21: 0.9203\n",
      "Epoch 61/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1049 - auc_21: 0.9592 - val_loss: 0.1475 - val_auc_21: 0.9194\n",
      "Epoch 62/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1032 - auc_21: 0.9587 - val_loss: 0.1338 - val_auc_21: 0.9247\n",
      "Epoch 63/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1015 - auc_21: 0.9620 - val_loss: 0.1379 - val_auc_21: 0.9237\n",
      "Epoch 64/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1001 - auc_21: 0.9608 - val_loss: 0.1236 - val_auc_21: 0.9105\n",
      "Epoch 65/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0986 - auc_21: 0.9633 - val_loss: 0.1344 - val_auc_21: 0.9255\n",
      "Epoch 66/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0969 - auc_21: 0.9620 - val_loss: 0.1040 - val_auc_21: 0.9185\n",
      "Epoch 67/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1004 - auc_21: 0.9641 - val_loss: 0.1157 - val_auc_21: 0.9136\n",
      "Epoch 68/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0947 - auc_21: 0.9635 - val_loss: 0.1200 - val_auc_21: 0.9139\n",
      "Epoch 69/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0929 - auc_21: 0.9648 - val_loss: 0.1273 - val_auc_21: 0.9113\n",
      "Epoch 70/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0917 - auc_21: 0.9647 - val_loss: 0.1278 - val_auc_21: 0.9113\n",
      "Epoch 71/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0902 - auc_21: 0.9653 - val_loss: 0.1259 - val_auc_21: 0.9107\n",
      "Epoch 72/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0888 - auc_21: 0.9668 - val_loss: 0.1252 - val_auc_21: 0.9110\n",
      "Epoch 73/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0875 - auc_21: 0.9667 - val_loss: 0.1191 - val_auc_21: 0.9142\n",
      "Epoch 74/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0864 - auc_21: 0.9678 - val_loss: 0.1129 - val_auc_21: 0.8976\n",
      "Epoch 75/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0883 - auc_21: 0.9687 - val_loss: 0.1105 - val_auc_21: 0.8984\n",
      "Epoch 76/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0842 - auc_21: 0.9685 - val_loss: 0.1190 - val_auc_21: 0.8954\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6354 - auc_22: 0.5348 - val_loss: 0.4971 - val_auc_22: 0.6248\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.4768 - auc_22: 0.6982 - val_loss: 0.3795 - val_auc_22: 0.7748\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.3942 - auc_22: 0.8022 - val_loss: 0.3623 - val_auc_22: 0.8093\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3463 - auc_22: 0.8336 - val_loss: 0.3036 - val_auc_22: 0.8398\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.3195 - auc_22: 0.8565 - val_loss: 0.2794 - val_auc_22: 0.8573\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3000 - auc_22: 0.8671 - val_loss: 0.2661 - val_auc_22: 0.8643\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2867 - auc_22: 0.8765 - val_loss: 0.2945 - val_auc_22: 0.8552\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2762 - auc_22: 0.8790 - val_loss: 0.2569 - val_auc_22: 0.8743\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2672 - auc_22: 0.8913 - val_loss: 0.2494 - val_auc_22: 0.8785\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2604 - auc_22: 0.8985 - val_loss: 0.2559 - val_auc_22: 0.8773\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2537 - auc_22: 0.8999 - val_loss: 0.2892 - val_auc_22: 0.8685\n",
      "Epoch 12/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2496 - auc_22: 0.9005 - val_loss: 0.2825 - val_auc_22: 0.8723\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2459 - auc_22: 0.9016 - val_loss: 0.2521 - val_auc_22: 0.8820\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2369 - auc_22: 0.9052 - val_loss: 0.2241 - val_auc_22: 0.8913\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2335 - auc_22: 0.9084 - val_loss: 0.2720 - val_auc_22: 0.8776\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2318 - auc_22: 0.9066 - val_loss: 0.2353 - val_auc_22: 0.8906\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2241 - auc_22: 0.9144 - val_loss: 0.2503 - val_auc_22: 0.8865\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2220 - auc_22: 0.9136 - val_loss: 0.2439 - val_auc_22: 0.8903\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2154 - auc_22: 0.9184 - val_loss: 0.2372 - val_auc_22: 0.8918\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2134 - auc_22: 0.9165 - val_loss: 0.2112 - val_auc_22: 0.9005\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2085 - auc_22: 0.9228 - val_loss: 0.2101 - val_auc_22: 0.9006\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2048 - auc_22: 0.9227 - val_loss: 0.2327 - val_auc_22: 0.8951\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2007 - auc_22: 0.9237 - val_loss: 0.1975 - val_auc_22: 0.9046\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1974 - auc_22: 0.9283 - val_loss: 0.1981 - val_auc_22: 0.9058\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1924 - auc_22: 0.9288 - val_loss: 0.2045 - val_auc_22: 0.9044\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1916 - auc_22: 0.9318 - val_loss: 0.1833 - val_auc_22: 0.9107\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1867 - auc_22: 0.9328 - val_loss: 0.1900 - val_auc_22: 0.9084\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1825 - auc_22: 0.9313 - val_loss: 0.2060 - val_auc_22: 0.9054\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1786 - auc_22: 0.9320 - val_loss: 0.1693 - val_auc_22: 0.9113\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1816 - auc_22: 0.9369 - val_loss: 0.1733 - val_auc_22: 0.9109\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1728 - auc_22: 0.9354 - val_loss: 0.1748 - val_auc_22: 0.9141\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1695 - auc_22: 0.9378 - val_loss: 0.1970 - val_auc_22: 0.9081\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1674 - auc_22: 0.9367 - val_loss: 0.1860 - val_auc_22: 0.9111\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1640 - auc_22: 0.9393 - val_loss: 0.1610 - val_auc_22: 0.9167\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1614 - auc_22: 0.9413 - val_loss: 0.1616 - val_auc_22: 0.9170\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1590 - auc_22: 0.9427 - val_loss: 0.1695 - val_auc_22: 0.9139\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1572 - auc_22: 0.9427 - val_loss: 0.1750 - val_auc_22: 0.9121\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1538 - auc_22: 0.9420 - val_loss: 0.1728 - val_auc_22: 0.9135\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1525 - auc_22: 0.9445 - val_loss: 0.1860 - val_auc_22: 0.9103\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1495 - auc_22: 0.9444 - val_loss: 0.1563 - val_auc_22: 0.9177\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1505 - auc_22: 0.9530 - val_loss: 0.1664 - val_auc_22: 0.9177\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1445 - auc_22: 0.9471 - val_loss: 0.1672 - val_auc_22: 0.9180\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1425 - auc_22: 0.9477 - val_loss: 0.1547 - val_auc_22: 0.9198\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1401 - auc_22: 0.9492 - val_loss: 0.1609 - val_auc_22: 0.9183\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1381 - auc_22: 0.9489 - val_loss: 0.1616 - val_auc_22: 0.9192\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1368 - auc_22: 0.9514 - val_loss: 0.1646 - val_auc_22: 0.9184\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1343 - auc_22: 0.9511 - val_loss: 0.1605 - val_auc_22: 0.9191\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1326 - auc_22: 0.9516 - val_loss: 0.1506 - val_auc_22: 0.9226\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1302 - auc_22: 0.9527 - val_loss: 0.1573 - val_auc_22: 0.9222\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1282 - auc_22: 0.9535 - val_loss: 0.1418 - val_auc_22: 0.9263\n",
      "Epoch 51/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1287 - auc_22: 0.9546 - val_loss: 0.1455 - val_auc_22: 0.9272\n",
      "Epoch 52/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1253 - auc_22: 0.9567 - val_loss: 0.1520 - val_auc_22: 0.9251\n",
      "Epoch 53/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1253 - auc_22: 0.9524 - val_loss: 0.1474 - val_auc_22: 0.9264\n",
      "Epoch 54/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1216 - auc_22: 0.9571 - val_loss: 0.1433 - val_auc_22: 0.9275\n",
      "Epoch 55/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1197 - auc_22: 0.9585 - val_loss: 0.1573 - val_auc_22: 0.9249\n",
      "Epoch 56/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1183 - auc_22: 0.9572 - val_loss: 0.1479 - val_auc_22: 0.9270\n",
      "Epoch 57/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1174 - auc_22: 0.9568 - val_loss: 0.1447 - val_auc_22: 0.9281\n",
      "Epoch 58/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1158 - auc_22: 0.9586 - val_loss: 0.1348 - val_auc_22: 0.9312\n",
      "Epoch 59/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1140 - auc_22: 0.9587 - val_loss: 0.1590 - val_auc_22: 0.9225\n",
      "Epoch 60/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1121 - auc_22: 0.9600 - val_loss: 0.1356 - val_auc_22: 0.9342\n",
      "Epoch 61/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1108 - auc_22: 0.9603 - val_loss: 0.1364 - val_auc_22: 0.9325\n",
      "Epoch 62/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1085 - auc_22: 0.9615 - val_loss: 0.1532 - val_auc_22: 0.9265\n",
      "Epoch 63/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1075 - auc_22: 0.9613 - val_loss: 0.1387 - val_auc_22: 0.9326\n",
      "Epoch 64/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1061 - auc_22: 0.9615 - val_loss: 0.1477 - val_auc_22: 0.9294\n",
      "Epoch 65/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1049 - auc_22: 0.9603 - val_loss: 0.1377 - val_auc_22: 0.9325\n",
      "Epoch 66/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1032 - auc_22: 0.9623 - val_loss: 0.1172 - val_auc_22: 0.9192\n",
      "Epoch 67/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1098 - auc_22: 0.9638 - val_loss: 0.1285 - val_auc_22: 0.9155\n",
      "Epoch 68/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1020 - auc_22: 0.9623 - val_loss: 0.1332 - val_auc_22: 0.9174\n",
      "Epoch 69/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1000 - auc_22: 0.9627 - val_loss: 0.1333 - val_auc_22: 0.9181\n",
      "Epoch 70/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0994 - auc_22: 0.9628 - val_loss: 0.1460 - val_auc_22: 0.9332\n",
      "Epoch 71/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0977 - auc_22: 0.9632 - val_loss: 0.1309 - val_auc_22: 0.9192\n",
      "Epoch 72/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0961 - auc_22: 0.9643 - val_loss: 0.1339 - val_auc_22: 0.9185\n",
      "Epoch 73/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0954 - auc_22: 0.9635 - val_loss: 0.1359 - val_auc_22: 0.9170\n",
      "Epoch 74/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0938 - auc_22: 0.9645 - val_loss: 0.1267 - val_auc_22: 0.9206\n",
      "Epoch 75/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0925 - auc_22: 0.9650 - val_loss: 0.1195 - val_auc_22: 0.9233\n",
      "Epoch 76/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0918 - auc_22: 0.9655 - val_loss: 0.1271 - val_auc_22: 0.9209\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 2s 20ms/step - loss: 0.6244 - auc_23: 0.5487 - val_loss: 0.4717 - val_auc_23: 0.6609\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.4579 - auc_23: 0.7380 - val_loss: 0.4023 - val_auc_23: 0.7702\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3806 - auc_23: 0.8044 - val_loss: 0.3646 - val_auc_23: 0.8112\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3388 - auc_23: 0.8311 - val_loss: 0.2964 - val_auc_23: 0.8448\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3112 - auc_23: 0.8589 - val_loss: 0.2538 - val_auc_23: 0.8669\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2930 - auc_23: 0.8750 - val_loss: 0.2803 - val_auc_23: 0.8591\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2787 - auc_23: 0.8823 - val_loss: 0.2507 - val_auc_23: 0.8762\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2677 - auc_23: 0.8916 - val_loss: 0.2507 - val_auc_23: 0.8786\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2582 - auc_23: 0.8960 - val_loss: 0.2486 - val_auc_23: 0.8824\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2550 - auc_23: 0.9066 - val_loss: 0.2674 - val_auc_23: 0.8769\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2440 - auc_23: 0.9039 - val_loss: 0.2175 - val_auc_23: 0.8967\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2383 - auc_23: 0.9097 - val_loss: 0.2066 - val_auc_23: 0.8986\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2344 - auc_23: 0.9119 - val_loss: 0.2306 - val_auc_23: 0.8924\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2277 - auc_23: 0.9126 - val_loss: 0.2180 - val_auc_23: 0.8975\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2230 - auc_23: 0.9153 - val_loss: 0.2251 - val_auc_23: 0.8959\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2183 - auc_23: 0.9174 - val_loss: 0.2347 - val_auc_23: 0.8921\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2135 - auc_23: 0.9176 - val_loss: 0.1895 - val_auc_23: 0.9072\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2122 - auc_23: 0.9236 - val_loss: 0.2116 - val_auc_23: 0.8988\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2050 - auc_23: 0.9216 - val_loss: 0.2013 - val_auc_23: 0.9021\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2006 - auc_23: 0.9267 - val_loss: 0.2126 - val_auc_23: 0.8989\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1960 - auc_23: 0.9276 - val_loss: 0.2078 - val_auc_23: 0.9013\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1922 - auc_23: 0.9292 - val_loss: 0.1907 - val_auc_23: 0.9073\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1881 - auc_23: 0.9307 - val_loss: 0.1951 - val_auc_23: 0.9059\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1841 - auc_23: 0.9306 - val_loss: 0.1913 - val_auc_23: 0.9080\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1809 - auc_23: 0.9338 - val_loss: 0.1870 - val_auc_23: 0.9099\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1763 - auc_23: 0.9359 - val_loss: 0.1945 - val_auc_23: 0.9070\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1736 - auc_23: 0.9354 - val_loss: 0.1990 - val_auc_23: 0.9065\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1698 - auc_23: 0.9379 - val_loss: 0.1671 - val_auc_23: 0.9130\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1664 - auc_23: 0.9386 - val_loss: 0.1927 - val_auc_23: 0.9071\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1645 - auc_23: 0.9377 - val_loss: 0.1884 - val_auc_23: 0.9099\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1613 - auc_23: 0.9465 - val_loss: 0.1814 - val_auc_23: 0.9113\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1575 - auc_23: 0.9440 - val_loss: 0.1727 - val_auc_23: 0.9146\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1542 - auc_23: 0.9440 - val_loss: 0.1564 - val_auc_23: 0.9198\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1525 - auc_23: 0.9467 - val_loss: 0.1910 - val_auc_23: 0.9098\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1490 - auc_23: 0.9477 - val_loss: 0.1799 - val_auc_23: 0.9127\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1470 - auc_23: 0.9465 - val_loss: 0.1856 - val_auc_23: 0.9130\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1439 - auc_23: 0.9461 - val_loss: 0.1462 - val_auc_23: 0.9228\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1416 - auc_23: 0.9494 - val_loss: 0.1671 - val_auc_23: 0.9162\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1389 - auc_23: 0.9492 - val_loss: 0.1524 - val_auc_23: 0.9211\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1367 - auc_23: 0.9506 - val_loss: 0.1537 - val_auc_23: 0.9208\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1345 - auc_23: 0.9510 - val_loss: 0.1666 - val_auc_23: 0.9174\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1326 - auc_23: 0.9515 - val_loss: 0.1566 - val_auc_23: 0.9220\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1301 - auc_23: 0.9527 - val_loss: 0.1655 - val_auc_23: 0.9189\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1287 - auc_23: 0.9526 - val_loss: 0.1608 - val_auc_23: 0.9208\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1259 - auc_23: 0.9535 - val_loss: 0.1660 - val_auc_23: 0.9187\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1272 - auc_23: 0.9537 - val_loss: 0.1627 - val_auc_23: 0.9204\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1227 - auc_23: 0.9551 - val_loss: 0.1493 - val_auc_23: 0.9253\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.5598 - auc_24: 0.6197 - val_loss: 0.4469 - val_auc_24: 0.6928\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.4210 - auc_24: 0.7715 - val_loss: 0.3464 - val_auc_24: 0.7789\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3516 - auc_24: 0.8273 - val_loss: 0.3085 - val_auc_24: 0.8219\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3143 - auc_24: 0.8528 - val_loss: 0.3038 - val_auc_24: 0.8310\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2915 - auc_24: 0.8711 - val_loss: 0.2991 - val_auc_24: 0.8397\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2831 - auc_24: 0.8706 - val_loss: 0.2774 - val_auc_24: 0.8498\n",
      "Epoch 7/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2668 - auc_24: 0.8845 - val_loss: 0.2696 - val_auc_24: 0.8563\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2560 - auc_24: 0.8955 - val_loss: 0.2652 - val_auc_24: 0.8607\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2470 - auc_24: 0.9007 - val_loss: 0.2590 - val_auc_24: 0.8663\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2394 - auc_24: 0.8994 - val_loss: 0.2143 - val_auc_24: 0.8801\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2308 - auc_24: 0.9080 - val_loss: 0.2139 - val_auc_24: 0.8814\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2248 - auc_24: 0.9127 - val_loss: 0.2262 - val_auc_24: 0.8830\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2178 - auc_24: 0.9152 - val_loss: 0.2334 - val_auc_24: 0.8776\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2119 - auc_24: 0.9175 - val_loss: 0.2190 - val_auc_24: 0.8813\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2062 - auc_24: 0.9196 - val_loss: 0.2177 - val_auc_24: 0.8821\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2017 - auc_24: 0.9229 - val_loss: 0.2189 - val_auc_24: 0.8818\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1953 - auc_24: 0.9261 - val_loss: 0.1957 - val_auc_24: 0.8909\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1899 - auc_24: 0.9287 - val_loss: 0.2041 - val_auc_24: 0.8893\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1854 - auc_24: 0.9287 - val_loss: 0.2050 - val_auc_24: 0.8881\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1802 - auc_24: 0.9312 - val_loss: 0.1961 - val_auc_24: 0.8907\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1765 - auc_24: 0.9323 - val_loss: 0.1840 - val_auc_24: 0.8956\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1717 - auc_24: 0.9355 - val_loss: 0.1833 - val_auc_24: 0.8958\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1678 - auc_24: 0.9375 - val_loss: 0.1818 - val_auc_24: 0.8978\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1641 - auc_24: 0.9382 - val_loss: 0.1845 - val_auc_24: 0.8971\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1603 - auc_24: 0.9391 - val_loss: 0.1468 - val_auc_24: 0.9062\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1669 - auc_24: 0.9439 - val_loss: 0.1525 - val_auc_24: 0.9079\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1542 - auc_24: 0.9438 - val_loss: 0.1865 - val_auc_24: 0.8993\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1529 - auc_24: 0.9418 - val_loss: 0.1807 - val_auc_24: 0.9018\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1485 - auc_24: 0.9454 - val_loss: 0.1793 - val_auc_24: 0.9021\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1500 - auc_24: 0.9412 - val_loss: 0.1706 - val_auc_24: 0.9025\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1429 - auc_24: 0.9466 - val_loss: 0.1645 - val_auc_24: 0.9068\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1401 - auc_24: 0.9474 - val_loss: 0.1628 - val_auc_24: 0.9073\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1375 - auc_24: 0.9489 - val_loss: 0.1474 - val_auc_24: 0.9124\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1361 - auc_24: 0.9521 - val_loss: 0.1496 - val_auc_24: 0.9150\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1330 - auc_24: 0.9519 - val_loss: 0.1472 - val_auc_24: 0.9163\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.6143 - auc_25: 0.5738 - val_loss: 0.4929 - val_auc_25: 0.6648\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.4414 - auc_25: 0.7396 - val_loss: 0.3929 - val_auc_25: 0.7823\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3623 - auc_25: 0.8152 - val_loss: 0.3215 - val_auc_25: 0.8247\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3234 - auc_25: 0.8419 - val_loss: 0.2891 - val_auc_25: 0.8479\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3015 - auc_25: 0.8610 - val_loss: 0.2730 - val_auc_25: 0.8586\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2919 - auc_25: 0.8829 - val_loss: 0.2778 - val_auc_25: 0.8591\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2772 - auc_25: 0.8833 - val_loss: 0.2803 - val_auc_25: 0.8607\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2688 - auc_25: 0.8871 - val_loss: 0.2841 - val_auc_25: 0.8614\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2638 - auc_25: 0.8871 - val_loss: 0.2570 - val_auc_25: 0.8739\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2548 - auc_25: 0.8982 - val_loss: 0.2627 - val_auc_25: 0.8742\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2490 - auc_25: 0.9026 - val_loss: 0.2672 - val_auc_25: 0.8748\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2469 - auc_25: 0.8998 - val_loss: 0.2571 - val_auc_25: 0.8796\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2392 - auc_25: 0.9075 - val_loss: 0.2411 - val_auc_25: 0.8859\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2354 - auc_25: 0.9081 - val_loss: 0.2246 - val_auc_25: 0.8930\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2305 - auc_25: 0.9115 - val_loss: 0.2152 - val_auc_25: 0.8928\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2262 - auc_25: 0.9150 - val_loss: 0.2313 - val_auc_25: 0.8924\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2226 - auc_25: 0.9150 - val_loss: 0.2329 - val_auc_25: 0.8929\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2184 - auc_25: 0.9172 - val_loss: 0.2306 - val_auc_25: 0.8938\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2147 - auc_25: 0.9183 - val_loss: 0.2169 - val_auc_25: 0.8943\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2113 - auc_25: 0.9237 - val_loss: 0.2158 - val_auc_25: 0.8946\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2075 - auc_25: 0.9252 - val_loss: 0.2024 - val_auc_25: 0.9010\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2035 - auc_25: 0.9270 - val_loss: 0.2159 - val_auc_25: 0.8956\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1997 - auc_25: 0.9248 - val_loss: 0.2002 - val_auc_25: 0.9025\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1962 - auc_25: 0.9286 - val_loss: 0.2200 - val_auc_25: 0.8960\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1951 - auc_25: 0.9279 - val_loss: 0.2304 - val_auc_25: 0.8945\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1908 - auc_25: 0.9328 - val_loss: 0.1952 - val_auc_25: 0.9043\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1863 - auc_25: 0.9328 - val_loss: 0.2036 - val_auc_25: 0.9024\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1883 - auc_25: 0.9280 - val_loss: 0.2427 - val_auc_25: 0.8899\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1852 - auc_25: 0.9317 - val_loss: 0.2022 - val_auc_25: 0.9041\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1783 - auc_25: 0.9369 - val_loss: 0.1999 - val_auc_25: 0.9056\n",
      "Epoch 31/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1746 - auc_25: 0.9369 - val_loss: 0.1820 - val_auc_25: 0.9090\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1727 - auc_25: 0.9390 - val_loss: 0.2173 - val_auc_25: 0.9016\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1721 - auc_25: 0.9358 - val_loss: 0.1753 - val_auc_25: 0.9127\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1689 - auc_25: 0.9422 - val_loss: 0.1749 - val_auc_25: 0.9140\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1652 - auc_25: 0.9410 - val_loss: 0.1980 - val_auc_25: 0.9074\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1627 - auc_25: 0.9411 - val_loss: 0.1710 - val_auc_25: 0.9144\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1612 - auc_25: 0.9423 - val_loss: 0.1621 - val_auc_25: 0.9184\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1656 - auc_25: 0.9445 - val_loss: 0.1479 - val_auc_25: 0.9193\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1566 - auc_25: 0.9451 - val_loss: 0.1725 - val_auc_25: 0.9173\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1539 - auc_25: 0.9450 - val_loss: 0.1962 - val_auc_25: 0.9119\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1573 - auc_25: 0.9423 - val_loss: 0.2047 - val_auc_25: 0.9085\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1513 - auc_25: 0.9448 - val_loss: 0.2006 - val_auc_25: 0.9104\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1483 - auc_25: 0.9463 - val_loss: 0.1667 - val_auc_25: 0.9158\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1482 - auc_25: 0.9472 - val_loss: 0.1860 - val_auc_25: 0.9136\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1446 - auc_25: 0.9475 - val_loss: 0.1801 - val_auc_25: 0.9134\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1419 - auc_25: 0.9487 - val_loss: 0.1682 - val_auc_25: 0.9178\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1402 - auc_25: 0.9496 - val_loss: 0.1726 - val_auc_25: 0.9164\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1390 - auc_25: 0.9505 - val_loss: 0.1702 - val_auc_25: 0.9188\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.6088 - auc_26: 0.5725 - val_loss: 0.4432 - val_auc_26: 0.6813\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.4546 - auc_26: 0.7309 - val_loss: 0.3373 - val_auc_26: 0.7867\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3760 - auc_26: 0.8024 - val_loss: 0.3289 - val_auc_26: 0.8122\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3298 - auc_26: 0.8365 - val_loss: 0.2736 - val_auc_26: 0.8418\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3002 - auc_26: 0.8641 - val_loss: 0.2704 - val_auc_26: 0.8500\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2785 - auc_26: 0.8745 - val_loss: 0.2275 - val_auc_26: 0.8671\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2620 - auc_26: 0.8909 - val_loss: 0.2407 - val_auc_26: 0.8633\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2488 - auc_26: 0.8950 - val_loss: 0.2244 - val_auc_26: 0.8630\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2376 - auc_26: 0.9041 - val_loss: 0.2027 - val_auc_26: 0.8685\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2286 - auc_26: 0.9082 - val_loss: 0.2119 - val_auc_26: 0.8686\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2203 - auc_26: 0.9103 - val_loss: 0.2146 - val_auc_26: 0.8672\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2129 - auc_26: 0.9143 - val_loss: 0.2104 - val_auc_26: 0.8693\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2085 - auc_26: 0.9242 - val_loss: 0.2145 - val_auc_26: 0.8687\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1999 - auc_26: 0.9209 - val_loss: 0.1933 - val_auc_26: 0.8737\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1939 - auc_26: 0.9249 - val_loss: 0.1931 - val_auc_26: 0.8747\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1887 - auc_26: 0.9285 - val_loss: 0.2006 - val_auc_26: 0.8736\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1833 - auc_26: 0.9296 - val_loss: 0.2077 - val_auc_26: 0.8731\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1772 - auc_26: 0.9320 - val_loss: 0.2020 - val_auc_26: 0.8760\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1722 - auc_26: 0.9346 - val_loss: 0.1797 - val_auc_26: 0.8820\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1662 - auc_26: 0.9396 - val_loss: 0.1960 - val_auc_26: 0.8803\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1627 - auc_26: 0.9419 - val_loss: 0.1717 - val_auc_26: 0.8828\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1581 - auc_26: 0.9441 - val_loss: 0.1622 - val_auc_26: 0.8867\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1603 - auc_26: 0.9468 - val_loss: 0.1481 - val_auc_26: 0.8884\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1521 - auc_26: 0.9454 - val_loss: 0.1660 - val_auc_26: 0.8912\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1477 - auc_26: 0.9461 - val_loss: 0.1611 - val_auc_26: 0.8916\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1452 - auc_26: 0.9464 - val_loss: 0.1655 - val_auc_26: 0.8896\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1429 - auc_26: 0.9505 - val_loss: 0.1534 - val_auc_26: 0.8797\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1386 - auc_26: 0.9498 - val_loss: 0.1579 - val_auc_26: 0.8786\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1364 - auc_26: 0.9504 - val_loss: 0.1787 - val_auc_26: 0.8740\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1330 - auc_26: 0.9506 - val_loss: 0.1636 - val_auc_26: 0.8807\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1304 - auc_26: 0.9529 - val_loss: 0.1736 - val_auc_26: 0.8785\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1311 - auc_26: 0.9517 - val_loss: 0.1813 - val_auc_26: 0.8770\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1264 - auc_26: 0.9549 - val_loss: 0.1706 - val_auc_26: 0.8807\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.6177 - auc_27: 0.5523 - val_loss: 0.4946 - val_auc_27: 0.6434\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.4724 - auc_27: 0.7100 - val_loss: 0.3822 - val_auc_27: 0.7649\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3818 - auc_27: 0.8001 - val_loss: 0.3634 - val_auc_27: 0.8026\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3302 - auc_27: 0.8321 - val_loss: 0.3095 - val_auc_27: 0.8183\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2983 - auc_27: 0.8585 - val_loss: 0.2529 - val_auc_27: 0.8355\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2769 - auc_27: 0.8837 - val_loss: 0.2815 - val_auc_27: 0.8424\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2642 - auc_27: 0.8831 - val_loss: 0.2627 - val_auc_27: 0.8377\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2501 - auc_27: 0.8966 - val_loss: 0.2271 - val_auc_27: 0.8489\n",
      "Epoch 9/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2416 - auc_27: 0.9042 - val_loss: 0.2198 - val_auc_27: 0.8534\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2322 - auc_27: 0.9089 - val_loss: 0.2075 - val_auc_27: 0.8633\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2266 - auc_27: 0.9147 - val_loss: 0.2164 - val_auc_27: 0.8622\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2191 - auc_27: 0.9146 - val_loss: 0.2002 - val_auc_27: 0.8639\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2136 - auc_27: 0.9200 - val_loss: 0.2473 - val_auc_27: 0.8554\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2116 - auc_27: 0.9137 - val_loss: 0.2330 - val_auc_27: 0.8582\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2082 - auc_27: 0.9144 - val_loss: 0.2001 - val_auc_27: 0.8714\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2007 - auc_27: 0.9237 - val_loss: 0.2178 - val_auc_27: 0.8664\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2012 - auc_27: 0.9204 - val_loss: 0.2159 - val_auc_27: 0.8668\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1936 - auc_27: 0.9269 - val_loss: 0.1891 - val_auc_27: 0.8745\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1902 - auc_27: 0.9302 - val_loss: 0.1926 - val_auc_27: 0.8772\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1876 - auc_27: 0.9290 - val_loss: 0.2057 - val_auc_27: 0.8745\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1844 - auc_27: 0.9334 - val_loss: 0.1945 - val_auc_27: 0.8765\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1809 - auc_27: 0.9331 - val_loss: 0.2081 - val_auc_27: 0.8724\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1786 - auc_27: 0.9366 - val_loss: 0.1916 - val_auc_27: 0.8796\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1753 - auc_27: 0.9371 - val_loss: 0.1946 - val_auc_27: 0.8799\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1727 - auc_27: 0.9367 - val_loss: 0.1846 - val_auc_27: 0.8825\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1696 - auc_27: 0.9392 - val_loss: 0.1691 - val_auc_27: 0.8825\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1674 - auc_27: 0.9394 - val_loss: 0.1849 - val_auc_27: 0.8840\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1658 - auc_27: 0.9394 - val_loss: 0.2010 - val_auc_27: 0.8818\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1621 - auc_27: 0.9409 - val_loss: 0.1718 - val_auc_27: 0.8844\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1600 - auc_27: 0.9441 - val_loss: 0.2040 - val_auc_27: 0.8844\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1578 - auc_27: 0.9434 - val_loss: 0.1744 - val_auc_27: 0.8861\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1550 - auc_27: 0.9469 - val_loss: 0.1748 - val_auc_27: 0.8874\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1524 - auc_27: 0.9450 - val_loss: 0.1665 - val_auc_27: 0.8893\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1533 - auc_27: 0.9485 - val_loss: 0.1640 - val_auc_27: 0.8903\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1482 - auc_27: 0.9455 - val_loss: 0.1639 - val_auc_27: 0.8896\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1457 - auc_27: 0.9486 - val_loss: 0.1882 - val_auc_27: 0.8902\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1458 - auc_27: 0.9443 - val_loss: 0.1834 - val_auc_27: 0.8931\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1430 - auc_27: 0.9462 - val_loss: 0.1741 - val_auc_27: 0.8968\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1397 - auc_27: 0.9493 - val_loss: 0.1584 - val_auc_27: 0.8786\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1381 - auc_27: 0.9520 - val_loss: 0.1624 - val_auc_27: 0.8814\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1358 - auc_27: 0.9521 - val_loss: 0.1780 - val_auc_27: 0.8968\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1339 - auc_27: 0.9515 - val_loss: 0.1645 - val_auc_27: 0.8830\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1322 - auc_27: 0.9524 - val_loss: 0.1575 - val_auc_27: 0.8825\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1302 - auc_27: 0.9537 - val_loss: 0.1516 - val_auc_27: 0.8847\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1280 - auc_27: 0.9532 - val_loss: 0.1539 - val_auc_27: 0.8833\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1270 - auc_27: 0.9572 - val_loss: 0.1747 - val_auc_27: 0.8808\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1251 - auc_27: 0.9557 - val_loss: 0.1454 - val_auc_27: 0.8871\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1242 - auc_27: 0.9596 - val_loss: 0.1286 - val_auc_27: 0.8903\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1242 - auc_27: 0.9597 - val_loss: 0.1382 - val_auc_27: 0.8908\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1240 - auc_27: 0.9612 - val_loss: 0.1574 - val_auc_27: 0.8860\n",
      "Epoch 51/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1186 - auc_27: 0.9590 - val_loss: 0.1554 - val_auc_27: 0.8861\n",
      "Epoch 52/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1172 - auc_27: 0.9606 - val_loss: 0.1490 - val_auc_27: 0.8868\n",
      "Epoch 53/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1157 - auc_27: 0.9612 - val_loss: 0.1407 - val_auc_27: 0.8868\n",
      "Epoch 54/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1146 - auc_27: 0.9636 - val_loss: 0.1669 - val_auc_27: 0.8868\n",
      "Epoch 55/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1125 - auc_27: 0.9612 - val_loss: 0.1465 - val_auc_27: 0.8872\n",
      "Epoch 56/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1113 - auc_27: 0.9620 - val_loss: 0.1475 - val_auc_27: 0.8882\n",
      "Epoch 57/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1098 - auc_27: 0.9614 - val_loss: 0.1352 - val_auc_27: 0.8894\n",
      "Epoch 58/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1082 - auc_27: 0.9629 - val_loss: 0.1572 - val_auc_27: 0.8909\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.6191 - auc_28: 0.5585 - val_loss: 0.4913 - val_auc_28: 0.6460\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.4616 - auc_28: 0.7183 - val_loss: 0.4011 - val_auc_28: 0.7591\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3825 - auc_28: 0.7931 - val_loss: 0.3482 - val_auc_28: 0.8129\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3339 - auc_28: 0.8349 - val_loss: 0.2875 - val_auc_28: 0.8343\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3033 - auc_28: 0.8649 - val_loss: 0.2486 - val_auc_28: 0.8530\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2858 - auc_28: 0.8809 - val_loss: 0.2534 - val_auc_28: 0.8521\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2682 - auc_28: 0.8885 - val_loss: 0.2493 - val_auc_28: 0.8542\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2559 - auc_28: 0.8922 - val_loss: 0.2550 - val_auc_28: 0.8540\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2447 - auc_28: 0.8985 - val_loss: 0.2265 - val_auc_28: 0.8600\n",
      "Epoch 10/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2355 - auc_28: 0.9066 - val_loss: 0.2318 - val_auc_28: 0.8624\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2280 - auc_28: 0.9093 - val_loss: 0.2326 - val_auc_28: 0.8649\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2213 - auc_28: 0.9121 - val_loss: 0.2183 - val_auc_28: 0.8610\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2168 - auc_28: 0.9171 - val_loss: 0.2421 - val_auc_28: 0.8605\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2098 - auc_28: 0.9180 - val_loss: 0.2126 - val_auc_28: 0.8623\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2047 - auc_28: 0.9216 - val_loss: 0.1904 - val_auc_28: 0.8684\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2025 - auc_28: 0.9264 - val_loss: 0.2002 - val_auc_28: 0.8677\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1963 - auc_28: 0.9261 - val_loss: 0.2223 - val_auc_28: 0.8613\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1953 - auc_28: 0.9236 - val_loss: 0.2152 - val_auc_28: 0.8620\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1880 - auc_28: 0.9302 - val_loss: 0.2126 - val_auc_28: 0.8634\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1842 - auc_28: 0.9306 - val_loss: 0.2130 - val_auc_28: 0.8664\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1812 - auc_28: 0.9327 - val_loss: 0.2061 - val_auc_28: 0.8704\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1776 - auc_28: 0.9361 - val_loss: 0.2045 - val_auc_28: 0.8668\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1748 - auc_28: 0.9362 - val_loss: 0.1765 - val_auc_28: 0.8786\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1715 - auc_28: 0.9387 - val_loss: 0.1782 - val_auc_28: 0.8788\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1695 - auc_28: 0.9404 - val_loss: 0.1897 - val_auc_28: 0.8782\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1658 - auc_28: 0.9399 - val_loss: 0.1972 - val_auc_28: 0.8772\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1622 - auc_28: 0.9410 - val_loss: 0.1837 - val_auc_28: 0.8675\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1587 - auc_28: 0.9420 - val_loss: 0.1615 - val_auc_28: 0.8688\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1563 - auc_28: 0.9458 - val_loss: 0.1827 - val_auc_28: 0.8710\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1529 - auc_28: 0.9447 - val_loss: 0.1831 - val_auc_28: 0.8713\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1503 - auc_28: 0.9457 - val_loss: 0.1889 - val_auc_28: 0.8712\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1480 - auc_28: 0.9457 - val_loss: 0.1737 - val_auc_28: 0.8748\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1454 - auc_28: 0.9464 - val_loss: 0.1814 - val_auc_28: 0.8732\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1421 - auc_28: 0.9477 - val_loss: 0.1675 - val_auc_28: 0.8736\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1397 - auc_28: 0.9498 - val_loss: 0.1542 - val_auc_28: 0.8773\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1375 - auc_28: 0.9526 - val_loss: 0.1658 - val_auc_28: 0.8762\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1353 - auc_28: 0.9496 - val_loss: 0.1613 - val_auc_28: 0.8760\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1315 - auc_28: 0.9519 - val_loss: 0.1633 - val_auc_28: 0.8758\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1293 - auc_28: 0.9530 - val_loss: 0.1434 - val_auc_28: 0.8811\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1332 - auc_28: 0.9593 - val_loss: 0.1501 - val_auc_28: 0.8804\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1250 - auc_28: 0.9550 - val_loss: 0.1500 - val_auc_28: 0.8825\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1255 - auc_28: 0.9544 - val_loss: 0.1514 - val_auc_28: 0.8857\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1209 - auc_28: 0.9571 - val_loss: 0.1547 - val_auc_28: 0.8845\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1211 - auc_28: 0.9569 - val_loss: 0.1663 - val_auc_28: 0.8814\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1174 - auc_28: 0.9590 - val_loss: 0.1547 - val_auc_28: 0.8849\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1161 - auc_28: 0.9567 - val_loss: 0.1415 - val_auc_28: 0.8849\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1134 - auc_28: 0.9606 - val_loss: 0.1345 - val_auc_28: 0.8888\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1117 - auc_28: 0.9628 - val_loss: 0.1502 - val_auc_28: 0.8854\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1099 - auc_28: 0.9619 - val_loss: 0.1503 - val_auc_28: 0.8858\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1080 - auc_28: 0.9633 - val_loss: 0.1621 - val_auc_28: 0.8849\n",
      "Epoch 51/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1081 - auc_28: 0.9610 - val_loss: 0.1365 - val_auc_28: 0.8894\n",
      "Epoch 52/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1069 - auc_28: 0.9653 - val_loss: 0.1189 - val_auc_28: 0.8740\n",
      "Epoch 53/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1033 - auc_28: 0.9668 - val_loss: 0.1439 - val_auc_28: 0.8890\n",
      "Epoch 54/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1018 - auc_28: 0.9653 - val_loss: 0.1331 - val_auc_28: 0.8922\n",
      "Epoch 55/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1003 - auc_28: 0.9662 - val_loss: 0.1373 - val_auc_28: 0.8921\n",
      "Epoch 56/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0984 - auc_28: 0.9678 - val_loss: 0.1251 - val_auc_28: 0.8774\n",
      "Epoch 57/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0969 - auc_28: 0.9683 - val_loss: 0.1304 - val_auc_28: 0.8940\n",
      "Epoch 58/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0954 - auc_28: 0.9687 - val_loss: 0.1221 - val_auc_28: 0.8761\n",
      "Epoch 59/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0939 - auc_28: 0.9692 - val_loss: 0.1147 - val_auc_28: 0.8744\n",
      "Epoch 60/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0929 - auc_28: 0.9708 - val_loss: 0.1339 - val_auc_28: 0.8951\n",
      "Epoch 61/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0915 - auc_28: 0.9690 - val_loss: 0.1297 - val_auc_28: 0.8945\n",
      "Epoch 62/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0896 - auc_28: 0.9718 - val_loss: 0.1295 - val_auc_28: 0.8975\n",
      "Epoch 63/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0889 - auc_28: 0.9692 - val_loss: 0.1144 - val_auc_28: 0.8729\n",
      "Epoch 64/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0873 - auc_28: 0.9725 - val_loss: 0.1175 - val_auc_28: 0.8773\n",
      "Epoch 65/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0860 - auc_28: 0.9711 - val_loss: 0.1179 - val_auc_28: 0.8762\n",
      "Epoch 66/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0839 - auc_28: 0.9722 - val_loss: 0.1188 - val_auc_28: 0.8763\n",
      "Epoch 67/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0826 - auc_28: 0.9732 - val_loss: 0.1303 - val_auc_28: 0.8971\n",
      "Epoch 68/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0845 - auc_28: 0.9698 - val_loss: 0.1218 - val_auc_28: 0.9003\n",
      "Epoch 69/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0812 - auc_28: 0.9722 - val_loss: 0.1171 - val_auc_28: 0.8814\n",
      "Epoch 70/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0799 - auc_28: 0.9740 - val_loss: 0.1098 - val_auc_28: 0.8766\n",
      "Epoch 71/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0777 - auc_28: 0.9748 - val_loss: 0.1084 - val_auc_28: 0.8796\n",
      "Epoch 72/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0769 - auc_28: 0.9740 - val_loss: 0.1170 - val_auc_28: 0.8809\n",
      "Epoch 73/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0753 - auc_28: 0.9752 - val_loss: 0.0990 - val_auc_28: 0.8787\n",
      "Epoch 74/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0821 - auc_28: 0.9766 - val_loss: 0.1015 - val_auc_28: 0.9022\n",
      "Epoch 75/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0748 - auc_28: 0.9753 - val_loss: 0.1143 - val_auc_28: 0.8989\n",
      "Epoch 76/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0738 - auc_28: 0.9740 - val_loss: 0.1136 - val_auc_28: 0.9001\n",
      "Epoch 77/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0720 - auc_28: 0.9760 - val_loss: 0.1007 - val_auc_28: 0.8801\n",
      "Epoch 78/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0709 - auc_28: 0.9765 - val_loss: 0.1041 - val_auc_28: 0.8790\n",
      "Epoch 79/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0700 - auc_28: 0.9772 - val_loss: 0.1002 - val_auc_28: 0.8800\n",
      "Epoch 80/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0713 - auc_28: 0.9778 - val_loss: 0.0989 - val_auc_28: 0.8810\n",
      "Epoch 81/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0694 - auc_28: 0.9773 - val_loss: 0.1143 - val_auc_28: 0.8766\n",
      "Epoch 82/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0676 - auc_28: 0.9782 - val_loss: 0.1026 - val_auc_28: 0.8802\n",
      "Epoch 83/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0665 - auc_28: 0.9790 - val_loss: 0.0977 - val_auc_28: 0.8800\n",
      "Epoch 84/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0659 - auc_28: 0.9793 - val_loss: 0.1002 - val_auc_28: 0.8795\n",
      "Epoch 85/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0658 - auc_28: 0.9788 - val_loss: 0.0989 - val_auc_28: 0.8790\n",
      "Epoch 86/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0649 - auc_28: 0.9790 - val_loss: 0.1017 - val_auc_28: 0.8812\n",
      "Epoch 87/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0638 - auc_28: 0.9805 - val_loss: 0.1083 - val_auc_28: 0.8787\n",
      "Epoch 88/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0631 - auc_28: 0.9807 - val_loss: 0.1045 - val_auc_28: 0.8783\n",
      "Epoch 89/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0629 - auc_28: 0.9797 - val_loss: 0.1006 - val_auc_28: 0.8789\n",
      "Epoch 90/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0619 - auc_28: 0.9807 - val_loss: 0.0944 - val_auc_28: 0.8814\n",
      "Epoch 91/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0609 - auc_28: 0.9808 - val_loss: 0.0973 - val_auc_28: 0.8804\n",
      "Epoch 92/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0600 - auc_28: 0.9818 - val_loss: 0.1009 - val_auc_28: 0.8796\n",
      "Epoch 93/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0594 - auc_28: 0.9808 - val_loss: 0.0843 - val_auc_28: 0.8628\n",
      "Epoch 94/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0675 - auc_28: 0.9819 - val_loss: 0.0869 - val_auc_28: 0.8848\n",
      "Epoch 95/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0591 - auc_28: 0.9808 - val_loss: 0.0960 - val_auc_28: 0.8812\n",
      "Epoch 96/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0575 - auc_28: 0.9820 - val_loss: 0.0994 - val_auc_28: 0.8828\n",
      "Epoch 97/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0569 - auc_28: 0.9817 - val_loss: 0.0876 - val_auc_28: 0.8826\n",
      "Epoch 98/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0621 - auc_28: 0.9823 - val_loss: 0.0888 - val_auc_28: 0.8837\n",
      "Epoch 99/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0562 - auc_28: 0.9823 - val_loss: 0.0885 - val_auc_28: 0.8833\n",
      "Epoch 100/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0550 - auc_28: 0.9823 - val_loss: 0.0928 - val_auc_28: 0.8816\n",
      "Epoch 101/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0545 - auc_28: 0.9822 - val_loss: 0.0915 - val_auc_28: 0.8827\n",
      "Epoch 102/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0543 - auc_28: 0.9823 - val_loss: 0.0881 - val_auc_28: 0.8823\n",
      "Epoch 103/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0536 - auc_28: 0.9823 - val_loss: 0.0946 - val_auc_28: 0.8812\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.5894 - auc_29: 0.5578 - val_loss: 0.4602 - val_auc_29: 0.6679\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.4401 - auc_29: 0.7356 - val_loss: 0.3640 - val_auc_29: 0.7890\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3532 - auc_29: 0.8274 - val_loss: 0.2803 - val_auc_29: 0.8456\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3069 - auc_29: 0.8645 - val_loss: 0.2365 - val_auc_29: 0.8540\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2748 - auc_29: 0.8830 - val_loss: 0.2558 - val_auc_29: 0.8487\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2525 - auc_29: 0.8939 - val_loss: 0.2524 - val_auc_29: 0.8533\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2384 - auc_29: 0.9028 - val_loss: 0.2142 - val_auc_29: 0.8654\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2258 - auc_29: 0.9092 - val_loss: 0.2160 - val_auc_29: 0.8719\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2160 - auc_29: 0.9144 - val_loss: 0.1944 - val_auc_29: 0.8786\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2080 - auc_29: 0.9214 - val_loss: 0.2017 - val_auc_29: 0.8734\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2008 - auc_29: 0.9216 - val_loss: 0.1848 - val_auc_29: 0.8734\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1949 - auc_29: 0.9252 - val_loss: 0.1824 - val_auc_29: 0.8755\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1883 - auc_29: 0.9288 - val_loss: 0.1884 - val_auc_29: 0.8740\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1853 - auc_29: 0.9341 - val_loss: 0.1797 - val_auc_29: 0.8775\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1789 - auc_29: 0.9306 - val_loss: 0.1585 - val_auc_29: 0.8850\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1743 - auc_29: 0.9370 - val_loss: 0.1891 - val_auc_29: 0.8797\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1700 - auc_29: 0.9336 - val_loss: 0.1789 - val_auc_29: 0.8823\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1649 - auc_29: 0.9400 - val_loss: 0.1881 - val_auc_29: 0.8818\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1657 - auc_29: 0.9343 - val_loss: 0.1886 - val_auc_29: 0.8814\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1591 - auc_29: 0.9428 - val_loss: 0.1639 - val_auc_29: 0.8838\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1550 - auc_29: 0.9450 - val_loss: 0.1741 - val_auc_29: 0.8844\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1514 - auc_29: 0.9425 - val_loss: 0.1788 - val_auc_29: 0.8893\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1494 - auc_29: 0.9404 - val_loss: 0.1591 - val_auc_29: 0.8864\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1481 - auc_29: 0.9478 - val_loss: 0.1685 - val_auc_29: 0.8897\n",
      "Epoch 25/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1447 - auc_29: 0.9425 - val_loss: 0.1545 - val_auc_29: 0.8877\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1416 - auc_29: 0.9485 - val_loss: 0.1588 - val_auc_29: 0.8908\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1374 - auc_29: 0.9493 - val_loss: 0.1848 - val_auc_29: 0.8867\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1359 - auc_29: 0.9483 - val_loss: 0.1519 - val_auc_29: 0.8775\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1346 - auc_29: 0.9529 - val_loss: 0.1520 - val_auc_29: 0.8745\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1308 - auc_29: 0.9516 - val_loss: 0.1541 - val_auc_29: 0.8757\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1285 - auc_29: 0.9514 - val_loss: 0.1505 - val_auc_29: 0.8779\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1262 - auc_29: 0.9533 - val_loss: 0.1438 - val_auc_29: 0.8652\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1244 - auc_29: 0.9558 - val_loss: 0.1621 - val_auc_29: 0.8770\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1226 - auc_29: 0.9550 - val_loss: 0.1486 - val_auc_29: 0.8834\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1236 - auc_29: 0.9583 - val_loss: 0.1325 - val_auc_29: 0.8698\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1184 - auc_29: 0.9595 - val_loss: 0.1502 - val_auc_29: 0.8677\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1164 - auc_29: 0.9597 - val_loss: 0.1408 - val_auc_29: 0.8694\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1145 - auc_29: 0.9580 - val_loss: 0.1473 - val_auc_29: 0.8689\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1127 - auc_29: 0.9612 - val_loss: 0.1508 - val_auc_29: 0.8686\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1115 - auc_29: 0.9613 - val_loss: 0.1396 - val_auc_29: 0.8687\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1092 - auc_29: 0.9618 - val_loss: 0.1381 - val_auc_29: 0.8718\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1075 - auc_29: 0.9633 - val_loss: 0.1380 - val_auc_29: 0.8720\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1058 - auc_29: 0.9630 - val_loss: 0.1232 - val_auc_29: 0.8714\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1156 - auc_29: 0.9659 - val_loss: 0.1373 - val_auc_29: 0.8682\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1037 - auc_29: 0.9650 - val_loss: 0.1413 - val_auc_29: 0.8717\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1017 - auc_29: 0.9667 - val_loss: 0.1492 - val_auc_29: 0.8727\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1006 - auc_29: 0.9647 - val_loss: 0.1366 - val_auc_29: 0.8744\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0988 - auc_29: 0.9675 - val_loss: 0.1355 - val_auc_29: 0.8727\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0975 - auc_29: 0.9687 - val_loss: 0.1400 - val_auc_29: 0.8739\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0968 - auc_29: 0.9673 - val_loss: 0.1466 - val_auc_29: 0.8754\n",
      "Epoch 51/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0949 - auc_29: 0.9673 - val_loss: 0.1318 - val_auc_29: 0.8739\n",
      "Epoch 52/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0938 - auc_29: 0.9687 - val_loss: 0.1398 - val_auc_29: 0.8753\n",
      "Epoch 53/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0924 - auc_29: 0.9683 - val_loss: 0.1203 - val_auc_29: 0.8785\n",
      "Epoch 54/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0913 - auc_29: 0.9693 - val_loss: 0.1302 - val_auc_29: 0.8763\n",
      "Epoch 55/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0898 - auc_29: 0.9705 - val_loss: 0.1409 - val_auc_29: 0.8756\n",
      "Epoch 56/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0931 - auc_29: 0.9638 - val_loss: 0.1375 - val_auc_29: 0.8749\n",
      "Epoch 57/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0883 - auc_29: 0.9688 - val_loss: 0.1268 - val_auc_29: 0.8776\n",
      "Epoch 58/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0862 - auc_29: 0.9717 - val_loss: 0.1236 - val_auc_29: 0.8787\n",
      "Epoch 59/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0853 - auc_29: 0.9725 - val_loss: 0.1175 - val_auc_29: 0.8797\n",
      "Epoch 60/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0838 - auc_29: 0.9722 - val_loss: 0.1246 - val_auc_29: 0.8800\n",
      "Epoch 61/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0826 - auc_29: 0.9725 - val_loss: 0.1232 - val_auc_29: 0.8805\n",
      "Epoch 62/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0817 - auc_29: 0.9727 - val_loss: 0.1097 - val_auc_29: 0.8817\n",
      "Epoch 63/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0828 - auc_29: 0.9738 - val_loss: 0.1240 - val_auc_29: 0.8814\n",
      "Epoch 64/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0794 - auc_29: 0.9730 - val_loss: 0.1145 - val_auc_29: 0.8816\n",
      "Epoch 65/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0784 - auc_29: 0.9735 - val_loss: 0.1172 - val_auc_29: 0.8815\n",
      "Epoch 66/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0773 - auc_29: 0.9732 - val_loss: 0.1145 - val_auc_29: 0.8818\n",
      "Epoch 67/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0770 - auc_29: 0.9720 - val_loss: 0.1130 - val_auc_29: 0.8793\n",
      "Epoch 68/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0757 - auc_29: 0.9738 - val_loss: 0.1190 - val_auc_29: 0.8807\n",
      "Epoch 69/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0755 - auc_29: 0.9728 - val_loss: 0.1106 - val_auc_29: 0.8811\n",
      "Epoch 70/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0737 - auc_29: 0.9748 - val_loss: 0.1201 - val_auc_29: 0.8816\n",
      "Epoch 71/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0727 - auc_29: 0.9753 - val_loss: 0.1128 - val_auc_29: 0.8820\n",
      "Epoch 72/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0718 - auc_29: 0.9760 - val_loss: 0.1184 - val_auc_29: 0.8807\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.6104 - auc_30: 0.5570 - val_loss: 0.5063 - val_auc_30: 0.6448\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.4708 - auc_30: 0.7137 - val_loss: 0.3879 - val_auc_30: 0.7515\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3773 - auc_30: 0.8014 - val_loss: 0.3244 - val_auc_30: 0.8152\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3271 - auc_30: 0.8475 - val_loss: 0.2677 - val_auc_30: 0.8491\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2964 - auc_30: 0.8675 - val_loss: 0.2470 - val_auc_30: 0.8617\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2774 - auc_30: 0.8809 - val_loss: 0.2491 - val_auc_30: 0.8579\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2610 - auc_30: 0.8891 - val_loss: 0.2385 - val_auc_30: 0.8619\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2496 - auc_30: 0.8933 - val_loss: 0.2383 - val_auc_30: 0.8613\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2394 - auc_30: 0.9008 - val_loss: 0.2192 - val_auc_30: 0.8667\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2329 - auc_30: 0.9061 - val_loss: 0.2260 - val_auc_30: 0.8617\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2263 - auc_30: 0.9083 - val_loss: 0.2432 - val_auc_30: 0.8589\n",
      "Epoch 12/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2202 - auc_30: 0.9095 - val_loss: 0.2134 - val_auc_30: 0.8678\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2127 - auc_30: 0.9168 - val_loss: 0.2017 - val_auc_30: 0.8719\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2071 - auc_30: 0.9248 - val_loss: 0.2111 - val_auc_30: 0.8705\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2014 - auc_30: 0.9236 - val_loss: 0.2101 - val_auc_30: 0.8724\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1965 - auc_30: 0.9232 - val_loss: 0.2116 - val_auc_30: 0.8747\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1924 - auc_30: 0.9241 - val_loss: 0.1963 - val_auc_30: 0.8790\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1868 - auc_30: 0.9307 - val_loss: 0.1733 - val_auc_30: 0.8810\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1845 - auc_30: 0.9323 - val_loss: 0.1697 - val_auc_30: 0.8855\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1828 - auc_30: 0.9372 - val_loss: 0.1833 - val_auc_30: 0.8803\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1749 - auc_30: 0.9361 - val_loss: 0.1998 - val_auc_30: 0.8812\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1725 - auc_30: 0.9340 - val_loss: 0.1782 - val_auc_30: 0.8854\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1676 - auc_30: 0.9390 - val_loss: 0.1693 - val_auc_30: 0.8875\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1677 - auc_30: 0.9429 - val_loss: 0.1783 - val_auc_30: 0.8913\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1611 - auc_30: 0.9414 - val_loss: 0.1721 - val_auc_30: 0.8887\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1577 - auc_30: 0.9420 - val_loss: 0.1819 - val_auc_30: 0.8892\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1558 - auc_30: 0.9385 - val_loss: 0.1647 - val_auc_30: 0.8947\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1518 - auc_30: 0.9445 - val_loss: 0.1830 - val_auc_30: 0.8937\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1503 - auc_30: 0.9427 - val_loss: 0.1613 - val_auc_30: 0.8965\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1464 - auc_30: 0.9463 - val_loss: 0.1574 - val_auc_30: 0.8850\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1477 - auc_30: 0.9493 - val_loss: 0.1697 - val_auc_30: 0.8967\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1427 - auc_30: 0.9460 - val_loss: 0.1638 - val_auc_30: 0.8825\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1391 - auc_30: 0.9507 - val_loss: 0.1674 - val_auc_30: 0.8849\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1369 - auc_30: 0.9499 - val_loss: 0.1572 - val_auc_30: 0.8885\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1345 - auc_30: 0.9517 - val_loss: 0.1559 - val_auc_30: 0.8902\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1321 - auc_30: 0.9529 - val_loss: 0.1582 - val_auc_30: 0.8899\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1298 - auc_30: 0.9538 - val_loss: 0.1677 - val_auc_30: 0.8913\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1301 - auc_30: 0.9524 - val_loss: 0.1680 - val_auc_30: 0.8926\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1258 - auc_30: 0.9543 - val_loss: 0.1387 - val_auc_30: 0.8935\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1241 - auc_30: 0.9575 - val_loss: 0.1498 - val_auc_30: 0.8918\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1225 - auc_30: 0.9572 - val_loss: 0.1591 - val_auc_30: 0.8918\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1238 - auc_30: 0.9544 - val_loss: 0.1611 - val_auc_30: 0.8912\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1193 - auc_30: 0.9563 - val_loss: 0.1465 - val_auc_30: 0.8924\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1165 - auc_30: 0.9590 - val_loss: 0.1397 - val_auc_30: 0.8945\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1148 - auc_30: 0.9598 - val_loss: 0.1428 - val_auc_30: 0.8948\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1132 - auc_30: 0.9606 - val_loss: 0.1342 - val_auc_30: 0.8947\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1111 - auc_30: 0.9616 - val_loss: 0.1390 - val_auc_30: 0.8958\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1099 - auc_30: 0.9617 - val_loss: 0.1466 - val_auc_30: 0.8942\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1090 - auc_30: 0.9626 - val_loss: 0.1573 - val_auc_30: 0.8935\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1069 - auc_30: 0.9614 - val_loss: 0.1417 - val_auc_30: 0.8963\n",
      "Epoch 51/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1054 - auc_30: 0.9650 - val_loss: 0.1421 - val_auc_30: 0.8961\n",
      "Epoch 52/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1036 - auc_30: 0.9641 - val_loss: 0.1415 - val_auc_30: 0.8963\n",
      "Epoch 53/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1020 - auc_30: 0.9656 - val_loss: 0.1513 - val_auc_30: 0.8940\n",
      "Epoch 54/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1030 - auc_30: 0.9631 - val_loss: 0.1426 - val_auc_30: 0.8958\n",
      "Epoch 55/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0993 - auc_30: 0.9653 - val_loss: 0.1218 - val_auc_30: 0.8978\n",
      "Epoch 56/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0981 - auc_30: 0.9677 - val_loss: 0.1134 - val_auc_30: 0.9027\n",
      "Epoch 57/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0967 - auc_30: 0.9690 - val_loss: 0.1213 - val_auc_30: 0.8995\n",
      "Epoch 58/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0947 - auc_30: 0.9694 - val_loss: 0.1187 - val_auc_30: 0.9009\n",
      "Epoch 59/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0955 - auc_30: 0.9706 - val_loss: 0.1267 - val_auc_30: 0.9038\n",
      "Epoch 60/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0920 - auc_30: 0.9705 - val_loss: 0.1219 - val_auc_30: 0.9032\n",
      "Epoch 61/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0907 - auc_30: 0.9703 - val_loss: 0.1104 - val_auc_30: 0.9051\n",
      "Epoch 62/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0902 - auc_30: 0.9716 - val_loss: 0.1175 - val_auc_30: 0.9055\n",
      "Epoch 63/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0890 - auc_30: 0.9697 - val_loss: 0.1238 - val_auc_30: 0.9033\n",
      "Epoch 64/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0870 - auc_30: 0.9730 - val_loss: 0.1225 - val_auc_30: 0.9036\n",
      "Epoch 65/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0868 - auc_30: 0.9711 - val_loss: 0.1136 - val_auc_30: 0.9050\n",
      "Epoch 66/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0881 - auc_30: 0.9735 - val_loss: 0.1249 - val_auc_30: 0.9024\n",
      "Epoch 67/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0840 - auc_30: 0.9727 - val_loss: 0.1205 - val_auc_30: 0.9047\n",
      "Epoch 68/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0834 - auc_30: 0.9727 - val_loss: 0.1331 - val_auc_30: 0.9031\n",
      "Epoch 69/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0819 - auc_30: 0.9737 - val_loss: 0.1103 - val_auc_30: 0.8893\n",
      "Epoch 70/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0812 - auc_30: 0.9732 - val_loss: 0.1178 - val_auc_30: 0.9070\n",
      "Epoch 71/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0811 - auc_30: 0.9735 - val_loss: 0.1136 - val_auc_30: 0.9083\n",
      "Epoch 72/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0786 - auc_30: 0.9760 - val_loss: 0.1279 - val_auc_30: 0.9032\n",
      "Epoch 73/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0781 - auc_30: 0.9752 - val_loss: 0.1215 - val_auc_30: 0.9062\n",
      "Epoch 74/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0768 - auc_30: 0.9747 - val_loss: 0.1145 - val_auc_30: 0.9079\n",
      "Epoch 75/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0758 - auc_30: 0.9748 - val_loss: 0.1038 - val_auc_30: 0.8914\n",
      "Epoch 76/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0746 - auc_30: 0.9762 - val_loss: 0.1162 - val_auc_30: 0.9086\n",
      "Epoch 77/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0739 - auc_30: 0.9758 - val_loss: 0.1117 - val_auc_30: 0.9094\n",
      "Epoch 78/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0774 - auc_30: 0.9717 - val_loss: 0.1186 - val_auc_30: 0.9055\n",
      "Epoch 79/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0723 - auc_30: 0.9753 - val_loss: 0.1088 - val_auc_30: 0.8897\n",
      "Epoch 80/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0712 - auc_30: 0.9768 - val_loss: 0.1124 - val_auc_30: 0.9084\n",
      "Epoch 81/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0725 - auc_30: 0.9750 - val_loss: 0.1092 - val_auc_30: 0.8905\n",
      "Epoch 82/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0693 - auc_30: 0.9765 - val_loss: 0.1060 - val_auc_30: 0.8902\n",
      "Epoch 83/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0690 - auc_30: 0.9773 - val_loss: 0.1044 - val_auc_30: 0.8904\n",
      "Epoch 84/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0678 - auc_30: 0.9775 - val_loss: 0.0977 - val_auc_30: 0.8920\n",
      "Epoch 85/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0678 - auc_30: 0.9787 - val_loss: 0.1076 - val_auc_30: 0.8907\n",
      "Epoch 86/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0667 - auc_30: 0.9778 - val_loss: 0.1099 - val_auc_30: 0.8914\n",
      "Epoch 87/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0655 - auc_30: 0.9778 - val_loss: 0.1034 - val_auc_30: 0.8927\n",
      "Epoch 88/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0650 - auc_30: 0.9778 - val_loss: 0.1070 - val_auc_30: 0.8914\n",
      "Epoch 89/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0642 - auc_30: 0.9778 - val_loss: 0.0983 - val_auc_30: 0.8927\n",
      "Epoch 90/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0632 - auc_30: 0.9787 - val_loss: 0.0935 - val_auc_30: 0.8934\n",
      "Epoch 91/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0626 - auc_30: 0.9795 - val_loss: 0.0975 - val_auc_30: 0.8923\n",
      "Epoch 92/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0617 - auc_30: 0.9790 - val_loss: 0.0980 - val_auc_30: 0.8939\n",
      "Epoch 93/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0611 - auc_30: 0.9790 - val_loss: 0.1038 - val_auc_30: 0.8921\n",
      "Epoch 94/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0603 - auc_30: 0.9790 - val_loss: 0.1035 - val_auc_30: 0.8925\n",
      "Epoch 95/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0598 - auc_30: 0.9783 - val_loss: 0.1038 - val_auc_30: 0.8922\n",
      "Epoch 96/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0595 - auc_30: 0.9792 - val_loss: 0.0873 - val_auc_30: 0.8942\n",
      "Epoch 97/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0583 - auc_30: 0.9798 - val_loss: 0.0879 - val_auc_30: 0.8933\n",
      "Epoch 98/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0578 - auc_30: 0.9808 - val_loss: 0.1072 - val_auc_30: 0.8923\n",
      "Epoch 99/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0570 - auc_30: 0.9810 - val_loss: 0.0946 - val_auc_30: 0.8949\n",
      "Epoch 100/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0560 - auc_30: 0.9810 - val_loss: 0.0920 - val_auc_30: 0.8748\n",
      "Epoch 101/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0557 - auc_30: 0.9805 - val_loss: 0.0993 - val_auc_30: 0.8936\n",
      "Epoch 102/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0553 - auc_30: 0.9812 - val_loss: 0.0937 - val_auc_30: 0.8743\n",
      "Epoch 103/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0552 - auc_30: 0.9812 - val_loss: 0.0961 - val_auc_30: 0.8736\n",
      "Epoch 104/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0542 - auc_30: 0.9815 - val_loss: 0.0906 - val_auc_30: 0.8750\n",
      "Epoch 105/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0537 - auc_30: 0.9807 - val_loss: 0.0912 - val_auc_30: 0.8733\n",
      "Epoch 106/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0527 - auc_30: 0.9823 - val_loss: 0.0869 - val_auc_30: 0.8753\n",
      "Epoch 107/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0517 - auc_30: 0.9832 - val_loss: 0.0904 - val_auc_30: 0.8733\n",
      "Epoch 108/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0507 - auc_30: 0.9823 - val_loss: 0.0817 - val_auc_30: 0.8762\n",
      "Epoch 109/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0504 - auc_30: 0.9833 - val_loss: 0.0951 - val_auc_30: 0.8743\n",
      "Epoch 110/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0511 - auc_30: 0.9823 - val_loss: 0.0910 - val_auc_30: 0.8740\n",
      "Epoch 111/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0494 - auc_30: 0.9835 - val_loss: 0.0914 - val_auc_30: 0.8755\n",
      "Epoch 112/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0487 - auc_30: 0.9833 - val_loss: 0.0844 - val_auc_30: 0.8764\n",
      "Epoch 113/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0482 - auc_30: 0.9843 - val_loss: 0.0867 - val_auc_30: 0.8772\n",
      "Epoch 114/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0475 - auc_30: 0.9845 - val_loss: 0.0867 - val_auc_30: 0.8759\n",
      "Epoch 115/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0471 - auc_30: 0.9843 - val_loss: 0.0922 - val_auc_30: 0.8763\n",
      "Epoch 116/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0465 - auc_30: 0.9843 - val_loss: 0.0888 - val_auc_30: 0.8753\n",
      "Epoch 117/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0463 - auc_30: 0.9848 - val_loss: 0.0956 - val_auc_30: 0.8758\n",
      "Epoch 118/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0453 - auc_30: 0.9850 - val_loss: 0.0879 - val_auc_30: 0.8774\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 2s 21ms/step - loss: 0.5975 - auc_31: 0.5742 - val_loss: 0.4543 - val_auc_31: 0.6776\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.4606 - auc_31: 0.7315 - val_loss: 0.3979 - val_auc_31: 0.7670\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.3887 - auc_31: 0.7982 - val_loss: 0.3261 - val_auc_31: 0.8253\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.3444 - auc_31: 0.8306 - val_loss: 0.3082 - val_auc_31: 0.8449\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.3148 - auc_31: 0.8498 - val_loss: 0.2724 - val_auc_31: 0.8703\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2931 - auc_31: 0.8656 - val_loss: 0.2730 - val_auc_31: 0.8743\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.2770 - auc_31: 0.8721 - val_loss: 0.2410 - val_auc_31: 0.8914\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.2627 - auc_31: 0.8860 - val_loss: 0.2496 - val_auc_31: 0.8915\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.2513 - auc_31: 0.8931 - val_loss: 0.2204 - val_auc_31: 0.9060\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.2434 - auc_31: 0.8994 - val_loss: 0.2284 - val_auc_31: 0.9048\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.2336 - auc_31: 0.8998 - val_loss: 0.2159 - val_auc_31: 0.9111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.2262 - auc_31: 0.9054 - val_loss: 0.2198 - val_auc_31: 0.9115\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.2208 - auc_31: 0.9069 - val_loss: 0.2367 - val_auc_31: 0.9051\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2132 - auc_31: 0.9098 - val_loss: 0.2004 - val_auc_31: 0.9157\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2066 - auc_31: 0.9163 - val_loss: 0.1754 - val_auc_31: 0.9223\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.2008 - auc_31: 0.9210 - val_loss: 0.1721 - val_auc_31: 0.9240\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 0.1975 - auc_31: 0.9297 - val_loss: 0.1813 - val_auc_31: 0.9207\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1906 - auc_31: 0.9248 - val_loss: 0.1911 - val_auc_31: 0.9169\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.1855 - auc_31: 0.9285 - val_loss: 0.1630 - val_auc_31: 0.9295\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.1806 - auc_31: 0.9324 - val_loss: 0.1744 - val_auc_31: 0.9240\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.1766 - auc_31: 0.9337 - val_loss: 0.1932 - val_auc_31: 0.9164\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1724 - auc_31: 0.9346 - val_loss: 0.1823 - val_auc_31: 0.9214\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1677 - auc_31: 0.9375 - val_loss: 0.1496 - val_auc_31: 0.9318\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.1673 - auc_31: 0.9414 - val_loss: 0.1715 - val_auc_31: 0.9272\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.1608 - auc_31: 0.9390 - val_loss: 0.1683 - val_auc_31: 0.9289\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.1565 - auc_31: 0.9431 - val_loss: 0.1678 - val_auc_31: 0.9265\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.1535 - auc_31: 0.9429 - val_loss: 0.1464 - val_auc_31: 0.9337\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.1594 - auc_31: 0.9463 - val_loss: 0.1505 - val_auc_31: 0.9355\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.1485 - auc_31: 0.9461 - val_loss: 0.1489 - val_auc_31: 0.9330\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.1448 - auc_31: 0.9464 - val_loss: 0.1614 - val_auc_31: 0.9294\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.1423 - auc_31: 0.9480 - val_loss: 0.1632 - val_auc_31: 0.9282\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.1393 - auc_31: 0.9481 - val_loss: 0.1414 - val_auc_31: 0.9355\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1371 - auc_31: 0.9491 - val_loss: 0.1487 - val_auc_31: 0.9326\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.1339 - auc_31: 0.9513 - val_loss: 0.1408 - val_auc_31: 0.9356\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.1315 - auc_31: 0.9520 - val_loss: 0.1423 - val_auc_31: 0.9350\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1293 - auc_31: 0.9538 - val_loss: 0.1395 - val_auc_31: 0.9339\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1283 - auc_31: 0.9558 - val_loss: 0.1449 - val_auc_31: 0.9328\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1249 - auc_31: 0.9543 - val_loss: 0.1294 - val_auc_31: 0.9374\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1224 - auc_31: 0.9572 - val_loss: 0.1407 - val_auc_31: 0.9339\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1205 - auc_31: 0.9564 - val_loss: 0.1633 - val_auc_31: 0.9300\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1184 - auc_31: 0.9573 - val_loss: 0.1478 - val_auc_31: 0.9315\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1161 - auc_31: 0.9580 - val_loss: 0.1415 - val_auc_31: 0.9332\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1140 - auc_31: 0.9597 - val_loss: 0.1297 - val_auc_31: 0.9363\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1122 - auc_31: 0.9595 - val_loss: 0.1254 - val_auc_31: 0.9372\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1098 - auc_31: 0.9620 - val_loss: 0.1150 - val_auc_31: 0.9395\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1079 - auc_31: 0.9610 - val_loss: 0.1262 - val_auc_31: 0.9373\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1059 - auc_31: 0.9622 - val_loss: 0.1224 - val_auc_31: 0.9385\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1047 - auc_31: 0.9627 - val_loss: 0.1365 - val_auc_31: 0.9339\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1046 - auc_31: 0.9595 - val_loss: 0.1270 - val_auc_31: 0.9346\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1004 - auc_31: 0.9628 - val_loss: 0.1186 - val_auc_31: 0.9368\n",
      "Epoch 51/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0988 - auc_31: 0.9627 - val_loss: 0.1142 - val_auc_31: 0.9380\n",
      "Epoch 52/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0970 - auc_31: 0.9652 - val_loss: 0.1177 - val_auc_31: 0.9376\n",
      "Epoch 53/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0954 - auc_31: 0.9653 - val_loss: 0.1126 - val_auc_31: 0.9370\n",
      "Epoch 54/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0979 - auc_31: 0.9652 - val_loss: 0.1127 - val_auc_31: 0.9330\n",
      "Epoch 55/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0931 - auc_31: 0.9652 - val_loss: 0.1193 - val_auc_31: 0.9320\n",
      "Epoch 56/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0916 - auc_31: 0.9650 - val_loss: 0.0986 - val_auc_31: 0.9371\n",
      "Epoch 57/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.0957 - auc_31: 0.9688 - val_loss: 0.0939 - val_auc_31: 0.9407\n",
      "Epoch 58/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.0880 - auc_31: 0.9693 - val_loss: 0.1212 - val_auc_31: 0.9353\n",
      "Epoch 59/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.0874 - auc_31: 0.9662 - val_loss: 0.1055 - val_auc_31: 0.9383\n",
      "Epoch 60/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0858 - auc_31: 0.9685 - val_loss: 0.1071 - val_auc_31: 0.9375\n",
      "Epoch 61/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.0860 - auc_31: 0.9688 - val_loss: 0.1072 - val_auc_31: 0.9367\n",
      "Epoch 62/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0829 - auc_31: 0.9705 - val_loss: 0.1107 - val_auc_31: 0.9365\n",
      "Epoch 63/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0820 - auc_31: 0.9708 - val_loss: 0.1087 - val_auc_31: 0.9345\n",
      "Epoch 64/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.0805 - auc_31: 0.9715 - val_loss: 0.1088 - val_auc_31: 0.9355\n",
      "Epoch 65/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0802 - auc_31: 0.9707 - val_loss: 0.1012 - val_auc_31: 0.9375\n",
      "Epoch 66/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.0786 - auc_31: 0.9720 - val_loss: 0.1014 - val_auc_31: 0.9379\n",
      "Epoch 67/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0772 - auc_31: 0.9715 - val_loss: 0.1019 - val_auc_31: 0.9373\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.6549 - auc_32: 0.5389 - val_loss: 0.4797 - val_auc_32: 0.6071\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.4995 - auc_32: 0.6912 - val_loss: 0.3892 - val_auc_32: 0.7520\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.4001 - auc_32: 0.7825 - val_loss: 0.3319 - val_auc_32: 0.8188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3463 - auc_32: 0.8313 - val_loss: 0.2890 - val_auc_32: 0.8530\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3138 - auc_32: 0.8547 - val_loss: 0.2910 - val_auc_32: 0.8583\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2911 - auc_32: 0.8623 - val_loss: 0.2363 - val_auc_32: 0.8839\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2771 - auc_32: 0.8810 - val_loss: 0.2352 - val_auc_32: 0.8855\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2622 - auc_32: 0.8885 - val_loss: 0.2698 - val_auc_32: 0.8731\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2522 - auc_32: 0.8878 - val_loss: 0.2383 - val_auc_32: 0.8866\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2420 - auc_32: 0.8963 - val_loss: 0.2612 - val_auc_32: 0.8806\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2354 - auc_32: 0.8952 - val_loss: 0.2088 - val_auc_32: 0.9022\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2267 - auc_32: 0.9042 - val_loss: 0.2319 - val_auc_32: 0.8940\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2206 - auc_32: 0.9061 - val_loss: 0.2035 - val_auc_32: 0.9052\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2160 - auc_32: 0.9133 - val_loss: 0.1873 - val_auc_32: 0.9080\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2074 - auc_32: 0.9153 - val_loss: 0.2068 - val_auc_32: 0.9055\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2016 - auc_32: 0.9181 - val_loss: 0.1855 - val_auc_32: 0.9106\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1963 - auc_32: 0.9206 - val_loss: 0.1849 - val_auc_32: 0.9125\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1907 - auc_32: 0.9258 - val_loss: 0.1922 - val_auc_32: 0.9100\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1870 - auc_32: 0.9291 - val_loss: 0.1917 - val_auc_32: 0.9101\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1814 - auc_32: 0.9289 - val_loss: 0.1854 - val_auc_32: 0.9113\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1772 - auc_32: 0.9296 - val_loss: 0.1771 - val_auc_32: 0.9148\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1732 - auc_32: 0.9340 - val_loss: 0.1759 - val_auc_32: 0.9160\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1690 - auc_32: 0.9352 - val_loss: 0.1747 - val_auc_32: 0.9160\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1654 - auc_32: 0.9369 - val_loss: 0.1670 - val_auc_32: 0.9185\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1631 - auc_32: 0.9377 - val_loss: 0.1489 - val_auc_32: 0.9239\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1584 - auc_32: 0.9435 - val_loss: 0.1632 - val_auc_32: 0.9186\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1567 - auc_32: 0.9426 - val_loss: 0.1723 - val_auc_32: 0.9166\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1520 - auc_32: 0.9436 - val_loss: 0.1808 - val_auc_32: 0.9152\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1495 - auc_32: 0.9444 - val_loss: 0.1727 - val_auc_32: 0.9202\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1500 - auc_32: 0.9467 - val_loss: 0.1622 - val_auc_32: 0.9193\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1445 - auc_32: 0.9462 - val_loss: 0.1603 - val_auc_32: 0.9203\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1412 - auc_32: 0.9483 - val_loss: 0.1619 - val_auc_32: 0.9196\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1389 - auc_32: 0.9473 - val_loss: 0.1586 - val_auc_32: 0.9215\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1360 - auc_32: 0.9501 - val_loss: 0.1696 - val_auc_32: 0.9175\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1345 - auc_32: 0.9506 - val_loss: 0.1763 - val_auc_32: 0.9149\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.6590 - auc_33: 0.5071 - val_loss: 0.5412 - val_auc_33: 0.5674\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.5332 - auc_33: 0.6385 - val_loss: 0.4380 - val_auc_33: 0.7221\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.4430 - auc_33: 0.7553 - val_loss: 0.3794 - val_auc_33: 0.7951\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3845 - auc_33: 0.8071 - val_loss: 0.3485 - val_auc_33: 0.8234\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3469 - auc_33: 0.8317 - val_loss: 0.3250 - val_auc_33: 0.8454\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.3202 - auc_33: 0.8493 - val_loss: 0.3095 - val_auc_33: 0.8579\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3021 - auc_33: 0.8589 - val_loss: 0.2582 - val_auc_33: 0.8859\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2878 - auc_33: 0.8780 - val_loss: 0.2530 - val_auc_33: 0.8906\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2774 - auc_33: 0.8819 - val_loss: 0.2347 - val_auc_33: 0.9008\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2682 - auc_33: 0.8899 - val_loss: 0.2365 - val_auc_33: 0.9022\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2602 - auc_33: 0.8916 - val_loss: 0.2388 - val_auc_33: 0.9039\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2519 - auc_33: 0.8969 - val_loss: 0.2178 - val_auc_33: 0.9135\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.2467 - auc_33: 0.8989 - val_loss: 0.2564 - val_auc_33: 0.8999\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.2415 - auc_33: 0.9029 - val_loss: 0.2453 - val_auc_33: 0.9055\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.2379 - auc_33: 0.9106 - val_loss: 0.2114 - val_auc_33: 0.9133\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2320 - auc_33: 0.9134 - val_loss: 0.2263 - val_auc_33: 0.9080\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2265 - auc_33: 0.9102 - val_loss: 0.2114 - val_auc_33: 0.9140\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2230 - auc_33: 0.9116 - val_loss: 0.2211 - val_auc_33: 0.9104\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2182 - auc_33: 0.9134 - val_loss: 0.2338 - val_auc_33: 0.9058\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2151 - auc_33: 0.9165 - val_loss: 0.2398 - val_auc_33: 0.9049\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2134 - auc_33: 0.9147 - val_loss: 0.2506 - val_auc_33: 0.9009\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2129 - auc_33: 0.9112 - val_loss: 0.2256 - val_auc_33: 0.9093\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2049 - auc_33: 0.9206 - val_loss: 0.2105 - val_auc_33: 0.9156\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2017 - auc_33: 0.9204 - val_loss: 0.2147 - val_auc_33: 0.9149\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1996 - auc_33: 0.9194 - val_loss: 0.2069 - val_auc_33: 0.9172\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1963 - auc_33: 0.9237 - val_loss: 0.1986 - val_auc_33: 0.9201\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1939 - auc_33: 0.9255 - val_loss: 0.1984 - val_auc_33: 0.9200\n",
      "Epoch 28/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1921 - auc_33: 0.9264 - val_loss: 0.1975 - val_auc_33: 0.9208\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1891 - auc_33: 0.9281 - val_loss: 0.1824 - val_auc_33: 0.9268\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1880 - auc_33: 0.9314 - val_loss: 0.1921 - val_auc_33: 0.9234\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1846 - auc_33: 0.9300 - val_loss: 0.1881 - val_auc_33: 0.9259\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1824 - auc_33: 0.9326 - val_loss: 0.1873 - val_auc_33: 0.9258\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1827 - auc_33: 0.9335 - val_loss: 0.1812 - val_auc_33: 0.9284\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1793 - auc_33: 0.9332 - val_loss: 0.1980 - val_auc_33: 0.9228\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1772 - auc_33: 0.9338 - val_loss: 0.1731 - val_auc_33: 0.9306\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1753 - auc_33: 0.9335 - val_loss: 0.1788 - val_auc_33: 0.9286\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1751 - auc_33: 0.9393 - val_loss: 0.1734 - val_auc_33: 0.9309\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1733 - auc_33: 0.9392 - val_loss: 0.1923 - val_auc_33: 0.9247\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1703 - auc_33: 0.9359 - val_loss: 0.1983 - val_auc_33: 0.9233\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1696 - auc_33: 0.9380 - val_loss: 0.2257 - val_auc_33: 0.9151\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1689 - auc_33: 0.9371 - val_loss: 0.1968 - val_auc_33: 0.9242\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1653 - auc_33: 0.9405 - val_loss: 0.2032 - val_auc_33: 0.9228\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1648 - auc_33: 0.9376 - val_loss: 0.1859 - val_auc_33: 0.9280\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1629 - auc_33: 0.9383 - val_loss: 0.1765 - val_auc_33: 0.9303\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1613 - auc_33: 0.9417 - val_loss: 0.1730 - val_auc_33: 0.9289\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1608 - auc_33: 0.9407 - val_loss: 0.1740 - val_auc_33: 0.9284\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1616 - auc_33: 0.9426 - val_loss: 0.1600 - val_auc_33: 0.9331\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1580 - auc_33: 0.9392 - val_loss: 0.1453 - val_auc_33: 0.9359\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1686 - auc_33: 0.9435 - val_loss: 0.1450 - val_auc_33: 0.9341\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1570 - auc_33: 0.9428 - val_loss: 0.1651 - val_auc_33: 0.9306\n",
      "Epoch 51/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1547 - auc_33: 0.9436 - val_loss: 0.1817 - val_auc_33: 0.9253\n",
      "Epoch 52/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1535 - auc_33: 0.9438 - val_loss: 0.1686 - val_auc_33: 0.9299\n",
      "Epoch 53/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1522 - auc_33: 0.9452 - val_loss: 0.1592 - val_auc_33: 0.9305\n",
      "Epoch 54/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1517 - auc_33: 0.9466 - val_loss: 0.1718 - val_auc_33: 0.9293\n",
      "Epoch 55/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1508 - auc_33: 0.9452 - val_loss: 0.1594 - val_auc_33: 0.9306\n",
      "Epoch 56/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1491 - auc_33: 0.9480 - val_loss: 0.1780 - val_auc_33: 0.9273\n",
      "Epoch 57/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1477 - auc_33: 0.9475 - val_loss: 0.1657 - val_auc_33: 0.9294\n",
      "Epoch 58/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1469 - auc_33: 0.9493 - val_loss: 0.1782 - val_auc_33: 0.9250\n",
      "Epoch 59/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1465 - auc_33: 0.9486 - val_loss: 0.1875 - val_auc_33: 0.9222\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.6289 - auc_34: 0.5610 - val_loss: 0.4520 - val_auc_34: 0.6564\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.4660 - auc_34: 0.7166 - val_loss: 0.3489 - val_auc_34: 0.7850\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3828 - auc_34: 0.7942 - val_loss: 0.3310 - val_auc_34: 0.8167\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3390 - auc_34: 0.8238 - val_loss: 0.2642 - val_auc_34: 0.8656\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3141 - auc_34: 0.8501 - val_loss: 0.2462 - val_auc_34: 0.8824\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2930 - auc_34: 0.8596 - val_loss: 0.2322 - val_auc_34: 0.8937\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2799 - auc_34: 0.8744 - val_loss: 0.2579 - val_auc_34: 0.8852\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2704 - auc_34: 0.8754 - val_loss: 0.2694 - val_auc_34: 0.8828\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2587 - auc_34: 0.8872 - val_loss: 0.2454 - val_auc_34: 0.8872\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2547 - auc_34: 0.8846 - val_loss: 0.2537 - val_auc_34: 0.8845\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2430 - auc_34: 0.8954 - val_loss: 0.2291 - val_auc_34: 0.8945\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2352 - auc_34: 0.9013 - val_loss: 0.2087 - val_auc_34: 0.9030\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2285 - auc_34: 0.9074 - val_loss: 0.2148 - val_auc_34: 0.9007\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2217 - auc_34: 0.9081 - val_loss: 0.1953 - val_auc_34: 0.9107\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2179 - auc_34: 0.9168 - val_loss: 0.2233 - val_auc_34: 0.8999\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2093 - auc_34: 0.9137 - val_loss: 0.2021 - val_auc_34: 0.9086\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2033 - auc_34: 0.9207 - val_loss: 0.1899 - val_auc_34: 0.9138\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1970 - auc_34: 0.9228 - val_loss: 0.1593 - val_auc_34: 0.9233\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1921 - auc_34: 0.9265 - val_loss: 0.1824 - val_auc_34: 0.9145\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1846 - auc_34: 0.9272 - val_loss: 0.1805 - val_auc_34: 0.9166\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1798 - auc_34: 0.9287 - val_loss: 0.1583 - val_auc_34: 0.9247\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1747 - auc_34: 0.9329 - val_loss: 0.1825 - val_auc_34: 0.9166\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1696 - auc_34: 0.9348 - val_loss: 0.1845 - val_auc_34: 0.9170\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1649 - auc_34: 0.9377 - val_loss: 0.1528 - val_auc_34: 0.9292\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1662 - auc_34: 0.9412 - val_loss: 0.1444 - val_auc_34: 0.9313\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1588 - auc_34: 0.9396 - val_loss: 0.1559 - val_auc_34: 0.9287\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1552 - auc_34: 0.9467 - val_loss: 0.1865 - val_auc_34: 0.9171\n",
      "Epoch 28/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1575 - auc_34: 0.9335 - val_loss: 0.1661 - val_auc_34: 0.9264\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1496 - auc_34: 0.9493 - val_loss: 0.1581 - val_auc_34: 0.9289\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1447 - auc_34: 0.9452 - val_loss: 0.1500 - val_auc_34: 0.9321\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1417 - auc_34: 0.9455 - val_loss: 0.1529 - val_auc_34: 0.9314\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1391 - auc_34: 0.9489 - val_loss: 0.1595 - val_auc_34: 0.9309\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1373 - auc_34: 0.9469 - val_loss: 0.1503 - val_auc_34: 0.9337\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1336 - auc_34: 0.9522 - val_loss: 0.1632 - val_auc_34: 0.9309\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1312 - auc_34: 0.9531 - val_loss: 0.1471 - val_auc_34: 0.9336\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.6612 - auc_35: 0.5000 - val_loss: 0.6206 - val_auc_35: 0.5050\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.5415 - auc_35: 0.5712 - val_loss: 0.4690 - val_auc_35: 0.6895\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.4406 - auc_35: 0.7333 - val_loss: 0.3795 - val_auc_35: 0.7930\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3764 - auc_35: 0.8056 - val_loss: 0.3109 - val_auc_35: 0.8476\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3389 - auc_35: 0.8385 - val_loss: 0.2942 - val_auc_35: 0.8620\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3147 - auc_35: 0.8567 - val_loss: 0.3140 - val_auc_35: 0.8587\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3004 - auc_35: 0.8629 - val_loss: 0.2749 - val_auc_35: 0.8795\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2855 - auc_35: 0.8761 - val_loss: 0.2339 - val_auc_35: 0.8965\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2806 - auc_35: 0.8881 - val_loss: 0.2319 - val_auc_35: 0.8986\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2690 - auc_35: 0.8861 - val_loss: 0.2189 - val_auc_35: 0.9040\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2625 - auc_35: 0.8941 - val_loss: 0.2382 - val_auc_35: 0.8970\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2583 - auc_35: 0.8965 - val_loss: 0.2088 - val_auc_35: 0.9066\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2524 - auc_35: 0.9009 - val_loss: 0.2151 - val_auc_35: 0.9047\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2449 - auc_35: 0.9006 - val_loss: 0.2186 - val_auc_35: 0.9047\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2398 - auc_35: 0.9038 - val_loss: 0.2188 - val_auc_35: 0.9051\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2400 - auc_35: 0.9087 - val_loss: 0.2137 - val_auc_35: 0.9058\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2318 - auc_35: 0.9078 - val_loss: 0.2155 - val_auc_35: 0.9065\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2275 - auc_35: 0.9108 - val_loss: 0.2163 - val_auc_35: 0.9071\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2228 - auc_35: 0.9113 - val_loss: 0.1848 - val_auc_35: 0.9200\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2230 - auc_35: 0.9182 - val_loss: 0.1845 - val_auc_35: 0.9196\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2170 - auc_35: 0.9197 - val_loss: 0.2068 - val_auc_35: 0.9117\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2129 - auc_35: 0.9159 - val_loss: 0.2055 - val_auc_35: 0.9132\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2085 - auc_35: 0.9206 - val_loss: 0.2167 - val_auc_35: 0.9096\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2050 - auc_35: 0.9217 - val_loss: 0.2250 - val_auc_35: 0.9062\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2052 - auc_35: 0.9208 - val_loss: 0.1892 - val_auc_35: 0.9158\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2013 - auc_35: 0.9267 - val_loss: 0.1984 - val_auc_35: 0.9129\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1951 - auc_35: 0.9267 - val_loss: 0.1998 - val_auc_35: 0.9119\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1916 - auc_35: 0.9277 - val_loss: 0.1828 - val_auc_35: 0.9176\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1896 - auc_35: 0.9305 - val_loss: 0.2042 - val_auc_35: 0.9095\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1867 - auc_35: 0.9269 - val_loss: 0.2104 - val_auc_35: 0.9088\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1833 - auc_35: 0.9310 - val_loss: 0.1912 - val_auc_35: 0.9144\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1831 - auc_35: 0.9283 - val_loss: 0.1948 - val_auc_35: 0.9137\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1777 - auc_35: 0.9318 - val_loss: 0.1935 - val_auc_35: 0.9142\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1774 - auc_35: 0.9306 - val_loss: 0.2118 - val_auc_35: 0.9087\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1740 - auc_35: 0.9319 - val_loss: 0.1934 - val_auc_35: 0.9137\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1710 - auc_35: 0.9340 - val_loss: 0.1905 - val_auc_35: 0.9159\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1687 - auc_35: 0.9352 - val_loss: 0.1886 - val_auc_35: 0.9171\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1669 - auc_35: 0.9351 - val_loss: 0.1915 - val_auc_35: 0.9163\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 2s 22ms/step - loss: 0.6512 - auc_36: 0.5419 - val_loss: 0.5203 - val_auc_36: 0.6210\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.5123 - auc_36: 0.6844 - val_loss: 0.4101 - val_auc_36: 0.7403\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.4213 - auc_36: 0.7765 - val_loss: 0.3563 - val_auc_36: 0.7871\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3694 - auc_36: 0.8216 - val_loss: 0.3098 - val_auc_36: 0.8236\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3360 - auc_36: 0.8407 - val_loss: 0.3243 - val_auc_36: 0.8277\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3149 - auc_36: 0.8529 - val_loss: 0.3289 - val_auc_36: 0.8325\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2955 - auc_36: 0.8641 - val_loss: 0.2999 - val_auc_36: 0.8479\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2798 - auc_36: 0.8751 - val_loss: 0.2446 - val_auc_36: 0.8752\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2697 - auc_36: 0.8902 - val_loss: 0.2772 - val_auc_36: 0.8648\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2583 - auc_36: 0.8912 - val_loss: 0.2438 - val_auc_36: 0.8798\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2537 - auc_36: 0.8972 - val_loss: 0.2555 - val_auc_36: 0.8782\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2451 - auc_36: 0.9007 - val_loss: 0.2668 - val_auc_36: 0.8766\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2381 - auc_36: 0.9028 - val_loss: 0.2561 - val_auc_36: 0.8812\n",
      "Epoch 14/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2318 - auc_36: 0.9065 - val_loss: 0.2587 - val_auc_36: 0.8817\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2273 - auc_36: 0.9072 - val_loss: 0.2224 - val_auc_36: 0.8951\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2242 - auc_36: 0.9171 - val_loss: 0.2573 - val_auc_36: 0.8850\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2177 - auc_36: 0.9093 - val_loss: 0.2296 - val_auc_36: 0.8938\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2121 - auc_36: 0.9153 - val_loss: 0.2443 - val_auc_36: 0.8889\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2081 - auc_36: 0.9164 - val_loss: 0.2346 - val_auc_36: 0.8926\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2034 - auc_36: 0.9192 - val_loss: 0.2184 - val_auc_36: 0.8992\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1996 - auc_36: 0.9218 - val_loss: 0.2276 - val_auc_36: 0.8965\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1961 - auc_36: 0.9217 - val_loss: 0.2394 - val_auc_36: 0.8947\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1927 - auc_36: 0.9242 - val_loss: 0.2301 - val_auc_36: 0.8973\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.1880 - auc_36: 0.9261 - val_loss: 0.2174 - val_auc_36: 0.9031\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.1846 - auc_36: 0.9294 - val_loss: 0.2068 - val_auc_36: 0.9027\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.1811 - auc_36: 0.9298 - val_loss: 0.2022 - val_auc_36: 0.9051\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.1780 - auc_36: 0.9313 - val_loss: 0.1980 - val_auc_36: 0.9069\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.1737 - auc_36: 0.9335 - val_loss: 0.1983 - val_auc_36: 0.9067\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.1712 - auc_36: 0.9341 - val_loss: 0.2053 - val_auc_36: 0.9047\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1675 - auc_36: 0.9356 - val_loss: 0.2046 - val_auc_36: 0.9059\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.1638 - auc_36: 0.9375 - val_loss: 0.1939 - val_auc_36: 0.9096\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 0.1607 - auc_36: 0.9381 - val_loss: 0.1798 - val_auc_36: 0.9142\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 0.1589 - auc_36: 0.9381 - val_loss: 0.1739 - val_auc_36: 0.9009\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.1557 - auc_36: 0.9411 - val_loss: 0.1984 - val_auc_36: 0.9088\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.1519 - auc_36: 0.9422 - val_loss: 0.1444 - val_auc_36: 0.9072\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.1596 - auc_36: 0.9461 - val_loss: 0.1625 - val_auc_36: 0.9035\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1479 - auc_36: 0.9460 - val_loss: 0.1939 - val_auc_36: 0.9106\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1461 - auc_36: 0.9439 - val_loss: 0.1791 - val_auc_36: 0.8972\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1423 - auc_36: 0.9461 - val_loss: 0.1667 - val_auc_36: 0.9011\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1402 - auc_36: 0.9478 - val_loss: 0.1620 - val_auc_36: 0.9020\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1381 - auc_36: 0.9499 - val_loss: 0.1566 - val_auc_36: 0.9033\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1376 - auc_36: 0.9515 - val_loss: 0.1524 - val_auc_36: 0.9057\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1341 - auc_36: 0.9536 - val_loss: 0.1721 - val_auc_36: 0.8997\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1315 - auc_36: 0.9531 - val_loss: 0.1649 - val_auc_36: 0.9023\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.1300 - auc_36: 0.9535 - val_loss: 0.1534 - val_auc_36: 0.9057\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 2s 25ms/step - loss: 0.5748 - auc_37: 0.5958 - val_loss: 0.4772 - val_auc_37: 0.6781\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.4475 - auc_37: 0.7466 - val_loss: 0.3925 - val_auc_37: 0.7680\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.3779 - auc_37: 0.8127 - val_loss: 0.3438 - val_auc_37: 0.8067\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3359 - auc_37: 0.8389 - val_loss: 0.3387 - val_auc_37: 0.8218\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.3073 - auc_37: 0.8596 - val_loss: 0.2792 - val_auc_37: 0.8554\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2898 - auc_37: 0.8690 - val_loss: 0.2933 - val_auc_37: 0.8553\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2768 - auc_37: 0.8856 - val_loss: 0.2689 - val_auc_37: 0.8682\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2652 - auc_37: 0.8909 - val_loss: 0.2661 - val_auc_37: 0.8713\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2555 - auc_37: 0.8935 - val_loss: 0.2457 - val_auc_37: 0.8818\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2477 - auc_37: 0.9002 - val_loss: 0.2482 - val_auc_37: 0.8837\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2409 - auc_37: 0.9071 - val_loss: 0.2468 - val_auc_37: 0.8860\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2348 - auc_37: 0.9070 - val_loss: 0.2531 - val_auc_37: 0.8840\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2279 - auc_37: 0.9099 - val_loss: 0.2362 - val_auc_37: 0.8918\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2224 - auc_37: 0.9142 - val_loss: 0.2313 - val_auc_37: 0.8954\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2162 - auc_37: 0.9159 - val_loss: 0.2279 - val_auc_37: 0.8975\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2115 - auc_37: 0.9181 - val_loss: 0.2190 - val_auc_37: 0.9019\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2062 - auc_37: 0.9214 - val_loss: 0.2218 - val_auc_37: 0.9020\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2010 - auc_37: 0.9227 - val_loss: 0.1947 - val_auc_37: 0.9127\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1980 - auc_37: 0.9261 - val_loss: 0.2134 - val_auc_37: 0.9045\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1927 - auc_37: 0.9264 - val_loss: 0.2173 - val_auc_37: 0.9052\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1877 - auc_37: 0.9288 - val_loss: 0.1968 - val_auc_37: 0.9133\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1837 - auc_37: 0.9295 - val_loss: 0.2026 - val_auc_37: 0.9113\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1793 - auc_37: 0.9332 - val_loss: 0.1834 - val_auc_37: 0.9139\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1754 - auc_37: 0.9336 - val_loss: 0.1791 - val_auc_37: 0.9162\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1762 - auc_37: 0.9370 - val_loss: 0.2127 - val_auc_37: 0.9089\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1686 - auc_37: 0.9356 - val_loss: 0.2170 - val_auc_37: 0.9092\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1703 - auc_37: 0.9324 - val_loss: 0.2218 - val_auc_37: 0.9036\n",
      "Epoch 28/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1640 - auc_37: 0.9357 - val_loss: 0.2103 - val_auc_37: 0.9084\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1594 - auc_37: 0.9386 - val_loss: 0.2049 - val_auc_37: 0.9084\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1563 - auc_37: 0.9411 - val_loss: 0.1727 - val_auc_37: 0.9208\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1537 - auc_37: 0.9434 - val_loss: 0.1838 - val_auc_37: 0.9169\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1514 - auc_37: 0.9432 - val_loss: 0.1903 - val_auc_37: 0.9152\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1484 - auc_37: 0.9442 - val_loss: 0.1671 - val_auc_37: 0.9232\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1491 - auc_37: 0.9484 - val_loss: 0.1552 - val_auc_37: 0.9098\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1430 - auc_37: 0.9487 - val_loss: 0.1633 - val_auc_37: 0.9083\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1409 - auc_37: 0.9468 - val_loss: 0.1524 - val_auc_37: 0.9125\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1386 - auc_37: 0.9506 - val_loss: 0.1605 - val_auc_37: 0.9092\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1360 - auc_37: 0.9520 - val_loss: 0.1789 - val_auc_37: 0.9194\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1341 - auc_37: 0.9510 - val_loss: 0.1618 - val_auc_37: 0.9084\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1319 - auc_37: 0.9515 - val_loss: 0.1616 - val_auc_37: 0.9087\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1306 - auc_37: 0.9551 - val_loss: 0.1458 - val_auc_37: 0.9132\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1377 - auc_37: 0.9561 - val_loss: 0.1516 - val_auc_37: 0.9102\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1263 - auc_37: 0.9534 - val_loss: 0.1577 - val_auc_37: 0.9087\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1239 - auc_37: 0.9554 - val_loss: 0.1692 - val_auc_37: 0.9054\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1241 - auc_37: 0.9542 - val_loss: 0.1721 - val_auc_37: 0.9056\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1210 - auc_37: 0.9559 - val_loss: 0.1581 - val_auc_37: 0.9115\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1192 - auc_37: 0.9571 - val_loss: 0.1423 - val_auc_37: 0.9160\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1175 - auc_37: 0.9593 - val_loss: 0.1699 - val_auc_37: 0.9076\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1169 - auc_37: 0.9581 - val_loss: 0.1493 - val_auc_37: 0.9142\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1147 - auc_37: 0.9605 - val_loss: 0.1433 - val_auc_37: 0.9167\n",
      "Epoch 51/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1124 - auc_37: 0.9588 - val_loss: 0.1461 - val_auc_37: 0.9161\n",
      "Epoch 52/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1106 - auc_37: 0.9603 - val_loss: 0.1521 - val_auc_37: 0.9147\n",
      "Epoch 53/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1093 - auc_37: 0.9610 - val_loss: 0.1526 - val_auc_37: 0.9146\n",
      "Epoch 54/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1078 - auc_37: 0.9598 - val_loss: 0.1386 - val_auc_37: 0.9187\n",
      "Epoch 55/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1062 - auc_37: 0.9625 - val_loss: 0.1454 - val_auc_37: 0.9175\n",
      "Epoch 56/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1054 - auc_37: 0.9633 - val_loss: 0.1341 - val_auc_37: 0.9196\n",
      "Epoch 57/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1033 - auc_37: 0.9628 - val_loss: 0.1330 - val_auc_37: 0.9204\n",
      "Epoch 58/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1015 - auc_37: 0.9637 - val_loss: 0.1256 - val_auc_37: 0.9219\n",
      "Epoch 59/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1002 - auc_37: 0.9642 - val_loss: 0.1317 - val_auc_37: 0.9180\n",
      "Epoch 60/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0996 - auc_37: 0.9633 - val_loss: 0.1272 - val_auc_37: 0.9199\n",
      "Epoch 61/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1025 - auc_37: 0.9661 - val_loss: 0.1233 - val_auc_37: 0.9211\n",
      "Epoch 62/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0968 - auc_37: 0.9652 - val_loss: 0.1269 - val_auc_37: 0.9222\n",
      "Epoch 63/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0950 - auc_37: 0.9667 - val_loss: 0.1382 - val_auc_37: 0.9192\n",
      "Epoch 64/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0944 - auc_37: 0.9655 - val_loss: 0.1319 - val_auc_37: 0.9217\n",
      "Epoch 65/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0935 - auc_37: 0.9645 - val_loss: 0.1321 - val_auc_37: 0.9206\n",
      "Epoch 66/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0917 - auc_37: 0.9677 - val_loss: 0.1291 - val_auc_37: 0.9217\n",
      "Epoch 67/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0905 - auc_37: 0.9670 - val_loss: 0.1288 - val_auc_37: 0.9220\n",
      "Epoch 68/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0892 - auc_37: 0.9685 - val_loss: 0.1313 - val_auc_37: 0.9212\n",
      "Epoch 69/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0878 - auc_37: 0.9688 - val_loss: 0.1215 - val_auc_37: 0.9253\n",
      "Epoch 70/300\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.0868 - auc_37: 0.9708 - val_loss: 0.1285 - val_auc_37: 0.9232\n",
      "Epoch 71/300\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 0.0858 - auc_37: 0.9697 - val_loss: 0.1263 - val_auc_37: 0.9245\n",
      "Epoch 72/300\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.0843 - auc_37: 0.9707 - val_loss: 0.1227 - val_auc_37: 0.9253\n",
      "Epoch 73/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.0833 - auc_37: 0.9720 - val_loss: 0.1338 - val_auc_37: 0.9219\n",
      "Epoch 74/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.0826 - auc_37: 0.9718 - val_loss: 0.1040 - val_auc_37: 0.9276\n",
      "Epoch 75/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.0884 - auc_37: 0.9730 - val_loss: 0.0965 - val_auc_37: 0.9292\n",
      "Epoch 76/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.0812 - auc_37: 0.9725 - val_loss: 0.1099 - val_auc_37: 0.9270\n",
      "Epoch 77/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0795 - auc_37: 0.9723 - val_loss: 0.1241 - val_auc_37: 0.9240\n",
      "Epoch 78/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0783 - auc_37: 0.9727 - val_loss: 0.1206 - val_auc_37: 0.9250\n",
      "Epoch 79/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0770 - auc_37: 0.9730 - val_loss: 0.1157 - val_auc_37: 0.9268\n",
      "Epoch 80/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.0785 - auc_37: 0.9717 - val_loss: 0.1327 - val_auc_37: 0.9225\n",
      "Epoch 81/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0763 - auc_37: 0.9730 - val_loss: 0.1133 - val_auc_37: 0.9264\n",
      "Epoch 82/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0744 - auc_37: 0.9738 - val_loss: 0.1151 - val_auc_37: 0.9281\n",
      "Epoch 83/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0735 - auc_37: 0.9743 - val_loss: 0.1138 - val_auc_37: 0.9274\n",
      "Epoch 84/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0722 - auc_37: 0.9748 - val_loss: 0.1074 - val_auc_37: 0.9089\n",
      "Epoch 85/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0715 - auc_37: 0.9758 - val_loss: 0.1167 - val_auc_37: 0.9280\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 2s 23ms/step - loss: 0.6770 - auc_38: 0.5158 - val_loss: 0.5118 - val_auc_38: 0.5831\n",
      "Epoch 2/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 16ms/step - loss: 0.5212 - auc_38: 0.6600 - val_loss: 0.4359 - val_auc_38: 0.7247\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.4291 - auc_38: 0.7670 - val_loss: 0.3976 - val_auc_38: 0.7673\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3740 - auc_38: 0.8094 - val_loss: 0.3608 - val_auc_38: 0.7971\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3400 - auc_38: 0.8307 - val_loss: 0.3244 - val_auc_38: 0.8228\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.3168 - auc_38: 0.8516 - val_loss: 0.3291 - val_auc_38: 0.8267\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2993 - auc_38: 0.8596 - val_loss: 0.2972 - val_auc_38: 0.8474\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2858 - auc_38: 0.8728 - val_loss: 0.2872 - val_auc_38: 0.8556\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2777 - auc_38: 0.8750 - val_loss: 0.3014 - val_auc_38: 0.8537\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2665 - auc_38: 0.8808 - val_loss: 0.2949 - val_auc_38: 0.8594\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2578 - auc_38: 0.8873 - val_loss: 0.2489 - val_auc_38: 0.8797\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2514 - auc_38: 0.8921 - val_loss: 0.2350 - val_auc_38: 0.8878\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2448 - auc_38: 0.9008 - val_loss: 0.2667 - val_auc_38: 0.8755\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2384 - auc_38: 0.9001 - val_loss: 0.2550 - val_auc_38: 0.8808\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2324 - auc_38: 0.9040 - val_loss: 0.2471 - val_auc_38: 0.8865\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2268 - auc_38: 0.9080 - val_loss: 0.2429 - val_auc_38: 0.8885\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2221 - auc_38: 0.9091 - val_loss: 0.2553 - val_auc_38: 0.8852\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2171 - auc_38: 0.9097 - val_loss: 0.2369 - val_auc_38: 0.8938\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2123 - auc_38: 0.9134 - val_loss: 0.2234 - val_auc_38: 0.8998\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2075 - auc_38: 0.9168 - val_loss: 0.2080 - val_auc_38: 0.9056\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2043 - auc_38: 0.9161 - val_loss: 0.2198 - val_auc_38: 0.9020\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1986 - auc_38: 0.9214 - val_loss: 0.2298 - val_auc_38: 0.8989\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1945 - auc_38: 0.9243 - val_loss: 0.2161 - val_auc_38: 0.9030\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1906 - auc_38: 0.9255 - val_loss: 0.2129 - val_auc_38: 0.9053\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1872 - auc_38: 0.9277 - val_loss: 0.1965 - val_auc_38: 0.9086\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1882 - auc_38: 0.9300 - val_loss: 0.1653 - val_auc_38: 0.9176\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1884 - auc_38: 0.9332 - val_loss: 0.1854 - val_auc_38: 0.9123\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1773 - auc_38: 0.9334 - val_loss: 0.2044 - val_auc_38: 0.9064\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1747 - auc_38: 0.9310 - val_loss: 0.2120 - val_auc_38: 0.9048\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1700 - auc_38: 0.9342 - val_loss: 0.2126 - val_auc_38: 0.9050\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1668 - auc_38: 0.9359 - val_loss: 0.2057 - val_auc_38: 0.9065\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1625 - auc_38: 0.9367 - val_loss: 0.1917 - val_auc_38: 0.9114\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1588 - auc_38: 0.9394 - val_loss: 0.1812 - val_auc_38: 0.9148\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1554 - auc_38: 0.9389 - val_loss: 0.1983 - val_auc_38: 0.9109\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1540 - auc_38: 0.9397 - val_loss: 0.1837 - val_auc_38: 0.9152\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1489 - auc_38: 0.9441 - val_loss: 0.1885 - val_auc_38: 0.9135\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 2s 23ms/step - loss: 0.6212 - auc_39: 0.5233 - val_loss: 0.5137 - val_auc_39: 0.6064\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.5057 - auc_39: 0.6698 - val_loss: 0.4431 - val_auc_39: 0.7236\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.4291 - auc_39: 0.7547 - val_loss: 0.3856 - val_auc_39: 0.7740\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.3823 - auc_39: 0.7997 - val_loss: 0.3595 - val_auc_39: 0.7982\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3507 - auc_39: 0.8336 - val_loss: 0.3319 - val_auc_39: 0.8202\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.3275 - auc_39: 0.8485 - val_loss: 0.3163 - val_auc_39: 0.8335\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3100 - auc_39: 0.8572 - val_loss: 0.3154 - val_auc_39: 0.8396\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2959 - auc_39: 0.8679 - val_loss: 0.3138 - val_auc_39: 0.8452\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2846 - auc_39: 0.8761 - val_loss: 0.2983 - val_auc_39: 0.8558\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2761 - auc_39: 0.8818 - val_loss: 0.2667 - val_auc_39: 0.8697\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2676 - auc_39: 0.8884 - val_loss: 0.2915 - val_auc_39: 0.8647\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2610 - auc_39: 0.8931 - val_loss: 0.2861 - val_auc_39: 0.8702\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2559 - auc_39: 0.8913 - val_loss: 0.2699 - val_auc_39: 0.8780\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2493 - auc_39: 0.9002 - val_loss: 0.2957 - val_auc_39: 0.8724\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2441 - auc_39: 0.9016 - val_loss: 0.2789 - val_auc_39: 0.8793\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2392 - auc_39: 0.9049 - val_loss: 0.2730 - val_auc_39: 0.8825\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2342 - auc_39: 0.9084 - val_loss: 0.2621 - val_auc_39: 0.8876\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2292 - auc_39: 0.9087 - val_loss: 0.2533 - val_auc_39: 0.8918\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2249 - auc_39: 0.9153 - val_loss: 0.2622 - val_auc_39: 0.8892\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2204 - auc_39: 0.9154 - val_loss: 0.2405 - val_auc_39: 0.8958\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2162 - auc_39: 0.9175 - val_loss: 0.2617 - val_auc_39: 0.8908\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2147 - auc_39: 0.9106 - val_loss: 0.2388 - val_auc_39: 0.8963\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2088 - auc_39: 0.9193 - val_loss: 0.2271 - val_auc_39: 0.8971\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.2046 - auc_39: 0.9214 - val_loss: 0.2450 - val_auc_39: 0.8966\n",
      "Epoch 25/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2015 - auc_39: 0.9225 - val_loss: 0.2509 - val_auc_39: 0.8952\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1990 - auc_39: 0.9230 - val_loss: 0.2358 - val_auc_39: 0.8949\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1937 - auc_39: 0.9269 - val_loss: 0.2141 - val_auc_39: 0.9036\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1908 - auc_39: 0.9315 - val_loss: 0.2501 - val_auc_39: 0.8915\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1879 - auc_39: 0.9276 - val_loss: 0.2204 - val_auc_39: 0.9020\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1878 - auc_39: 0.9264 - val_loss: 0.2073 - val_auc_39: 0.9032\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1856 - auc_39: 0.9331 - val_loss: 0.1727 - val_auc_39: 0.9152\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1865 - auc_39: 0.9363 - val_loss: 0.2034 - val_auc_39: 0.9056\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1762 - auc_39: 0.9345 - val_loss: 0.2315 - val_auc_39: 0.8995\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1748 - auc_39: 0.9323 - val_loss: 0.1834 - val_auc_39: 0.9149\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1732 - auc_39: 0.9388 - val_loss: 0.1860 - val_auc_39: 0.9133\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1692 - auc_39: 0.9381 - val_loss: 0.2102 - val_auc_39: 0.9052\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1672 - auc_39: 0.9351 - val_loss: 0.1852 - val_auc_39: 0.9144\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1643 - auc_39: 0.9402 - val_loss: 0.1953 - val_auc_39: 0.9113\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1622 - auc_39: 0.9379 - val_loss: 0.1837 - val_auc_39: 0.9158\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1589 - auc_39: 0.9409 - val_loss: 0.1742 - val_auc_39: 0.9207\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1573 - auc_39: 0.9438 - val_loss: 0.2040 - val_auc_39: 0.9088\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 2s 23ms/step - loss: 0.5843 - auc_40: 0.5965 - val_loss: 0.4656 - val_auc_40: 0.6729\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.4454 - auc_40: 0.7439 - val_loss: 0.3505 - val_auc_40: 0.7773\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.3685 - auc_40: 0.8151 - val_loss: 0.3271 - val_auc_40: 0.8117\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.3277 - auc_40: 0.8453 - val_loss: 0.2951 - val_auc_40: 0.8402\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.3019 - auc_40: 0.8622 - val_loss: 0.2949 - val_auc_40: 0.8478\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2830 - auc_40: 0.8763 - val_loss: 0.2517 - val_auc_40: 0.8713\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2686 - auc_40: 0.8853 - val_loss: 0.2666 - val_auc_40: 0.8678\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2571 - auc_40: 0.8927 - val_loss: 0.2962 - val_auc_40: 0.8613\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2480 - auc_40: 0.8963 - val_loss: 0.2799 - val_auc_40: 0.8694\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2413 - auc_40: 0.9027 - val_loss: 0.2677 - val_auc_40: 0.8761\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2340 - auc_40: 0.9052 - val_loss: 0.2644 - val_auc_40: 0.8776\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2277 - auc_40: 0.9086 - val_loss: 0.2277 - val_auc_40: 0.8937\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2202 - auc_40: 0.9113 - val_loss: 0.2204 - val_auc_40: 0.8972\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2145 - auc_40: 0.9142 - val_loss: 0.2350 - val_auc_40: 0.8930\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.2095 - auc_40: 0.9162 - val_loss: 0.2567 - val_auc_40: 0.8848\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2058 - auc_40: 0.9156 - val_loss: 0.2071 - val_auc_40: 0.8983\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1989 - auc_40: 0.9212 - val_loss: 0.2293 - val_auc_40: 0.8949\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1954 - auc_40: 0.9186 - val_loss: 0.2052 - val_auc_40: 0.9008\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1914 - auc_40: 0.9267 - val_loss: 0.2067 - val_auc_40: 0.9009\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1860 - auc_40: 0.9267 - val_loss: 0.1986 - val_auc_40: 0.9020\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1825 - auc_40: 0.9307 - val_loss: 0.2403 - val_auc_40: 0.8891\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1890 - auc_40: 0.9190 - val_loss: 0.2073 - val_auc_40: 0.8986\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1795 - auc_40: 0.9316 - val_loss: 0.1872 - val_auc_40: 0.9057\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1746 - auc_40: 0.9311 - val_loss: 0.2205 - val_auc_40: 0.8959\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1705 - auc_40: 0.9327 - val_loss: 0.1826 - val_auc_40: 0.9085\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1686 - auc_40: 0.9375 - val_loss: 0.1791 - val_auc_40: 0.9109\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1633 - auc_40: 0.9361 - val_loss: 0.1570 - val_auc_40: 0.9194\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1618 - auc_40: 0.9396 - val_loss: 0.1778 - val_auc_40: 0.9138\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1580 - auc_40: 0.9391 - val_loss: 0.1868 - val_auc_40: 0.9119\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.1553 - auc_40: 0.9417 - val_loss: 0.1744 - val_auc_40: 0.9005\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1526 - auc_40: 0.9428 - val_loss: 0.1797 - val_auc_40: 0.9149\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1498 - auc_40: 0.9441 - val_loss: 0.1793 - val_auc_40: 0.8996\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1482 - auc_40: 0.9444 - val_loss: 0.1715 - val_auc_40: 0.9027\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1455 - auc_40: 0.9457 - val_loss: 0.1943 - val_auc_40: 0.8959\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1458 - auc_40: 0.9433 - val_loss: 0.1715 - val_auc_40: 0.9028\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1410 - auc_40: 0.9474 - val_loss: 0.1563 - val_auc_40: 0.9083\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1385 - auc_40: 0.9498 - val_loss: 0.1711 - val_auc_40: 0.9042\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1365 - auc_40: 0.9482 - val_loss: 0.1488 - val_auc_40: 0.9102\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1328 - auc_40: 0.9520 - val_loss: 0.1737 - val_auc_40: 0.9033\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1310 - auc_40: 0.9503 - val_loss: 0.1655 - val_auc_40: 0.9057\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1283 - auc_40: 0.9515 - val_loss: 0.1456 - val_auc_40: 0.9108\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1262 - auc_40: 0.9539 - val_loss: 0.1327 - val_auc_40: 0.9162\n",
      "Epoch 43/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1243 - auc_40: 0.9568 - val_loss: 0.1539 - val_auc_40: 0.9086\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1224 - auc_40: 0.9550 - val_loss: 0.1665 - val_auc_40: 0.9059\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1201 - auc_40: 0.9571 - val_loss: 0.1643 - val_auc_40: 0.9065\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1191 - auc_40: 0.9554 - val_loss: 0.1611 - val_auc_40: 0.9071\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1163 - auc_40: 0.9574 - val_loss: 0.1338 - val_auc_40: 0.9159\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1200 - auc_40: 0.9607 - val_loss: 0.1364 - val_auc_40: 0.9156\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1126 - auc_40: 0.9610 - val_loss: 0.1541 - val_auc_40: 0.9096\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1105 - auc_40: 0.9610 - val_loss: 0.1436 - val_auc_40: 0.9142\n",
      "Epoch 51/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1095 - auc_40: 0.9601 - val_loss: 0.1401 - val_auc_40: 0.9133\n",
      "Epoch 52/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1093 - auc_40: 0.9634 - val_loss: 0.1301 - val_auc_40: 0.9172\n",
      "Epoch 53/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1091 - auc_40: 0.9642 - val_loss: 0.1283 - val_auc_40: 0.9179\n",
      "Epoch 54/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1048 - auc_40: 0.9646 - val_loss: 0.1440 - val_auc_40: 0.9133\n",
      "Epoch 55/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1032 - auc_40: 0.9633 - val_loss: 0.1385 - val_auc_40: 0.9155\n",
      "Epoch 56/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1015 - auc_40: 0.9640 - val_loss: 0.1406 - val_auc_40: 0.9150\n",
      "Epoch 57/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1005 - auc_40: 0.9643 - val_loss: 0.1426 - val_auc_40: 0.9147\n",
      "Epoch 58/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0989 - auc_40: 0.9651 - val_loss: 0.1365 - val_auc_40: 0.9171\n",
      "Epoch 59/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0971 - auc_40: 0.9670 - val_loss: 0.1248 - val_auc_40: 0.8992\n",
      "Epoch 60/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0959 - auc_40: 0.9668 - val_loss: 0.1157 - val_auc_40: 0.9022\n",
      "Epoch 61/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0988 - auc_40: 0.9692 - val_loss: 0.1257 - val_auc_40: 0.8995\n",
      "Epoch 62/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0934 - auc_40: 0.9680 - val_loss: 0.1297 - val_auc_40: 0.8988\n",
      "Epoch 63/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0922 - auc_40: 0.9680 - val_loss: 0.1070 - val_auc_40: 0.9061\n",
      "Epoch 64/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0980 - auc_40: 0.9702 - val_loss: 0.1110 - val_auc_40: 0.9043\n",
      "Epoch 65/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0902 - auc_40: 0.9688 - val_loss: 0.1323 - val_auc_40: 0.9002\n",
      "Epoch 66/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0888 - auc_40: 0.9702 - val_loss: 0.1181 - val_auc_40: 0.9021\n",
      "Epoch 67/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.0878 - auc_40: 0.9693 - val_loss: 0.1279 - val_auc_40: 0.8997\n",
      "Epoch 68/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0862 - auc_40: 0.9708 - val_loss: 0.1281 - val_auc_40: 0.8998\n",
      "Epoch 69/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0854 - auc_40: 0.9707 - val_loss: 0.1357 - val_auc_40: 0.8996\n",
      "Epoch 70/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0851 - auc_40: 0.9702 - val_loss: 0.1346 - val_auc_40: 0.8981\n",
      "Epoch 71/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0833 - auc_40: 0.9713 - val_loss: 0.1292 - val_auc_40: 0.9018\n",
      "Epoch 72/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0828 - auc_40: 0.9722 - val_loss: 0.1168 - val_auc_40: 0.9032\n",
      "Epoch 73/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0809 - auc_40: 0.9728 - val_loss: 0.1165 - val_auc_40: 0.9032\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 2s 23ms/step - loss: 0.5724 - auc_41: 0.5865 - val_loss: 0.4508 - val_auc_41: 0.6847\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.4176 - auc_41: 0.7614 - val_loss: 0.3641 - val_auc_41: 0.7829\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3504 - auc_41: 0.8244 - val_loss: 0.3376 - val_auc_41: 0.7968\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.3126 - auc_41: 0.8490 - val_loss: 0.2892 - val_auc_41: 0.8160\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2862 - auc_41: 0.8725 - val_loss: 0.2713 - val_auc_41: 0.8279\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2680 - auc_41: 0.8844 - val_loss: 0.2761 - val_auc_41: 0.8285\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2533 - auc_41: 0.8888 - val_loss: 0.2428 - val_auc_41: 0.8383\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2399 - auc_41: 0.9029 - val_loss: 0.2103 - val_auc_41: 0.8549\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2305 - auc_41: 0.9092 - val_loss: 0.2398 - val_auc_41: 0.8499\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2226 - auc_41: 0.9124 - val_loss: 0.2164 - val_auc_41: 0.8479\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2199 - auc_41: 0.9191 - val_loss: 0.2021 - val_auc_41: 0.8535\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2110 - auc_41: 0.9179 - val_loss: 0.2258 - val_auc_41: 0.8496\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2065 - auc_41: 0.9205 - val_loss: 0.2420 - val_auc_41: 0.8485\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2026 - auc_41: 0.9208 - val_loss: 0.2104 - val_auc_41: 0.8587\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1965 - auc_41: 0.9273 - val_loss: 0.2328 - val_auc_41: 0.8547\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1944 - auc_41: 0.9234 - val_loss: 0.2146 - val_auc_41: 0.8601\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1888 - auc_41: 0.9281 - val_loss: 0.1853 - val_auc_41: 0.8695\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1892 - auc_41: 0.9372 - val_loss: 0.2085 - val_auc_41: 0.8645\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1837 - auc_41: 0.9269 - val_loss: 0.1791 - val_auc_41: 0.8742\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1798 - auc_41: 0.9326 - val_loss: 0.1732 - val_auc_41: 0.8775\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1753 - auc_41: 0.9348 - val_loss: 0.2030 - val_auc_41: 0.8678\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1727 - auc_41: 0.9323 - val_loss: 0.1871 - val_auc_41: 0.8763\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1695 - auc_41: 0.9340 - val_loss: 0.1788 - val_auc_41: 0.8796\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1676 - auc_41: 0.9365 - val_loss: 0.2005 - val_auc_41: 0.8736\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1651 - auc_41: 0.9375 - val_loss: 0.1918 - val_auc_41: 0.8767\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1618 - auc_41: 0.9413 - val_loss: 0.1745 - val_auc_41: 0.8837\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1597 - auc_41: 0.9388 - val_loss: 0.1665 - val_auc_41: 0.8879\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1575 - auc_41: 0.9417 - val_loss: 0.1787 - val_auc_41: 0.8844\n",
      "Epoch 29/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1547 - auc_41: 0.9442 - val_loss: 0.1874 - val_auc_41: 0.8830\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1528 - auc_41: 0.9443 - val_loss: 0.1720 - val_auc_41: 0.8854\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1502 - auc_41: 0.9455 - val_loss: 0.1778 - val_auc_41: 0.8835\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1485 - auc_41: 0.9467 - val_loss: 0.1789 - val_auc_41: 0.8845\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1495 - auc_41: 0.9428 - val_loss: 0.1682 - val_auc_41: 0.8881\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1441 - auc_41: 0.9482 - val_loss: 0.1544 - val_auc_41: 0.8739\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1453 - auc_41: 0.9521 - val_loss: 0.1613 - val_auc_41: 0.8878\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1419 - auc_41: 0.9489 - val_loss: 0.1579 - val_auc_41: 0.8714\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1387 - auc_41: 0.9504 - val_loss: 0.1625 - val_auc_41: 0.8879\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1384 - auc_41: 0.9537 - val_loss: 0.1491 - val_auc_41: 0.8751\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1353 - auc_41: 0.9519 - val_loss: 0.1600 - val_auc_41: 0.8717\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1335 - auc_41: 0.9515 - val_loss: 0.1631 - val_auc_41: 0.8718\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1312 - auc_41: 0.9514 - val_loss: 0.1380 - val_auc_41: 0.8802\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1306 - auc_41: 0.9541 - val_loss: 0.1434 - val_auc_41: 0.8779\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1284 - auc_41: 0.9543 - val_loss: 0.1463 - val_auc_41: 0.8774\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1269 - auc_41: 0.9554 - val_loss: 0.1610 - val_auc_41: 0.8736\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1254 - auc_41: 0.9565 - val_loss: 0.1561 - val_auc_41: 0.8756\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1239 - auc_41: 0.9558 - val_loss: 0.1557 - val_auc_41: 0.8752\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1223 - auc_41: 0.9568 - val_loss: 0.1529 - val_auc_41: 0.8765\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.1210 - auc_41: 0.9581 - val_loss: 0.1433 - val_auc_41: 0.8787\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1193 - auc_41: 0.9581 - val_loss: 0.1519 - val_auc_41: 0.8777\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1179 - auc_41: 0.9589 - val_loss: 0.1460 - val_auc_41: 0.8786\n",
      "Epoch 51/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1166 - auc_41: 0.9581 - val_loss: 0.1402 - val_auc_41: 0.8800\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 2s 23ms/step - loss: 0.5850 - auc_42: 0.5951 - val_loss: 0.4047 - val_auc_42: 0.6837\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.4225 - auc_42: 0.7771 - val_loss: 0.3301 - val_auc_42: 0.7946\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3398 - auc_42: 0.8372 - val_loss: 0.2745 - val_auc_42: 0.8218\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2990 - auc_42: 0.8610 - val_loss: 0.2553 - val_auc_42: 0.8314\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2760 - auc_42: 0.8830 - val_loss: 0.2517 - val_auc_42: 0.8369\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2589 - auc_42: 0.8895 - val_loss: 0.2193 - val_auc_42: 0.8415\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2481 - auc_42: 0.9000 - val_loss: 0.2402 - val_auc_42: 0.8385\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2388 - auc_42: 0.8997 - val_loss: 0.2634 - val_auc_42: 0.8339\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2311 - auc_42: 0.9055 - val_loss: 0.2373 - val_auc_42: 0.8450\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2259 - auc_42: 0.9078 - val_loss: 0.2310 - val_auc_42: 0.8494\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2200 - auc_42: 0.9102 - val_loss: 0.2183 - val_auc_42: 0.8553\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2175 - auc_42: 0.9160 - val_loss: 0.2151 - val_auc_42: 0.8584\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2138 - auc_42: 0.9118 - val_loss: 0.2225 - val_auc_42: 0.8573\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2094 - auc_42: 0.9142 - val_loss: 0.2192 - val_auc_42: 0.8587\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2045 - auc_42: 0.9161 - val_loss: 0.1916 - val_auc_42: 0.8646\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2008 - auc_42: 0.9230 - val_loss: 0.1930 - val_auc_42: 0.8658\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1973 - auc_42: 0.9222 - val_loss: 0.1993 - val_auc_42: 0.8690\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1935 - auc_42: 0.9230 - val_loss: 0.1954 - val_auc_42: 0.8671\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1913 - auc_42: 0.9284 - val_loss: 0.1817 - val_auc_42: 0.8726\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1886 - auc_42: 0.9290 - val_loss: 0.2031 - val_auc_42: 0.8748\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1841 - auc_42: 0.9296 - val_loss: 0.2056 - val_auc_42: 0.8731\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1812 - auc_42: 0.9264 - val_loss: 0.1818 - val_auc_42: 0.8766\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1773 - auc_42: 0.9313 - val_loss: 0.1793 - val_auc_42: 0.8824\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1748 - auc_42: 0.9327 - val_loss: 0.1937 - val_auc_42: 0.8800\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1710 - auc_42: 0.9336 - val_loss: 0.1748 - val_auc_42: 0.8836\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1682 - auc_42: 0.9376 - val_loss: 0.1906 - val_auc_42: 0.8830\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1652 - auc_42: 0.9374 - val_loss: 0.1840 - val_auc_42: 0.8828\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1635 - auc_42: 0.9394 - val_loss: 0.1693 - val_auc_42: 0.8871\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1595 - auc_42: 0.9416 - val_loss: 0.1743 - val_auc_42: 0.8866\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1572 - auc_42: 0.9387 - val_loss: 0.1607 - val_auc_42: 0.8910\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1549 - auc_42: 0.9459 - val_loss: 0.1745 - val_auc_42: 0.8894\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1536 - auc_42: 0.9463 - val_loss: 0.1460 - val_auc_42: 0.8963\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1494 - auc_42: 0.9464 - val_loss: 0.1728 - val_auc_42: 0.8910\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1466 - auc_42: 0.9472 - val_loss: 0.1649 - val_auc_42: 0.8938\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1446 - auc_42: 0.9502 - val_loss: 0.1567 - val_auc_42: 0.8966\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.1422 - auc_42: 0.9489 - val_loss: 0.1813 - val_auc_42: 0.8906\n",
      "Epoch 37/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 19ms/step - loss: 0.1396 - auc_42: 0.9499 - val_loss: 0.1644 - val_auc_42: 0.8958\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.1374 - auc_42: 0.9503 - val_loss: 0.1636 - val_auc_42: 0.8968\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.1355 - auc_42: 0.9519 - val_loss: 0.1728 - val_auc_42: 0.8956\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.1333 - auc_42: 0.9515 - val_loss: 0.1455 - val_auc_42: 0.8997\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.1307 - auc_42: 0.9557 - val_loss: 0.1473 - val_auc_42: 0.9001\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 0.1283 - auc_42: 0.9573 - val_loss: 0.1553 - val_auc_42: 0.8994\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1273 - auc_42: 0.9547 - val_loss: 0.1361 - val_auc_42: 0.9044\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1302 - auc_42: 0.9595 - val_loss: 0.1360 - val_auc_42: 0.9063\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.1235 - auc_42: 0.9589 - val_loss: 0.1677 - val_auc_42: 0.8986\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.1221 - auc_42: 0.9561 - val_loss: 0.1468 - val_auc_42: 0.9027\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1193 - auc_42: 0.9604 - val_loss: 0.1478 - val_auc_42: 0.9025\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.1168 - auc_42: 0.9605 - val_loss: 0.1595 - val_auc_42: 0.8995\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.1150 - auc_42: 0.9592 - val_loss: 0.1416 - val_auc_42: 0.9046\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1145 - auc_42: 0.9593 - val_loss: 0.1281 - val_auc_42: 0.9079\n",
      "Epoch 51/300\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.1119 - auc_42: 0.9622 - val_loss: 0.1339 - val_auc_42: 0.9067\n",
      "Epoch 52/300\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.1102 - auc_42: 0.9628 - val_loss: 0.1476 - val_auc_42: 0.9040\n",
      "Epoch 53/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1085 - auc_42: 0.9634 - val_loss: 0.1245 - val_auc_42: 0.9090\n",
      "Epoch 54/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1136 - auc_42: 0.9641 - val_loss: 0.1242 - val_auc_42: 0.9104\n",
      "Epoch 55/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1062 - auc_42: 0.9647 - val_loss: 0.1290 - val_auc_42: 0.9089\n",
      "Epoch 56/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1099 - auc_42: 0.9664 - val_loss: 0.1433 - val_auc_42: 0.9074\n",
      "Epoch 57/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1036 - auc_42: 0.9645 - val_loss: 0.1491 - val_auc_42: 0.9041\n",
      "Epoch 58/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1016 - auc_42: 0.9643 - val_loss: 0.1299 - val_auc_42: 0.9083\n",
      "Epoch 59/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.1013 - auc_42: 0.9660 - val_loss: 0.1302 - val_auc_42: 0.9091\n",
      "Epoch 60/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0993 - auc_42: 0.9641 - val_loss: 0.1300 - val_auc_42: 0.9090\n",
      "Epoch 61/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0973 - auc_42: 0.9657 - val_loss: 0.1321 - val_auc_42: 0.9091\n",
      "Epoch 62/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.0962 - auc_42: 0.9669 - val_loss: 0.1248 - val_auc_42: 0.9085\n",
      "Epoch 63/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0953 - auc_42: 0.9671 - val_loss: 0.1254 - val_auc_42: 0.9089\n",
      "Epoch 64/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0958 - auc_42: 0.9645 - val_loss: 0.1336 - val_auc_42: 0.9089\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 2s 21ms/step - loss: 0.6498 - auc_43: 0.5147 - val_loss: 0.5176 - val_auc_43: 0.5767\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.4947 - auc_43: 0.6826 - val_loss: 0.4429 - val_auc_43: 0.7166\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3921 - auc_43: 0.7959 - val_loss: 0.3457 - val_auc_43: 0.7712\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3312 - auc_43: 0.8412 - val_loss: 0.3075 - val_auc_43: 0.7981\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2973 - auc_43: 0.8598 - val_loss: 0.2570 - val_auc_43: 0.8251\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.2761 - auc_43: 0.8790 - val_loss: 0.2610 - val_auc_43: 0.8274\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.2594 - auc_43: 0.8875 - val_loss: 0.2189 - val_auc_43: 0.8446\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.2463 - auc_43: 0.9002 - val_loss: 0.2536 - val_auc_43: 0.8360\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.2379 - auc_43: 0.9020 - val_loss: 0.2388 - val_auc_43: 0.8462\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.2281 - auc_43: 0.9101 - val_loss: 0.2258 - val_auc_43: 0.8438\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.2217 - auc_43: 0.9133 - val_loss: 0.2271 - val_auc_43: 0.8470\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.2156 - auc_43: 0.9169 - val_loss: 0.2252 - val_auc_43: 0.8499\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.2092 - auc_43: 0.9203 - val_loss: 0.2318 - val_auc_43: 0.8507\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.2056 - auc_43: 0.9190 - val_loss: 0.2155 - val_auc_43: 0.8588\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.2019 - auc_43: 0.9201 - val_loss: 0.1984 - val_auc_43: 0.8629\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.1955 - auc_43: 0.9252 - val_loss: 0.2104 - val_auc_43: 0.8643\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.1918 - auc_43: 0.9308 - val_loss: 0.2111 - val_auc_43: 0.8663\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.1873 - auc_43: 0.9302 - val_loss: 0.2156 - val_auc_43: 0.8653\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.1882 - auc_43: 0.9242 - val_loss: 0.2017 - val_auc_43: 0.8697\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.1806 - auc_43: 0.9322 - val_loss: 0.2115 - val_auc_43: 0.8691\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1765 - auc_43: 0.9353 - val_loss: 0.1696 - val_auc_43: 0.8806\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1731 - auc_43: 0.9366 - val_loss: 0.1657 - val_auc_43: 0.8829\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1700 - auc_43: 0.9419 - val_loss: 0.1823 - val_auc_43: 0.8812\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1658 - auc_43: 0.9406 - val_loss: 0.1815 - val_auc_43: 0.8825\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1647 - auc_43: 0.9391 - val_loss: 0.1949 - val_auc_43: 0.8804\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1607 - auc_43: 0.9437 - val_loss: 0.1597 - val_auc_43: 0.8888\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1570 - auc_43: 0.9451 - val_loss: 0.1750 - val_auc_43: 0.8874\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1531 - auc_43: 0.9449 - val_loss: 0.1830 - val_auc_43: 0.8872\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1502 - auc_43: 0.9450 - val_loss: 0.1757 - val_auc_43: 0.8904\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.1468 - auc_43: 0.9453 - val_loss: 0.1763 - val_auc_43: 0.8911\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.1442 - auc_43: 0.9466 - val_loss: 0.1713 - val_auc_43: 0.8902\n",
      "Epoch 32/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 20ms/step - loss: 0.1415 - auc_43: 0.9491 - val_loss: 0.1677 - val_auc_43: 0.8918\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.1396 - auc_43: 0.9500 - val_loss: 0.1775 - val_auc_43: 0.8909\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.1366 - auc_43: 0.9533 - val_loss: 0.1601 - val_auc_43: 0.8967\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 0.1338 - auc_43: 0.9515 - val_loss: 0.1570 - val_auc_43: 0.8980\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.1324 - auc_43: 0.9532 - val_loss: 0.1500 - val_auc_43: 0.8967\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1292 - auc_43: 0.9530 - val_loss: 0.1548 - val_auc_43: 0.8999\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.1271 - auc_43: 0.9538 - val_loss: 0.1494 - val_auc_43: 0.8997\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1251 - auc_43: 0.9544 - val_loss: 0.1340 - val_auc_43: 0.9002\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1297 - auc_43: 0.9603 - val_loss: 0.1320 - val_auc_43: 0.9014\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1218 - auc_43: 0.9575 - val_loss: 0.1504 - val_auc_43: 0.8986\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.1199 - auc_43: 0.9566 - val_loss: 0.1654 - val_auc_43: 0.9012\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1181 - auc_43: 0.9574 - val_loss: 0.1535 - val_auc_43: 0.8997\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1161 - auc_43: 0.9594 - val_loss: 0.1358 - val_auc_43: 0.9039\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.1145 - auc_43: 0.9617 - val_loss: 0.1556 - val_auc_43: 0.9023\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1134 - auc_43: 0.9585 - val_loss: 0.1395 - val_auc_43: 0.9033\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.1110 - auc_43: 0.9618 - val_loss: 0.1683 - val_auc_43: 0.9000\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.1126 - auc_43: 0.9586 - val_loss: 0.1407 - val_auc_43: 0.9030\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1079 - auc_43: 0.9621 - val_loss: 0.1400 - val_auc_43: 0.9035\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1068 - auc_43: 0.9629 - val_loss: 0.1482 - val_auc_43: 0.9033\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.5537 - auc_44: 0.6315 - val_loss: 0.3819 - val_auc_44: 0.7280\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3905 - auc_44: 0.7922 - val_loss: 0.2926 - val_auc_44: 0.8099\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.3178 - auc_44: 0.8514 - val_loss: 0.2389 - val_auc_44: 0.8361\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.2852 - auc_44: 0.8775 - val_loss: 0.2377 - val_auc_44: 0.8395\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.2618 - auc_44: 0.8856 - val_loss: 0.2476 - val_auc_44: 0.8416\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2469 - auc_44: 0.8954 - val_loss: 0.2234 - val_auc_44: 0.8532\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.2356 - auc_44: 0.9049 - val_loss: 0.2593 - val_auc_44: 0.8460\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.2270 - auc_44: 0.9036 - val_loss: 0.2360 - val_auc_44: 0.8465\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2188 - auc_44: 0.9100 - val_loss: 0.2253 - val_auc_44: 0.8522\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2147 - auc_44: 0.9134 - val_loss: 0.2156 - val_auc_44: 0.8570\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.2093 - auc_44: 0.9129 - val_loss: 0.1917 - val_auc_44: 0.8645\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.2033 - auc_44: 0.9150 - val_loss: 0.1929 - val_auc_44: 0.8656\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.1980 - auc_44: 0.9174 - val_loss: 0.2089 - val_auc_44: 0.8622\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.1936 - auc_44: 0.9180 - val_loss: 0.1879 - val_auc_44: 0.8695\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.1889 - auc_44: 0.9234 - val_loss: 0.1956 - val_auc_44: 0.8703\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.1844 - auc_44: 0.9253 - val_loss: 0.1778 - val_auc_44: 0.8762\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.1802 - auc_44: 0.9282 - val_loss: 0.1818 - val_auc_44: 0.8759\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.1762 - auc_44: 0.9311 - val_loss: 0.2067 - val_auc_44: 0.8729\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.1726 - auc_44: 0.9298 - val_loss: 0.1854 - val_auc_44: 0.8791\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.1680 - auc_44: 0.9326 - val_loss: 0.1654 - val_auc_44: 0.8851\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.1647 - auc_44: 0.9356 - val_loss: 0.1853 - val_auc_44: 0.8811\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.1630 - auc_44: 0.9377 - val_loss: 0.1652 - val_auc_44: 0.8871\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.1584 - auc_44: 0.9382 - val_loss: 0.1743 - val_auc_44: 0.8884\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.1547 - auc_44: 0.9379 - val_loss: 0.1775 - val_auc_44: 0.8895\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.1505 - auc_44: 0.9400 - val_loss: 0.1497 - val_auc_44: 0.8974\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 0.1477 - auc_44: 0.9422 - val_loss: 0.1569 - val_auc_44: 0.8971\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.1445 - auc_44: 0.9442 - val_loss: 0.1470 - val_auc_44: 0.8944\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 0.1414 - auc_44: 0.9464 - val_loss: 0.1538 - val_auc_44: 0.8974\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.1427 - auc_44: 0.9498 - val_loss: 0.1542 - val_auc_44: 0.8944\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.1369 - auc_44: 0.9464 - val_loss: 0.1469 - val_auc_44: 0.8969\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.1340 - auc_44: 0.9504 - val_loss: 0.1684 - val_auc_44: 0.8931\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.1338 - auc_44: 0.9473 - val_loss: 0.1503 - val_auc_44: 0.8965\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.1299 - auc_44: 0.9537 - val_loss: 0.1462 - val_auc_44: 0.8975\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1269 - auc_44: 0.9527 - val_loss: 0.1351 - val_auc_44: 0.9006\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1245 - auc_44: 0.9534 - val_loss: 0.1299 - val_auc_44: 0.9018\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.1248 - auc_44: 0.9583 - val_loss: 0.1445 - val_auc_44: 0.8983\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.1207 - auc_44: 0.9563 - val_loss: 0.1396 - val_auc_44: 0.9008\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1187 - auc_44: 0.9581 - val_loss: 0.1609 - val_auc_44: 0.8994\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1186 - auc_44: 0.9561 - val_loss: 0.1421 - val_auc_44: 0.9014\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1158 - auc_44: 0.9562 - val_loss: 0.1431 - val_auc_44: 0.9033\n",
      "Epoch 41/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1138 - auc_44: 0.9587 - val_loss: 0.1292 - val_auc_44: 0.9069\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1122 - auc_44: 0.9592 - val_loss: 0.1522 - val_auc_44: 0.9024\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1103 - auc_44: 0.9595 - val_loss: 0.1156 - val_auc_44: 0.9080\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1080 - auc_44: 0.9607 - val_loss: 0.1257 - val_auc_44: 0.9068\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1065 - auc_44: 0.9610 - val_loss: 0.1093 - val_auc_44: 0.9089\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.1100 - auc_44: 0.9654 - val_loss: 0.1258 - val_auc_44: 0.9076\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1029 - auc_44: 0.9634 - val_loss: 0.1448 - val_auc_44: 0.9036\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1017 - auc_44: 0.9621 - val_loss: 0.1128 - val_auc_44: 0.9078\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1020 - auc_44: 0.9672 - val_loss: 0.1356 - val_auc_44: 0.9065\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0988 - auc_44: 0.9654 - val_loss: 0.1406 - val_auc_44: 0.9066\n",
      "Epoch 51/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1093 - auc_44: 0.9557 - val_loss: 0.1489 - val_auc_44: 0.9039\n",
      "Epoch 52/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0968 - auc_44: 0.9644 - val_loss: 0.1022 - val_auc_44: 0.9093\n",
      "Epoch 53/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0994 - auc_44: 0.9681 - val_loss: 0.1168 - val_auc_44: 0.9110\n",
      "Epoch 54/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0936 - auc_44: 0.9656 - val_loss: 0.1208 - val_auc_44: 0.9092\n",
      "Epoch 55/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0921 - auc_44: 0.9667 - val_loss: 0.1195 - val_auc_44: 0.9100\n",
      "Epoch 56/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0910 - auc_44: 0.9670 - val_loss: 0.1202 - val_auc_44: 0.9093\n",
      "Epoch 57/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0901 - auc_44: 0.9669 - val_loss: 0.1082 - val_auc_44: 0.9088\n",
      "Epoch 58/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.0901 - auc_44: 0.9701 - val_loss: 0.1183 - val_auc_44: 0.9073\n",
      "Epoch 59/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0887 - auc_44: 0.9682 - val_loss: 0.1204 - val_auc_44: 0.9095\n",
      "Epoch 60/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0862 - auc_44: 0.9707 - val_loss: 0.1236 - val_auc_44: 0.9085\n",
      "Epoch 61/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0851 - auc_44: 0.9699 - val_loss: 0.1204 - val_auc_44: 0.9089\n",
      "Epoch 62/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0843 - auc_44: 0.9708 - val_loss: 0.1151 - val_auc_44: 0.9111\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 2s 23ms/step - loss: 0.5675 - auc_45: 0.5815 - val_loss: 0.4728 - val_auc_45: 0.7021\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.4142 - auc_45: 0.7756 - val_loss: 0.3465 - val_auc_45: 0.7681\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3433 - auc_45: 0.8379 - val_loss: 0.2843 - val_auc_45: 0.8066\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.3110 - auc_45: 0.8641 - val_loss: 0.2756 - val_auc_45: 0.8176\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2859 - auc_45: 0.8740 - val_loss: 0.2773 - val_auc_45: 0.8175\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2713 - auc_45: 0.8789 - val_loss: 0.2588 - val_auc_45: 0.8274\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.2607 - auc_45: 0.8926 - val_loss: 0.2347 - val_auc_45: 0.8389\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2492 - auc_45: 0.8956 - val_loss: 0.2387 - val_auc_45: 0.8412\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2408 - auc_45: 0.9034 - val_loss: 0.2516 - val_auc_45: 0.8416\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2336 - auc_45: 0.9049 - val_loss: 0.2556 - val_auc_45: 0.8439\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2277 - auc_45: 0.9074 - val_loss: 0.2305 - val_auc_45: 0.8428\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2220 - auc_45: 0.9087 - val_loss: 0.2080 - val_auc_45: 0.8513\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2180 - auc_45: 0.9117 - val_loss: 0.2292 - val_auc_45: 0.8487\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2128 - auc_45: 0.9144 - val_loss: 0.2140 - val_auc_45: 0.8543\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2089 - auc_45: 0.9167 - val_loss: 0.2321 - val_auc_45: 0.8527\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2057 - auc_45: 0.9171 - val_loss: 0.2280 - val_auc_45: 0.8533\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2012 - auc_45: 0.9201 - val_loss: 0.2045 - val_auc_45: 0.8615\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1974 - auc_45: 0.9227 - val_loss: 0.2196 - val_auc_45: 0.8588\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1941 - auc_45: 0.9258 - val_loss: 0.2117 - val_auc_45: 0.8624\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.1909 - auc_45: 0.9230 - val_loss: 0.1861 - val_auc_45: 0.8731\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1872 - auc_45: 0.9266 - val_loss: 0.1981 - val_auc_45: 0.8705\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1847 - auc_45: 0.9288 - val_loss: 0.2017 - val_auc_45: 0.8700\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1813 - auc_45: 0.9293 - val_loss: 0.1708 - val_auc_45: 0.8824\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1814 - auc_45: 0.9349 - val_loss: 0.1712 - val_auc_45: 0.8839\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1757 - auc_45: 0.9350 - val_loss: 0.1829 - val_auc_45: 0.8809\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1724 - auc_45: 0.9345 - val_loss: 0.1741 - val_auc_45: 0.8816\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1699 - auc_45: 0.9342 - val_loss: 0.1732 - val_auc_45: 0.8822\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1678 - auc_45: 0.9379 - val_loss: 0.1786 - val_auc_45: 0.8823\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1646 - auc_45: 0.9379 - val_loss: 0.1757 - val_auc_45: 0.8831\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1622 - auc_45: 0.9397 - val_loss: 0.1954 - val_auc_45: 0.8808\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1598 - auc_45: 0.9371 - val_loss: 0.1549 - val_auc_45: 0.8909\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1586 - auc_45: 0.9422 - val_loss: 0.1558 - val_auc_45: 0.8916\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1614 - auc_45: 0.9457 - val_loss: 0.1680 - val_auc_45: 0.8893\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1533 - auc_45: 0.9424 - val_loss: 0.1856 - val_auc_45: 0.8850\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1524 - auc_45: 0.9408 - val_loss: 0.1658 - val_auc_45: 0.8918\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1491 - auc_45: 0.9456 - val_loss: 0.1547 - val_auc_45: 0.8933\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1471 - auc_45: 0.9466 - val_loss: 0.1647 - val_auc_45: 0.8952\n",
      "Epoch 38/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1456 - auc_45: 0.9451 - val_loss: 0.1602 - val_auc_45: 0.8951\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.1433 - auc_45: 0.9466 - val_loss: 0.1584 - val_auc_45: 0.8981\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1415 - auc_45: 0.9477 - val_loss: 0.1563 - val_auc_45: 0.8996\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1399 - auc_45: 0.9482 - val_loss: 0.1605 - val_auc_45: 0.8975\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1381 - auc_45: 0.9520 - val_loss: 0.1446 - val_auc_45: 0.8953\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1366 - auc_45: 0.9521 - val_loss: 0.1435 - val_auc_45: 0.8957\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1343 - auc_45: 0.9527 - val_loss: 0.1383 - val_auc_45: 0.9004\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1334 - auc_45: 0.9529 - val_loss: 0.1576 - val_auc_45: 0.8967\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1306 - auc_45: 0.9524 - val_loss: 0.1523 - val_auc_45: 0.8978\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1291 - auc_45: 0.9544 - val_loss: 0.1398 - val_auc_45: 0.9012\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1262 - auc_45: 0.9553 - val_loss: 0.1649 - val_auc_45: 0.8992\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1250 - auc_45: 0.9542 - val_loss: 0.1490 - val_auc_45: 0.8988\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1232 - auc_45: 0.9554 - val_loss: 0.1442 - val_auc_45: 0.9001\n",
      "Epoch 51/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1220 - auc_45: 0.9554 - val_loss: 0.1530 - val_auc_45: 0.9024\n",
      "Epoch 52/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1204 - auc_45: 0.9559 - val_loss: 0.1408 - val_auc_45: 0.9016\n",
      "Epoch 53/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1182 - auc_45: 0.9579 - val_loss: 0.1480 - val_auc_45: 0.9004\n",
      "Epoch 54/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1179 - auc_45: 0.9571 - val_loss: 0.1450 - val_auc_45: 0.9002\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 2s 23ms/step - loss: 0.6055 - auc_46: 0.5512 - val_loss: 0.4807 - val_auc_46: 0.6397\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.4538 - auc_46: 0.7223 - val_loss: 0.3579 - val_auc_46: 0.7502\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3648 - auc_46: 0.8253 - val_loss: 0.3289 - val_auc_46: 0.7908\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3106 - auc_46: 0.8507 - val_loss: 0.2919 - val_auc_46: 0.8113\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2801 - auc_46: 0.8790 - val_loss: 0.2660 - val_auc_46: 0.8271\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2603 - auc_46: 0.8815 - val_loss: 0.2241 - val_auc_46: 0.8439\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2459 - auc_46: 0.8951 - val_loss: 0.2558 - val_auc_46: 0.8343\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2348 - auc_46: 0.9038 - val_loss: 0.2178 - val_auc_46: 0.8472\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2243 - auc_46: 0.9072 - val_loss: 0.2072 - val_auc_46: 0.8513\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.2165 - auc_46: 0.9137 - val_loss: 0.2222 - val_auc_46: 0.8473\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2091 - auc_46: 0.9170 - val_loss: 0.2045 - val_auc_46: 0.8525\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2047 - auc_46: 0.9237 - val_loss: 0.2443 - val_auc_46: 0.8409\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1991 - auc_46: 0.9174 - val_loss: 0.1968 - val_auc_46: 0.8623\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1934 - auc_46: 0.9258 - val_loss: 0.2126 - val_auc_46: 0.8580\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1891 - auc_46: 0.9278 - val_loss: 0.2012 - val_auc_46: 0.8593\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1850 - auc_46: 0.9295 - val_loss: 0.2132 - val_auc_46: 0.8559\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1817 - auc_46: 0.9285 - val_loss: 0.1881 - val_auc_46: 0.8559\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1781 - auc_46: 0.9350 - val_loss: 0.1807 - val_auc_46: 0.8461\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1749 - auc_46: 0.9353 - val_loss: 0.1794 - val_auc_46: 0.8475\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1724 - auc_46: 0.9409 - val_loss: 0.1818 - val_auc_46: 0.8483\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1680 - auc_46: 0.9372 - val_loss: 0.1908 - val_auc_46: 0.8464\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1649 - auc_46: 0.9424 - val_loss: 0.2018 - val_auc_46: 0.8442\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1629 - auc_46: 0.9405 - val_loss: 0.1710 - val_auc_46: 0.8370\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1643 - auc_46: 0.9472 - val_loss: 0.1969 - val_auc_46: 0.8477\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1620 - auc_46: 0.9397 - val_loss: 0.2076 - val_auc_46: 0.8602\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1577 - auc_46: 0.9399 - val_loss: 0.1856 - val_auc_46: 0.8383\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1535 - auc_46: 0.9448 - val_loss: 0.1610 - val_auc_46: 0.8440\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1532 - auc_46: 0.9480 - val_loss: 0.1764 - val_auc_46: 0.8384\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1507 - auc_46: 0.9440 - val_loss: 0.1839 - val_auc_46: 0.8363\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1473 - auc_46: 0.9500 - val_loss: 0.1920 - val_auc_46: 0.8374\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1459 - auc_46: 0.9480 - val_loss: 0.1667 - val_auc_46: 0.8436\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1435 - auc_46: 0.9509 - val_loss: 0.1846 - val_auc_46: 0.8378\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1418 - auc_46: 0.9506 - val_loss: 0.1749 - val_auc_46: 0.8404\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1399 - auc_46: 0.9536 - val_loss: 0.1607 - val_auc_46: 0.8466\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1408 - auc_46: 0.9529 - val_loss: 0.1588 - val_auc_46: 0.8472\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1364 - auc_46: 0.9536 - val_loss: 0.1649 - val_auc_46: 0.8462\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1349 - auc_46: 0.9553 - val_loss: 0.1688 - val_auc_46: 0.8448\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1333 - auc_46: 0.9559 - val_loss: 0.1653 - val_auc_46: 0.8469\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1316 - auc_46: 0.9561 - val_loss: 0.1794 - val_auc_46: 0.8414\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1298 - auc_46: 0.9561 - val_loss: 0.1626 - val_auc_46: 0.8487\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1283 - auc_46: 0.9573 - val_loss: 0.1550 - val_auc_46: 0.8525\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1270 - auc_46: 0.9603 - val_loss: 0.1717 - val_auc_46: 0.8473\n",
      "Epoch 43/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1251 - auc_46: 0.9581 - val_loss: 0.1826 - val_auc_46: 0.8418\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1266 - auc_46: 0.9573 - val_loss: 0.1703 - val_auc_46: 0.8476\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.1224 - auc_46: 0.9595 - val_loss: 0.1757 - val_auc_46: 0.8454\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1207 - auc_46: 0.9601 - val_loss: 0.1786 - val_auc_46: 0.8442\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1188 - auc_46: 0.9611 - val_loss: 0.1730 - val_auc_46: 0.8470\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1178 - auc_46: 0.9603 - val_loss: 0.1728 - val_auc_46: 0.8481\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1166 - auc_46: 0.9609 - val_loss: 0.1560 - val_auc_46: 0.8556\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1141 - auc_46: 0.9628 - val_loss: 0.1406 - val_auc_46: 0.8601\n",
      "Epoch 51/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1127 - auc_46: 0.9632 - val_loss: 0.1521 - val_auc_46: 0.8570\n",
      "Epoch 52/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1115 - auc_46: 0.9637 - val_loss: 0.1585 - val_auc_46: 0.8549\n",
      "Epoch 53/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1099 - auc_46: 0.9631 - val_loss: 0.1572 - val_auc_46: 0.8557\n",
      "Epoch 54/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1082 - auc_46: 0.9642 - val_loss: 0.1591 - val_auc_46: 0.8553\n",
      "Epoch 55/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1068 - auc_46: 0.9648 - val_loss: 0.1718 - val_auc_46: 0.8507\n",
      "Epoch 56/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1077 - auc_46: 0.9609 - val_loss: 0.1529 - val_auc_46: 0.8557\n",
      "Epoch 57/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1039 - auc_46: 0.9654 - val_loss: 0.1643 - val_auc_46: 0.8538\n",
      "Epoch 58/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1039 - auc_46: 0.9643 - val_loss: 0.1517 - val_auc_46: 0.8585\n",
      "Epoch 59/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1009 - auc_46: 0.9662 - val_loss: 0.1400 - val_auc_46: 0.8621\n",
      "Epoch 60/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0993 - auc_46: 0.9671 - val_loss: 0.1534 - val_auc_46: 0.8584\n",
      "Epoch 61/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0981 - auc_46: 0.9662 - val_loss: 0.1654 - val_auc_46: 0.8547\n",
      "Epoch 62/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0980 - auc_46: 0.9662 - val_loss: 0.1393 - val_auc_46: 0.8632\n",
      "Epoch 63/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0958 - auc_46: 0.9672 - val_loss: 0.1400 - val_auc_46: 0.8633\n",
      "Epoch 64/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0940 - auc_46: 0.9696 - val_loss: 0.1536 - val_auc_46: 0.8595\n",
      "Epoch 65/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0941 - auc_46: 0.9665 - val_loss: 0.1415 - val_auc_46: 0.8638\n",
      "Epoch 66/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0914 - auc_46: 0.9697 - val_loss: 0.1393 - val_auc_46: 0.8649\n",
      "Epoch 67/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0921 - auc_46: 0.9671 - val_loss: 0.1421 - val_auc_46: 0.8639\n",
      "Epoch 68/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0895 - auc_46: 0.9703 - val_loss: 0.1409 - val_auc_46: 0.8646\n",
      "Epoch 69/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0876 - auc_46: 0.9704 - val_loss: 0.1584 - val_auc_46: 0.8603\n",
      "Epoch 70/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0881 - auc_46: 0.9681 - val_loss: 0.1300 - val_auc_46: 0.8693\n",
      "Epoch 71/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0856 - auc_46: 0.9709 - val_loss: 0.1416 - val_auc_46: 0.8654\n",
      "Epoch 72/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0842 - auc_46: 0.9714 - val_loss: 0.1289 - val_auc_46: 0.8700\n",
      "Epoch 73/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0843 - auc_46: 0.9731 - val_loss: 0.1275 - val_auc_46: 0.8713\n",
      "Epoch 74/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0819 - auc_46: 0.9711 - val_loss: 0.1209 - val_auc_46: 0.8724\n",
      "Epoch 75/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0861 - auc_46: 0.9735 - val_loss: 0.1199 - val_auc_46: 0.8726\n",
      "Epoch 76/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0803 - auc_46: 0.9735 - val_loss: 0.1220 - val_auc_46: 0.8720\n",
      "Epoch 77/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0791 - auc_46: 0.9728 - val_loss: 0.1273 - val_auc_46: 0.8709\n",
      "Epoch 78/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0780 - auc_46: 0.9741 - val_loss: 0.1446 - val_auc_46: 0.8674\n",
      "Epoch 79/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0770 - auc_46: 0.9723 - val_loss: 0.1378 - val_auc_46: 0.8700\n",
      "Epoch 80/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0756 - auc_46: 0.9735 - val_loss: 0.1173 - val_auc_46: 0.8747\n",
      "Epoch 81/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0755 - auc_46: 0.9749 - val_loss: 0.1317 - val_auc_46: 0.8723\n",
      "Epoch 82/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0766 - auc_46: 0.9710 - val_loss: 0.1258 - val_auc_46: 0.8727\n",
      "Epoch 83/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0729 - auc_46: 0.9750 - val_loss: 0.1207 - val_auc_46: 0.8744\n",
      "Epoch 84/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0725 - auc_46: 0.9763 - val_loss: 0.1155 - val_auc_46: 0.8757\n",
      "Epoch 85/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0706 - auc_46: 0.9765 - val_loss: 0.1285 - val_auc_46: 0.8742\n",
      "Epoch 86/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0696 - auc_46: 0.9752 - val_loss: 0.1207 - val_auc_46: 0.8751\n",
      "Epoch 87/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0691 - auc_46: 0.9750 - val_loss: 0.1244 - val_auc_46: 0.8747\n",
      "Epoch 88/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0682 - auc_46: 0.9760 - val_loss: 0.1328 - val_auc_46: 0.8738\n",
      "Epoch 89/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0676 - auc_46: 0.9763 - val_loss: 0.1169 - val_auc_46: 0.8752\n",
      "Epoch 90/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0663 - auc_46: 0.9770 - val_loss: 0.0971 - val_auc_46: 0.8774\n",
      "Epoch 91/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0738 - auc_46: 0.9772 - val_loss: 0.1090 - val_auc_46: 0.8731\n",
      "Epoch 92/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0653 - auc_46: 0.9783 - val_loss: 0.1165 - val_auc_46: 0.8751\n",
      "Epoch 93/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0636 - auc_46: 0.9793 - val_loss: 0.1230 - val_auc_46: 0.8752\n",
      "Epoch 94/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0635 - auc_46: 0.9778 - val_loss: 0.1318 - val_auc_46: 0.8728\n",
      "Epoch 95/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0622 - auc_46: 0.9787 - val_loss: 0.1188 - val_auc_46: 0.8752\n",
      "Epoch 96/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0613 - auc_46: 0.9795 - val_loss: 0.1180 - val_auc_46: 0.8755\n",
      "Epoch 97/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0605 - auc_46: 0.9792 - val_loss: 0.1116 - val_auc_46: 0.8769\n",
      "Epoch 98/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0598 - auc_46: 0.9795 - val_loss: 0.1233 - val_auc_46: 0.8746\n",
      "Epoch 99/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0590 - auc_46: 0.9793 - val_loss: 0.1078 - val_auc_46: 0.8768\n",
      "Epoch 100/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0585 - auc_46: 0.9802 - val_loss: 0.1166 - val_auc_46: 0.8767\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 2s 21ms/step - loss: 0.5708 - auc_47: 0.5846 - val_loss: 0.4530 - val_auc_47: 0.6900\n",
      "Epoch 2/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 15ms/step - loss: 0.4312 - auc_47: 0.7633 - val_loss: 0.3607 - val_auc_47: 0.7675\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3534 - auc_47: 0.8217 - val_loss: 0.3194 - val_auc_47: 0.7940\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3112 - auc_47: 0.8599 - val_loss: 0.2829 - val_auc_47: 0.8160\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2842 - auc_47: 0.8728 - val_loss: 0.2701 - val_auc_47: 0.8230\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2643 - auc_47: 0.8890 - val_loss: 0.2550 - val_auc_47: 0.8317\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2494 - auc_47: 0.9015 - val_loss: 0.2635 - val_auc_47: 0.8291\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2382 - auc_47: 0.9047 - val_loss: 0.2762 - val_auc_47: 0.8249\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2290 - auc_47: 0.9083 - val_loss: 0.2243 - val_auc_47: 0.8429\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2212 - auc_47: 0.9197 - val_loss: 0.2549 - val_auc_47: 0.8329\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2143 - auc_47: 0.9170 - val_loss: 0.2227 - val_auc_47: 0.8472\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2076 - auc_47: 0.9232 - val_loss: 0.2353 - val_auc_47: 0.8447\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2028 - auc_47: 0.9219 - val_loss: 0.2222 - val_auc_47: 0.8384\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1972 - auc_47: 0.9236 - val_loss: 0.2009 - val_auc_47: 0.8340\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1923 - auc_47: 0.9280 - val_loss: 0.2346 - val_auc_47: 0.8259\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1889 - auc_47: 0.9252 - val_loss: 0.2089 - val_auc_47: 0.8353\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1840 - auc_47: 0.9324 - val_loss: 0.2269 - val_auc_47: 0.8281\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1816 - auc_47: 0.9307 - val_loss: 0.2009 - val_auc_47: 0.8415\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1782 - auc_47: 0.9335 - val_loss: 0.2155 - val_auc_47: 0.8370\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1737 - auc_47: 0.9353 - val_loss: 0.1983 - val_auc_47: 0.8305\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1706 - auc_47: 0.9376 - val_loss: 0.2237 - val_auc_47: 0.8224\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1675 - auc_47: 0.9378 - val_loss: 0.1687 - val_auc_47: 0.8400\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1695 - auc_47: 0.9416 - val_loss: 0.1641 - val_auc_47: 0.8407\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1630 - auc_47: 0.9429 - val_loss: 0.2023 - val_auc_47: 0.8314\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1606 - auc_47: 0.9408 - val_loss: 0.2198 - val_auc_47: 0.8271\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1582 - auc_47: 0.9412 - val_loss: 0.1873 - val_auc_47: 0.8350\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1550 - auc_47: 0.9438 - val_loss: 0.1982 - val_auc_47: 0.8320\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1526 - auc_47: 0.9446 - val_loss: 0.1910 - val_auc_47: 0.8351\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1508 - auc_47: 0.9460 - val_loss: 0.2016 - val_auc_47: 0.8323\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1494 - auc_47: 0.9446 - val_loss: 0.1675 - val_auc_47: 0.8449\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1541 - auc_47: 0.9530 - val_loss: 0.1816 - val_auc_47: 0.8390\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.1442 - auc_47: 0.9528 - val_loss: 0.1806 - val_auc_47: 0.8404\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.1420 - auc_47: 0.9515 - val_loss: 0.1641 - val_auc_47: 0.8471\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 2s 21ms/step - loss: 0.6277 - auc_48: 0.5277 - val_loss: 0.4644 - val_auc_48: 0.6274\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.4951 - auc_48: 0.7031 - val_loss: 0.3744 - val_auc_48: 0.7514\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3999 - auc_48: 0.7996 - val_loss: 0.3464 - val_auc_48: 0.7758\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3418 - auc_48: 0.8348 - val_loss: 0.2962 - val_auc_48: 0.8059\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3058 - auc_48: 0.8632 - val_loss: 0.2832 - val_auc_48: 0.8148\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2804 - auc_48: 0.8758 - val_loss: 0.2847 - val_auc_48: 0.8196\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2616 - auc_48: 0.8858 - val_loss: 0.2333 - val_auc_48: 0.8288\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2458 - auc_48: 0.8994 - val_loss: 0.2581 - val_auc_48: 0.8220\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2338 - auc_48: 0.9039 - val_loss: 0.2341 - val_auc_48: 0.8324\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2237 - auc_48: 0.9106 - val_loss: 0.2330 - val_auc_48: 0.8333\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2143 - auc_48: 0.9157 - val_loss: 0.2057 - val_auc_48: 0.8454\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2093 - auc_48: 0.9198 - val_loss: 0.2038 - val_auc_48: 0.8453\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2009 - auc_48: 0.9225 - val_loss: 0.2072 - val_auc_48: 0.8347\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1942 - auc_48: 0.9263 - val_loss: 0.1930 - val_auc_48: 0.8380\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1888 - auc_48: 0.9265 - val_loss: 0.1824 - val_auc_48: 0.8450\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1921 - auc_48: 0.9336 - val_loss: 0.1900 - val_auc_48: 0.8439\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1792 - auc_48: 0.9320 - val_loss: 0.1999 - val_auc_48: 0.8420\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1758 - auc_48: 0.9342 - val_loss: 0.2189 - val_auc_48: 0.8370\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1716 - auc_48: 0.9361 - val_loss: 0.1883 - val_auc_48: 0.8236\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1672 - auc_48: 0.9375 - val_loss: 0.1727 - val_auc_48: 0.8311\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1641 - auc_48: 0.9376 - val_loss: 0.1729 - val_auc_48: 0.8337\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1609 - auc_48: 0.9393 - val_loss: 0.1904 - val_auc_48: 0.8279\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1573 - auc_48: 0.9421 - val_loss: 0.1990 - val_auc_48: 0.8252\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1541 - auc_48: 0.9427 - val_loss: 0.1825 - val_auc_48: 0.8335\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1506 - auc_48: 0.9436 - val_loss: 0.1742 - val_auc_48: 0.8384\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1474 - auc_48: 0.9449 - val_loss: 0.1735 - val_auc_48: 0.8396\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1441 - auc_48: 0.9479 - val_loss: 0.1721 - val_auc_48: 0.8410\n",
      "Epoch 28/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1411 - auc_48: 0.9509 - val_loss: 0.1714 - val_auc_48: 0.8425\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1380 - auc_48: 0.9499 - val_loss: 0.1686 - val_auc_48: 0.8444\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1353 - auc_48: 0.9536 - val_loss: 0.1743 - val_auc_48: 0.8440\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1327 - auc_48: 0.9557 - val_loss: 0.1581 - val_auc_48: 0.8470\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1290 - auc_48: 0.95 - 1s 14ms/step - loss: 0.1290 - auc_48: 0.9564 - val_loss: 0.1531 - val_auc_48: 0.8490\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1264 - auc_48: 0.9569 - val_loss: 0.1540 - val_auc_48: 0.8489\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1286 - auc_48: 0.9598 - val_loss: 0.1575 - val_auc_48: 0.8494\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1223 - auc_48: 0.9583 - val_loss: 0.1612 - val_auc_48: 0.8500\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1207 - auc_48: 0.9572 - val_loss: 0.1524 - val_auc_48: 0.8520\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1170 - auc_48: 0.9593 - val_loss: 0.1298 - val_auc_48: 0.8596\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1194 - auc_48: 0.9622 - val_loss: 0.1328 - val_auc_48: 0.8590\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1149 - auc_48: 0.9649 - val_loss: 0.1568 - val_auc_48: 0.8537\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1119 - auc_48: 0.9611 - val_loss: 0.1580 - val_auc_48: 0.8537\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1093 - auc_48: 0.9622 - val_loss: 0.1288 - val_auc_48: 0.8596\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1093 - auc_48: 0.9657 - val_loss: 0.1295 - val_auc_48: 0.8618\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1054 - auc_48: 0.9641 - val_loss: 0.1326 - val_auc_48: 0.8596\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1040 - auc_48: 0.9666 - val_loss: 0.1492 - val_auc_48: 0.8583\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1020 - auc_48: 0.9678 - val_loss: 0.1397 - val_auc_48: 0.8590\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.1027 - auc_48: 0.9685 - val_loss: 0.1421 - val_auc_48: 0.8576\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1003 - auc_48: 0.9648 - val_loss: 0.1322 - val_auc_48: 0.8602\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0993 - auc_48: 0.9706 - val_loss: 0.1256 - val_auc_48: 0.8612\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0961 - auc_48: 0.9694 - val_loss: 0.1417 - val_auc_48: 0.8578\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0944 - auc_48: 0.9693 - val_loss: 0.1363 - val_auc_48: 0.8600\n",
      "Epoch 51/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0934 - auc_48: 0.9693 - val_loss: 0.1280 - val_auc_48: 0.8618\n",
      "Epoch 52/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0927 - auc_48: 0.9716 - val_loss: 0.1310 - val_auc_48: 0.8609\n",
      "Epoch 53/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0904 - auc_48: 0.9714 - val_loss: 0.1467 - val_auc_48: 0.8586\n",
      "Epoch 54/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0896 - auc_48: 0.9701 - val_loss: 0.1280 - val_auc_48: 0.8627\n",
      "Epoch 55/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0875 - auc_48: 0.9715 - val_loss: 0.1429 - val_auc_48: 0.8601\n",
      "Epoch 56/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0880 - auc_48: 0.9696 - val_loss: 0.1357 - val_auc_48: 0.8612\n",
      "Epoch 57/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0862 - auc_48: 0.9708 - val_loss: 0.1420 - val_auc_48: 0.8602\n",
      "Epoch 58/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0847 - auc_48: 0.9721 - val_loss: 0.1390 - val_auc_48: 0.8608\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6090 - auc_49: 0.5915 - val_loss: 0.4412 - val_auc_49: 0.6725\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.4366 - auc_49: 0.7501 - val_loss: 0.3725 - val_auc_49: 0.7637\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.3531 - auc_49: 0.8248 - val_loss: 0.3057 - val_auc_49: 0.8064\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.3067 - auc_49: 0.8518 - val_loss: 0.2759 - val_auc_49: 0.8181\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.2766 - auc_49: 0.8713 - val_loss: 0.2447 - val_auc_49: 0.8320\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2538 - auc_49: 0.8875 - val_loss: 0.2167 - val_auc_49: 0.8440\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2374 - auc_49: 0.9013 - val_loss: 0.2219 - val_auc_49: 0.8439\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2227 - auc_49: 0.9083 - val_loss: 0.2122 - val_auc_49: 0.8492\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2127 - auc_49: 0.9173 - val_loss: 0.2255 - val_auc_49: 0.8470\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.2039 - auc_49: 0.9182 - val_loss: 0.2221 - val_auc_49: 0.8452\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.1966 - auc_49: 0.9211 - val_loss: 0.2142 - val_auc_49: 0.8506\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.1899 - auc_49: 0.9245 - val_loss: 0.2197 - val_auc_49: 0.8488\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1848 - auc_49: 0.9265 - val_loss: 0.1891 - val_auc_49: 0.8498\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1791 - auc_49: 0.9326 - val_loss: 0.1955 - val_auc_49: 0.8504\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1744 - auc_49: 0.9322 - val_loss: 0.1931 - val_auc_49: 0.8395\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1696 - auc_49: 0.9360 - val_loss: 0.1845 - val_auc_49: 0.8451\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1654 - auc_49: 0.9373 - val_loss: 0.2228 - val_auc_49: 0.8445\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1623 - auc_49: 0.9388 - val_loss: 0.1760 - val_auc_49: 0.8371\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1576 - auc_49: 0.9440 - val_loss: 0.2254 - val_auc_49: 0.8473\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1677 - auc_49: 0.9340 - val_loss: 0.2159 - val_auc_49: 0.8361\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1529 - auc_49: 0.9450 - val_loss: 0.1838 - val_auc_49: 0.8371\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1493 - auc_49: 0.9473 - val_loss: 0.1944 - val_auc_49: 0.8334\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1462 - auc_49: 0.9485 - val_loss: 0.1613 - val_auc_49: 0.8439\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1440 - auc_49: 0.9487 - val_loss: 0.1635 - val_auc_49: 0.8416\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1436 - auc_49: 0.9525 - val_loss: 0.1666 - val_auc_49: 0.8434\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1387 - auc_49: 0.9531 - val_loss: 0.1768 - val_auc_49: 0.8403\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1362 - auc_49: 0.9531 - val_loss: 0.1781 - val_auc_49: 0.8405\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1340 - auc_49: 0.9527 - val_loss: 0.1523 - val_auc_49: 0.8472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1320 - auc_49: 0.9553 - val_loss: 0.1685 - val_auc_49: 0.8417\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1318 - auc_49: 0.9538 - val_loss: 0.1548 - val_auc_49: 0.8479\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1281 - auc_49: 0.9556 - val_loss: 0.1542 - val_auc_49: 0.8479\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1257 - auc_49: 0.9571 - val_loss: 0.1630 - val_auc_49: 0.8441\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1235 - auc_49: 0.9583 - val_loss: 0.1682 - val_auc_49: 0.8427\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1211 - auc_49: 0.9587 - val_loss: 0.1624 - val_auc_49: 0.8453\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1191 - auc_49: 0.9593 - val_loss: 0.1546 - val_auc_49: 0.8471\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1178 - auc_49: 0.9617 - val_loss: 0.1463 - val_auc_49: 0.8496\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1151 - auc_49: 0.9613 - val_loss: 0.1416 - val_auc_49: 0.8526\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1132 - auc_49: 0.9624 - val_loss: 0.1438 - val_auc_49: 0.8521\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1120 - auc_49: 0.9632 - val_loss: 0.1483 - val_auc_49: 0.8507\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1100 - auc_49: 0.9635 - val_loss: 0.1360 - val_auc_49: 0.8548\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1121 - auc_49: 0.9671 - val_loss: 0.1541 - val_auc_49: 0.8473\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1129 - auc_49: 0.9587 - val_loss: 0.1490 - val_auc_49: 0.8508\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1053 - auc_49: 0.9653 - val_loss: 0.1428 - val_auc_49: 0.8527\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1031 - auc_49: 0.9661 - val_loss: 0.1298 - val_auc_49: 0.8578\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1017 - auc_49: 0.9674 - val_loss: 0.1288 - val_auc_49: 0.8580\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1005 - auc_49: 0.9679 - val_loss: 0.1432 - val_auc_49: 0.8542\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0992 - auc_49: 0.9674 - val_loss: 0.1625 - val_auc_49: 0.8476\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0972 - auc_49: 0.9673 - val_loss: 0.1261 - val_auc_49: 0.8596\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0973 - auc_49: 0.9719 - val_loss: 0.1397 - val_auc_49: 0.8551\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0943 - auc_49: 0.9680 - val_loss: 0.1423 - val_auc_49: 0.8549\n",
      "Epoch 51/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0927 - auc_49: 0.9696 - val_loss: 0.1308 - val_auc_49: 0.8593\n",
      "Epoch 52/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0938 - auc_49: 0.9724 - val_loss: 0.1191 - val_auc_49: 0.8628\n",
      "Epoch 53/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0908 - auc_49: 0.9732 - val_loss: 0.1448 - val_auc_49: 0.8569\n",
      "Epoch 54/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0891 - auc_49: 0.9708 - val_loss: 0.1356 - val_auc_49: 0.8592\n",
      "Epoch 55/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0881 - auc_49: 0.9691 - val_loss: 0.1333 - val_auc_49: 0.8604\n",
      "Epoch 56/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0861 - auc_49: 0.9718 - val_loss: 0.1244 - val_auc_49: 0.8626\n",
      "Epoch 57/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0857 - auc_49: 0.9744 - val_loss: 0.1223 - val_auc_49: 0.8621\n",
      "Epoch 58/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0842 - auc_49: 0.9735 - val_loss: 0.1314 - val_auc_49: 0.8615\n",
      "Epoch 59/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0825 - auc_49: 0.9738 - val_loss: 0.1369 - val_auc_49: 0.8603\n",
      "Epoch 60/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0816 - auc_49: 0.9738 - val_loss: 0.1312 - val_auc_49: 0.8615\n",
      "Epoch 61/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0802 - auc_49: 0.9750 - val_loss: 0.1377 - val_auc_49: 0.8607\n",
      "Epoch 62/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0797 - auc_49: 0.9748 - val_loss: 0.1180 - val_auc_49: 0.8638\n",
      "Epoch 63/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0786 - auc_49: 0.9766 - val_loss: 0.1264 - val_auc_49: 0.8617\n",
      "Epoch 64/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0766 - auc_49: 0.9753 - val_loss: 0.1247 - val_auc_49: 0.8621\n",
      "Epoch 65/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0756 - auc_49: 0.9768 - val_loss: 0.1190 - val_auc_49: 0.8645\n",
      "Epoch 66/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0743 - auc_49: 0.9770 - val_loss: 0.1281 - val_auc_49: 0.8616\n",
      "Epoch 67/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0739 - auc_49: 0.9760 - val_loss: 0.1203 - val_auc_49: 0.8637\n",
      "Epoch 68/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0725 - auc_49: 0.9775 - val_loss: 0.1257 - val_auc_49: 0.8629\n",
      "Epoch 69/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0712 - auc_49: 0.9775 - val_loss: 0.1244 - val_auc_49: 0.8640\n",
      "Epoch 70/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0702 - auc_49: 0.9777 - val_loss: 0.1129 - val_auc_49: 0.8664\n",
      "Epoch 71/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0696 - auc_49: 0.9778 - val_loss: 0.1041 - val_auc_49: 0.8677\n",
      "Epoch 72/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0684 - auc_49: 0.9783 - val_loss: 0.1164 - val_auc_49: 0.8657\n",
      "Epoch 73/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0674 - auc_49: 0.9780 - val_loss: 0.1308 - val_auc_49: 0.8628\n",
      "Epoch 74/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0674 - auc_49: 0.9767 - val_loss: 0.1263 - val_auc_49: 0.8634\n",
      "Epoch 75/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0660 - auc_49: 0.9772 - val_loss: 0.1101 - val_auc_49: 0.8669\n",
      "Epoch 76/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0648 - auc_49: 0.9787 - val_loss: 0.1276 - val_auc_49: 0.8632\n",
      "Epoch 77/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0659 - auc_49: 0.9762 - val_loss: 0.1199 - val_auc_49: 0.8631\n",
      "Epoch 78/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0628 - auc_49: 0.9783 - val_loss: 0.1139 - val_auc_49: 0.8660\n",
      "Epoch 79/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0614 - auc_49: 0.9783 - val_loss: 0.1131 - val_auc_49: 0.8669\n",
      "Epoch 80/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0605 - auc_49: 0.9787 - val_loss: 0.1098 - val_auc_49: 0.8682\n",
      "Epoch 81/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0597 - auc_49: 0.9793 - val_loss: 0.1235 - val_auc_49: 0.8640\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.6016 - auc_50: 0.5442 - val_loss: 0.4547 - val_auc_50: 0.6495\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.4653 - auc_50: 0.7269 - val_loss: 0.3764 - val_auc_50: 0.7607\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3689 - auc_50: 0.8163 - val_loss: 0.3210 - val_auc_50: 0.7926\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3180 - auc_50: 0.8476 - val_loss: 0.2700 - val_auc_50: 0.8171\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2886 - auc_50: 0.8705 - val_loss: 0.2837 - val_auc_50: 0.8180\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2695 - auc_50: 0.8829 - val_loss: 0.2637 - val_auc_50: 0.8283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2539 - auc_50: 0.8944 - val_loss: 0.2439 - val_auc_50: 0.8380\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2415 - auc_50: 0.9015 - val_loss: 0.2429 - val_auc_50: 0.8367\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2306 - auc_50: 0.9081 - val_loss: 0.2476 - val_auc_50: 0.8380\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2223 - auc_50: 0.9118 - val_loss: 0.2317 - val_auc_50: 0.8416\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2163 - auc_50: 0.9141 - val_loss: 0.2224 - val_auc_50: 0.8456\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2102 - auc_50: 0.9203 - val_loss: 0.1949 - val_auc_50: 0.8546\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2040 - auc_50: 0.9227 - val_loss: 0.1876 - val_auc_50: 0.8440\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1984 - auc_50: 0.9239 - val_loss: 0.2012 - val_auc_50: 0.8443\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1981 - auc_50: 0.9279 - val_loss: 0.1887 - val_auc_50: 0.8442\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1917 - auc_50: 0.9275 - val_loss: 0.1874 - val_auc_50: 0.8468\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1875 - auc_50: 0.9284 - val_loss: 0.1945 - val_auc_50: 0.8491\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1851 - auc_50: 0.9302 - val_loss: 0.1825 - val_auc_50: 0.8433\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1804 - auc_50: 0.9325 - val_loss: 0.1898 - val_auc_50: 0.8553\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1777 - auc_50: 0.9335 - val_loss: 0.2152 - val_auc_50: 0.8453\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1733 - auc_50: 0.9357 - val_loss: 0.2002 - val_auc_50: 0.8265\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1701 - auc_50: 0.9386 - val_loss: 0.2044 - val_auc_50: 0.8260\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1669 - auc_50: 0.9392 - val_loss: 0.1999 - val_auc_50: 0.8284\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1629 - auc_50: 0.9418 - val_loss: 0.2065 - val_auc_50: 0.8276\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1604 - auc_50: 0.9384 - val_loss: 0.1572 - val_auc_50: 0.8485\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1588 - auc_50: 0.9460 - val_loss: 0.1841 - val_auc_50: 0.8381\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1545 - auc_50: 0.9468 - val_loss: 0.1814 - val_auc_50: 0.8399\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1525 - auc_50: 0.9467 - val_loss: 0.2074 - val_auc_50: 0.8313\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1503 - auc_50: 0.9473 - val_loss: 0.1959 - val_auc_50: 0.8358\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1481 - auc_50: 0.9451 - val_loss: 0.1882 - val_auc_50: 0.8404\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1451 - auc_50: 0.9510 - val_loss: 0.1848 - val_auc_50: 0.8423\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1427 - auc_50: 0.9506 - val_loss: 0.1811 - val_auc_50: 0.8444\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1403 - auc_50: 0.9527 - val_loss: 0.1788 - val_auc_50: 0.8455\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1386 - auc_50: 0.9539 - val_loss: 0.1953 - val_auc_50: 0.8404\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1363 - auc_50: 0.9543 - val_loss: 0.1889 - val_auc_50: 0.8435\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.6150 - auc_51: 0.5656 - val_loss: 0.4489 - val_auc_51: 0.6643\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.4884 - auc_51: 0.7231 - val_loss: 0.3696 - val_auc_51: 0.7781\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.4173 - auc_51: 0.7899 - val_loss: 0.3726 - val_auc_51: 0.7938\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3718 - auc_51: 0.8069 - val_loss: 0.3318 - val_auc_51: 0.8282\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3408 - auc_51: 0.8342 - val_loss: 0.3303 - val_auc_51: 0.8366\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3198 - auc_51: 0.8463 - val_loss: 0.2947 - val_auc_51: 0.8568\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3036 - auc_51: 0.8562 - val_loss: 0.2654 - val_auc_51: 0.8740\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2912 - auc_51: 0.8629 - val_loss: 0.2715 - val_auc_51: 0.8755\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2813 - auc_51: 0.8707 - val_loss: 0.2638 - val_auc_51: 0.8803\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2711 - auc_51: 0.8784 - val_loss: 0.2537 - val_auc_51: 0.8866\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2623 - auc_51: 0.8827 - val_loss: 0.2538 - val_auc_51: 0.8879\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2551 - auc_51: 0.8852 - val_loss: 0.2358 - val_auc_51: 0.8966\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2458 - auc_51: 0.8931 - val_loss: 0.2176 - val_auc_51: 0.9057\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2389 - auc_51: 0.8980 - val_loss: 0.2245 - val_auc_51: 0.9048\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2314 - auc_51: 0.8972 - val_loss: 0.2112 - val_auc_51: 0.9117\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2248 - auc_51: 0.9030 - val_loss: 0.2269 - val_auc_51: 0.9050\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2176 - auc_51: 0.9079 - val_loss: 0.2024 - val_auc_51: 0.9178\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2118 - auc_51: 0.9116 - val_loss: 0.2030 - val_auc_51: 0.9203\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2057 - auc_51: 0.9145 - val_loss: 0.2054 - val_auc_51: 0.9181\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2020 - auc_51: 0.9167 - val_loss: 0.2070 - val_auc_51: 0.9181\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1953 - auc_51: 0.9187 - val_loss: 0.1796 - val_auc_51: 0.9307\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1936 - auc_51: 0.9274 - val_loss: 0.1705 - val_auc_51: 0.9353\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1869 - auc_51: 0.9290 - val_loss: 0.1773 - val_auc_51: 0.9335\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1849 - auc_51: 0.9297 - val_loss: 0.1547 - val_auc_51: 0.9422\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1815 - auc_51: 0.9316 - val_loss: 0.1805 - val_auc_51: 0.9311\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1744 - auc_51: 0.9308 - val_loss: 0.1724 - val_auc_51: 0.9358\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1706 - auc_51: 0.9342 - val_loss: 0.1733 - val_auc_51: 0.9363\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1671 - auc_51: 0.9365 - val_loss: 0.1762 - val_auc_51: 0.9364\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1636 - auc_51: 0.9379 - val_loss: 0.1654 - val_auc_51: 0.9414\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1617 - auc_51: 0.9419 - val_loss: 0.1659 - val_auc_51: 0.9412\n",
      "Epoch 31/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1578 - auc_51: 0.9401 - val_loss: 0.1838 - val_auc_51: 0.9358\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1547 - auc_51: 0.9420 - val_loss: 0.1880 - val_auc_51: 0.9346\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1528 - auc_51: 0.9409 - val_loss: 0.1448 - val_auc_51: 0.9502\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1558 - auc_51: 0.9468 - val_loss: 0.1491 - val_auc_51: 0.9482\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1472 - auc_51: 0.9476 - val_loss: 0.1514 - val_auc_51: 0.9476\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1461 - auc_51: 0.9484 - val_loss: 0.1569 - val_auc_51: 0.9465\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1427 - auc_51: 0.9472 - val_loss: 0.1594 - val_auc_51: 0.9457\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1405 - auc_51: 0.9500 - val_loss: 0.1605 - val_auc_51: 0.9462\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1385 - auc_51: 0.9502 - val_loss: 0.1548 - val_auc_51: 0.9493\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1366 - auc_51: 0.9503 - val_loss: 0.1725 - val_auc_51: 0.9418\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1343 - auc_51: 0.9521 - val_loss: 0.1587 - val_auc_51: 0.9489\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1320 - auc_51: 0.9530 - val_loss: 0.1393 - val_auc_51: 0.9549\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1303 - auc_51: 0.9539 - val_loss: 0.1325 - val_auc_51: 0.9573\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1306 - auc_51: 0.9545 - val_loss: 0.1324 - val_auc_51: 0.9568\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1269 - auc_51: 0.9569 - val_loss: 0.1418 - val_auc_51: 0.9550\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1248 - auc_51: 0.9573 - val_loss: 0.1609 - val_auc_51: 0.9488\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1237 - auc_51: 0.9538 - val_loss: 0.1478 - val_auc_51: 0.9536\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1220 - auc_51: 0.9574 - val_loss: 0.1399 - val_auc_51: 0.9555\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1196 - auc_51: 0.9590 - val_loss: 0.1449 - val_auc_51: 0.9551\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1179 - auc_51: 0.9595 - val_loss: 0.1416 - val_auc_51: 0.9559\n",
      "Epoch 51/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1170 - auc_51: 0.9600 - val_loss: 0.1508 - val_auc_51: 0.9528\n",
      "Epoch 52/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1153 - auc_51: 0.9590 - val_loss: 0.1394 - val_auc_51: 0.9571\n",
      "Epoch 53/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1140 - auc_51: 0.9618 - val_loss: 0.1536 - val_auc_51: 0.9516\n",
      "Epoch 54/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1122 - auc_51: 0.9605 - val_loss: 0.1419 - val_auc_51: 0.9564\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.6240 - auc_52: 0.5598 - val_loss: 0.4404 - val_auc_52: 0.6983\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.4568 - auc_52: 0.7467 - val_loss: 0.3824 - val_auc_52: 0.7832\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3874 - auc_52: 0.7966 - val_loss: 0.3496 - val_auc_52: 0.8162\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3485 - auc_52: 0.8236 - val_loss: 0.3052 - val_auc_52: 0.8487\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3242 - auc_52: 0.8425 - val_loss: 0.3121 - val_auc_52: 0.8514\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3070 - auc_52: 0.8559 - val_loss: 0.3065 - val_auc_52: 0.8590\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2939 - auc_52: 0.8634 - val_loss: 0.3109 - val_auc_52: 0.8598\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2819 - auc_52: 0.8718 - val_loss: 0.2513 - val_auc_52: 0.8873\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2723 - auc_52: 0.8823 - val_loss: 0.2245 - val_auc_52: 0.9025\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2663 - auc_52: 0.8891 - val_loss: 0.2409 - val_auc_52: 0.8962\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2587 - auc_52: 0.8957 - val_loss: 0.2693 - val_auc_52: 0.8855\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2514 - auc_52: 0.8903 - val_loss: 0.2531 - val_auc_52: 0.8931\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2460 - auc_52: 0.8952 - val_loss: 0.2645 - val_auc_52: 0.8893\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2409 - auc_52: 0.8978 - val_loss: 0.2337 - val_auc_52: 0.9033\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2354 - auc_52: 0.9031 - val_loss: 0.2381 - val_auc_52: 0.9016\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2332 - auc_52: 0.9003 - val_loss: 0.2440 - val_auc_52: 0.8999\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2272 - auc_52: 0.9038 - val_loss: 0.2152 - val_auc_52: 0.9136\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2248 - auc_52: 0.9105 - val_loss: 0.2333 - val_auc_52: 0.9071\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2257 - auc_52: 0.9008 - val_loss: 0.2119 - val_auc_52: 0.9142\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2163 - auc_52: 0.9108 - val_loss: 0.2251 - val_auc_52: 0.9097\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2132 - auc_52: 0.9108 - val_loss: 0.2271 - val_auc_52: 0.9109\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2090 - auc_52: 0.9136 - val_loss: 0.2021 - val_auc_52: 0.9184\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2071 - auc_52: 0.9179 - val_loss: 0.1818 - val_auc_52: 0.9292\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2025 - auc_52: 0.9193 - val_loss: 0.1967 - val_auc_52: 0.9231\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1990 - auc_52: 0.9180 - val_loss: 0.1843 - val_auc_52: 0.9291\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1964 - auc_52: 0.9218 - val_loss: 0.1730 - val_auc_52: 0.9341\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1936 - auc_52: 0.9230 - val_loss: 0.1867 - val_auc_52: 0.9283\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1905 - auc_52: 0.9225 - val_loss: 0.2088 - val_auc_52: 0.9197\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1870 - auc_52: 0.9250 - val_loss: 0.1937 - val_auc_52: 0.9266\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1841 - auc_52: 0.9268 - val_loss: 0.1790 - val_auc_52: 0.9329\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1809 - auc_52: 0.9278 - val_loss: 0.1961 - val_auc_52: 0.9260\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1795 - auc_52: 0.9274 - val_loss: 0.2046 - val_auc_52: 0.9231\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1760 - auc_52: 0.9284 - val_loss: 0.1849 - val_auc_52: 0.9307\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1721 - auc_52: 0.9317 - val_loss: 0.1818 - val_auc_52: 0.9335\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1709 - auc_52: 0.9303 - val_loss: 0.1806 - val_auc_52: 0.9336\n",
      "Epoch 36/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1676 - auc_52: 0.9329 - val_loss: 0.1911 - val_auc_52: 0.9298\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.6455 - auc_53: 0.5188 - val_loss: 0.5373 - val_auc_53: 0.5932\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.4949 - auc_53: 0.6791 - val_loss: 0.4378 - val_auc_53: 0.7370\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.4088 - auc_53: 0.7796 - val_loss: 0.3767 - val_auc_53: 0.7991\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3586 - auc_53: 0.8206 - val_loss: 0.3400 - val_auc_53: 0.8320\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3293 - auc_53: 0.8453 - val_loss: 0.3128 - val_auc_53: 0.8517\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3090 - auc_53: 0.8597 - val_loss: 0.2840 - val_auc_53: 0.8679\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2948 - auc_53: 0.8745 - val_loss: 0.2861 - val_auc_53: 0.8687\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2829 - auc_53: 0.8731 - val_loss: 0.2335 - val_auc_53: 0.8931\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2732 - auc_53: 0.8806 - val_loss: 0.2325 - val_auc_53: 0.8967\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2644 - auc_53: 0.8860 - val_loss: 0.2486 - val_auc_53: 0.8910\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2566 - auc_53: 0.8850 - val_loss: 0.2356 - val_auc_53: 0.8991\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2492 - auc_53: 0.8962 - val_loss: 0.2374 - val_auc_53: 0.9003\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2422 - auc_53: 0.8959 - val_loss: 0.2116 - val_auc_53: 0.9132\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2364 - auc_53: 0.9042 - val_loss: 0.2101 - val_auc_53: 0.9132\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2309 - auc_53: 0.9082 - val_loss: 0.2402 - val_auc_53: 0.9030\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2245 - auc_53: 0.9044 - val_loss: 0.2291 - val_auc_53: 0.9073\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2198 - auc_53: 0.9082 - val_loss: 0.2224 - val_auc_53: 0.9115\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2144 - auc_53: 0.9106 - val_loss: 0.2080 - val_auc_53: 0.9176\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2108 - auc_53: 0.9178 - val_loss: 0.1831 - val_auc_53: 0.9283\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2107 - auc_53: 0.9193 - val_loss: 0.1853 - val_auc_53: 0.9265\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2030 - auc_53: 0.9208 - val_loss: 0.1932 - val_auc_53: 0.9239\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2007 - auc_53: 0.9248 - val_loss: 0.1938 - val_auc_53: 0.9239\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1953 - auc_53: 0.9228 - val_loss: 0.2009 - val_auc_53: 0.9212\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1914 - auc_53: 0.9252 - val_loss: 0.2069 - val_auc_53: 0.9199\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1889 - auc_53: 0.9287 - val_loss: 0.1701 - val_auc_53: 0.9371\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1860 - auc_53: 0.9280 - val_loss: 0.1982 - val_auc_53: 0.9248\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1827 - auc_53: 0.9316 - val_loss: 0.2002 - val_auc_53: 0.9242\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1803 - auc_53: 0.9295 - val_loss: 0.2016 - val_auc_53: 0.9252\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1757 - auc_53: 0.9331 - val_loss: 0.1828 - val_auc_53: 0.9340\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1730 - auc_53: 0.9324 - val_loss: 0.1821 - val_auc_53: 0.9342\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1708 - auc_53: 0.9387 - val_loss: 0.1724 - val_auc_53: 0.9391\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1685 - auc_53: 0.9375 - val_loss: 0.1545 - val_auc_53: 0.9461\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1643 - auc_53: 0.9403 - val_loss: 0.1803 - val_auc_53: 0.9358\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1619 - auc_53: 0.9385 - val_loss: 0.1561 - val_auc_53: 0.9461\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1606 - auc_53: 0.9432 - val_loss: 0.1592 - val_auc_53: 0.9456\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1564 - auc_53: 0.9442 - val_loss: 0.1792 - val_auc_53: 0.9368\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1549 - auc_53: 0.9438 - val_loss: 0.1525 - val_auc_53: 0.9493\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1527 - auc_53: 0.9474 - val_loss: 0.1704 - val_auc_53: 0.9422\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1496 - auc_53: 0.9474 - val_loss: 0.1634 - val_auc_53: 0.9451\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1477 - auc_53: 0.9482 - val_loss: 0.1671 - val_auc_53: 0.9433\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1458 - auc_53: 0.9484 - val_loss: 0.1466 - val_auc_53: 0.9529\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1479 - auc_53: 0.9516 - val_loss: 0.1561 - val_auc_53: 0.9480\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1419 - auc_53: 0.9496 - val_loss: 0.1457 - val_auc_53: 0.9525\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1398 - auc_53: 0.9531 - val_loss: 0.1625 - val_auc_53: 0.9461\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1377 - auc_53: 0.9518 - val_loss: 0.1470 - val_auc_53: 0.9525\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1435 - auc_53: 0.9561 - val_loss: 0.1525 - val_auc_53: 0.9497\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1367 - auc_53: 0.9520 - val_loss: 0.1633 - val_auc_53: 0.9467\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1325 - auc_53: 0.9546 - val_loss: 0.1507 - val_auc_53: 0.9513\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1308 - auc_53: 0.9569 - val_loss: 0.1355 - val_auc_53: 0.9559\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1388 - auc_53: 0.9565 - val_loss: 0.1290 - val_auc_53: 0.9590\n",
      "Epoch 51/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1299 - auc_53: 0.9567 - val_loss: 0.1411 - val_auc_53: 0.9551\n",
      "Epoch 52/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1266 - auc_53: 0.9580 - val_loss: 0.1472 - val_auc_53: 0.9531\n",
      "Epoch 53/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1250 - auc_53: 0.9590 - val_loss: 0.1320 - val_auc_53: 0.9578\n",
      "Epoch 54/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1242 - auc_53: 0.9598 - val_loss: 0.1413 - val_auc_53: 0.9550\n",
      "Epoch 55/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1221 - auc_53: 0.9590 - val_loss: 0.1624 - val_auc_53: 0.9491\n",
      "Epoch 56/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1210 - auc_53: 0.9591 - val_loss: 0.1412 - val_auc_53: 0.9552\n",
      "Epoch 57/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1194 - auc_53: 0.9611 - val_loss: 0.1408 - val_auc_53: 0.9559\n",
      "Epoch 58/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1179 - auc_53: 0.9623 - val_loss: 0.1466 - val_auc_53: 0.9540\n",
      "Epoch 59/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1169 - auc_53: 0.9608 - val_loss: 0.1454 - val_auc_53: 0.9541\n",
      "Epoch 60/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1160 - auc_53: 0.9601 - val_loss: 0.1367 - val_auc_53: 0.9573\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 2s 21ms/step - loss: 0.5884 - auc_54: 0.5970 - val_loss: 0.4114 - val_auc_54: 0.7105\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.4516 - auc_54: 0.7623 - val_loss: 0.3635 - val_auc_54: 0.7848\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3840 - auc_54: 0.8144 - val_loss: 0.3347 - val_auc_54: 0.8206\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3467 - auc_54: 0.8330 - val_loss: 0.3017 - val_auc_54: 0.8485\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3240 - auc_54: 0.8420 - val_loss: 0.2723 - val_auc_54: 0.8674\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3098 - auc_54: 0.8602 - val_loss: 0.2614 - val_auc_54: 0.8749\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2955 - auc_54: 0.8683 - val_loss: 0.2618 - val_auc_54: 0.8788\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2839 - auc_54: 0.8745 - val_loss: 0.2659 - val_auc_54: 0.8799\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2738 - auc_54: 0.8807 - val_loss: 0.2446 - val_auc_54: 0.8906\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2641 - auc_54: 0.8842 - val_loss: 0.2329 - val_auc_54: 0.8976\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2558 - auc_54: 0.8896 - val_loss: 0.2508 - val_auc_54: 0.8896\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2490 - auc_54: 0.8886 - val_loss: 0.2369 - val_auc_54: 0.8989\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2416 - auc_54: 0.8958 - val_loss: 0.2362 - val_auc_54: 0.8981\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2358 - auc_54: 0.8978 - val_loss: 0.2354 - val_auc_54: 0.9006\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2290 - auc_54: 0.9025 - val_loss: 0.2409 - val_auc_54: 0.9002\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2239 - auc_54: 0.9034 - val_loss: 0.2187 - val_auc_54: 0.9105\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2172 - auc_54: 0.9092 - val_loss: 0.2106 - val_auc_54: 0.9160\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2134 - auc_54: 0.9130 - val_loss: 0.1843 - val_auc_54: 0.9271\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2111 - auc_54: 0.9164 - val_loss: 0.1967 - val_auc_54: 0.9221\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2037 - auc_54: 0.9166 - val_loss: 0.2016 - val_auc_54: 0.9206\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1994 - auc_54: 0.9187 - val_loss: 0.1731 - val_auc_54: 0.9336\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1967 - auc_54: 0.9232 - val_loss: 0.1973 - val_auc_54: 0.9251\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1906 - auc_54: 0.9216 - val_loss: 0.1953 - val_auc_54: 0.9262\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1863 - auc_54: 0.9257 - val_loss: 0.2145 - val_auc_54: 0.9191\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1841 - auc_54: 0.9236 - val_loss: 0.2038 - val_auc_54: 0.9238\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1798 - auc_54: 0.9277 - val_loss: 0.1814 - val_auc_54: 0.9332\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1745 - auc_54: 0.9347 - val_loss: 0.1981 - val_auc_54: 0.9264\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1717 - auc_54: 0.9323 - val_loss: 0.1850 - val_auc_54: 0.9322\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1677 - auc_54: 0.9348 - val_loss: 0.1678 - val_auc_54: 0.9386\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1646 - auc_54: 0.9388 - val_loss: 0.1646 - val_auc_54: 0.9404\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1616 - auc_54: 0.9398 - val_loss: 0.1823 - val_auc_54: 0.9329\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1582 - auc_54: 0.9391 - val_loss: 0.1516 - val_auc_54: 0.9453\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1558 - auc_54: 0.9411 - val_loss: 0.1671 - val_auc_54: 0.9400\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1541 - auc_54: 0.9447 - val_loss: 0.1684 - val_auc_54: 0.9405\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1495 - auc_54: 0.9462 - val_loss: 0.1696 - val_auc_54: 0.9402\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1469 - auc_54: 0.9473 - val_loss: 0.1744 - val_auc_54: 0.9381\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1444 - auc_54: 0.9448 - val_loss: 0.1537 - val_auc_54: 0.9465\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1422 - auc_54: 0.9485 - val_loss: 0.1686 - val_auc_54: 0.9409\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1399 - auc_54: 0.9485 - val_loss: 0.1567 - val_auc_54: 0.9461\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1376 - auc_54: 0.9490 - val_loss: 0.1554 - val_auc_54: 0.9469\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1350 - auc_54: 0.9506 - val_loss: 0.1417 - val_auc_54: 0.9510\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1327 - auc_54: 0.9525 - val_loss: 0.1410 - val_auc_54: 0.9511\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1309 - auc_54: 0.9549 - val_loss: 0.1490 - val_auc_54: 0.9492\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1286 - auc_54: 0.9537 - val_loss: 0.1422 - val_auc_54: 0.9511\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1268 - auc_54: 0.9547 - val_loss: 0.1367 - val_auc_54: 0.9536\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1250 - auc_54: 0.9549 - val_loss: 0.1332 - val_auc_54: 0.9550\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1229 - auc_54: 0.9570 - val_loss: 0.1615 - val_auc_54: 0.9454\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1214 - auc_54: 0.9548 - val_loss: 0.1463 - val_auc_54: 0.9514\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1188 - auc_54: 0.9586 - val_loss: 0.1481 - val_auc_54: 0.9498\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1173 - auc_54: 0.9581 - val_loss: 0.1387 - val_auc_54: 0.9542\n",
      "Epoch 51/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1173 - auc_54: 0.9612 - val_loss: 0.1354 - val_auc_54: 0.9556\n",
      "Epoch 52/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1139 - auc_54: 0.9606 - val_loss: 0.1211 - val_auc_54: 0.9600\n",
      "Epoch 53/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1117 - auc_54: 0.9595 - val_loss: 0.1225 - val_auc_54: 0.9600\n",
      "Epoch 54/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1104 - auc_54: 0.9631 - val_loss: 0.1268 - val_auc_54: 0.9586\n",
      "Epoch 55/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1087 - auc_54: 0.9615 - val_loss: 0.1274 - val_auc_54: 0.9581\n",
      "Epoch 56/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1071 - auc_54: 0.9627 - val_loss: 0.1281 - val_auc_54: 0.9586\n",
      "Epoch 57/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1071 - auc_54: 0.9650 - val_loss: 0.1466 - val_auc_54: 0.9525\n",
      "Epoch 58/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1046 - auc_54: 0.9638 - val_loss: 0.1373 - val_auc_54: 0.9555\n",
      "Epoch 59/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1064 - auc_54: 0.9612 - val_loss: 0.1331 - val_auc_54: 0.9574\n",
      "Epoch 60/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1013 - auc_54: 0.9652 - val_loss: 0.1263 - val_auc_54: 0.9589\n",
      "Epoch 61/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0998 - auc_54: 0.9655 - val_loss: 0.1222 - val_auc_54: 0.9589\n",
      "Epoch 62/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0983 - auc_54: 0.9658 - val_loss: 0.1298 - val_auc_54: 0.9580\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.5867 - auc_55: 0.6031 - val_loss: 0.4411 - val_auc_55: 0.7069\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.4406 - auc_55: 0.7585 - val_loss: 0.3620 - val_auc_55: 0.7962\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3745 - auc_55: 0.8084 - val_loss: 0.3475 - val_auc_55: 0.8206\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3388 - auc_55: 0.8378 - val_loss: 0.3274 - val_auc_55: 0.8410\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3163 - auc_55: 0.8511 - val_loss: 0.2990 - val_auc_55: 0.8592\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2996 - auc_55: 0.8569 - val_loss: 0.2866 - val_auc_55: 0.8677\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2851 - auc_55: 0.8752 - val_loss: 0.2677 - val_auc_55: 0.8775\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2750 - auc_55: 0.8743 - val_loss: 0.2829 - val_auc_55: 0.8736\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2643 - auc_55: 0.8807 - val_loss: 0.2588 - val_auc_55: 0.8856\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2563 - auc_55: 0.8857 - val_loss: 0.2824 - val_auc_55: 0.8788\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2467 - auc_55: 0.8933 - val_loss: 0.2335 - val_auc_55: 0.9011\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2391 - auc_55: 0.8979 - val_loss: 0.2162 - val_auc_55: 0.9102\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2333 - auc_55: 0.9033 - val_loss: 0.2133 - val_auc_55: 0.9120\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2261 - auc_55: 0.9047 - val_loss: 0.2483 - val_auc_55: 0.9002\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2242 - auc_55: 0.9025 - val_loss: 0.2642 - val_auc_55: 0.8945\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2173 - auc_55: 0.9069 - val_loss: 0.2127 - val_auc_55: 0.9151\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2102 - auc_55: 0.9156 - val_loss: 0.2084 - val_auc_55: 0.9178\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2049 - auc_55: 0.9168 - val_loss: 0.2027 - val_auc_55: 0.9206\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2010 - auc_55: 0.9215 - val_loss: 0.1927 - val_auc_55: 0.9262\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1971 - auc_55: 0.9245 - val_loss: 0.1838 - val_auc_55: 0.9307\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1909 - auc_55: 0.9256 - val_loss: 0.2118 - val_auc_55: 0.9213\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1866 - auc_55: 0.9258 - val_loss: 0.1949 - val_auc_55: 0.9284\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1855 - auc_55: 0.9327 - val_loss: 0.1868 - val_auc_55: 0.9322\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1789 - auc_55: 0.9313 - val_loss: 0.1878 - val_auc_55: 0.9327\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1757 - auc_55: 0.9329 - val_loss: 0.1841 - val_auc_55: 0.9349\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1719 - auc_55: 0.9340 - val_loss: 0.2069 - val_auc_55: 0.9267\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1684 - auc_55: 0.9345 - val_loss: 0.1837 - val_auc_55: 0.9351\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1658 - auc_55: 0.9356 - val_loss: 0.1846 - val_auc_55: 0.9359\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1633 - auc_55: 0.9394 - val_loss: 0.1541 - val_auc_55: 0.9471\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1658 - auc_55: 0.9437 - val_loss: 0.1509 - val_auc_55: 0.9483\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1561 - auc_55: 0.9441 - val_loss: 0.1754 - val_auc_55: 0.9405\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1531 - auc_55: 0.9443 - val_loss: 0.1724 - val_auc_55: 0.9427\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1506 - auc_55: 0.9443 - val_loss: 0.1707 - val_auc_55: 0.9434\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1492 - auc_55: 0.9444 - val_loss: 0.1663 - val_auc_55: 0.9452\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1473 - auc_55: 0.9484 - val_loss: 0.1480 - val_auc_55: 0.9505\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1435 - auc_55: 0.9482 - val_loss: 0.1643 - val_auc_55: 0.9460\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1409 - auc_55: 0.9483 - val_loss: 0.1828 - val_auc_55: 0.9412\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1389 - auc_55: 0.9487 - val_loss: 0.1534 - val_auc_55: 0.9493\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1359 - auc_55: 0.9502 - val_loss: 0.1656 - val_auc_55: 0.9464\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1341 - auc_55: 0.9503 - val_loss: 0.1339 - val_auc_55: 0.9563\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1380 - auc_55: 0.9562 - val_loss: 0.1434 - val_auc_55: 0.9528\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1306 - auc_55: 0.9554 - val_loss: 0.1492 - val_auc_55: 0.9511\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1280 - auc_55: 0.9527 - val_loss: 0.1440 - val_auc_55: 0.9529\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1266 - auc_55: 0.9566 - val_loss: 0.1448 - val_auc_55: 0.9528\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1241 - auc_55: 0.9539 - val_loss: 0.1518 - val_auc_55: 0.9503\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1224 - auc_55: 0.9563 - val_loss: 0.1274 - val_auc_55: 0.9598\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1214 - auc_55: 0.9599 - val_loss: 0.1375 - val_auc_55: 0.9556\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1185 - auc_55: 0.9575 - val_loss: 0.1351 - val_auc_55: 0.9565\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1162 - auc_55: 0.9582 - val_loss: 0.1400 - val_auc_55: 0.9551\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1160 - auc_55: 0.9577 - val_loss: 0.1494 - val_auc_55: 0.9524\n",
      "Epoch 51/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1145 - auc_55: 0.9582 - val_loss: 0.1355 - val_auc_55: 0.9572\n",
      "Epoch 52/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1120 - auc_55: 0.9602 - val_loss: 0.1237 - val_auc_55: 0.9605\n",
      "Epoch 53/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1098 - auc_55: 0.9633 - val_loss: 0.1404 - val_auc_55: 0.9556\n",
      "Epoch 54/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1079 - auc_55: 0.9630 - val_loss: 0.1276 - val_auc_55: 0.9601\n",
      "Epoch 55/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1070 - auc_55: 0.9623 - val_loss: 0.1266 - val_auc_55: 0.9605\n",
      "Epoch 56/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1097 - auc_55: 0.9641 - val_loss: 0.1238 - val_auc_55: 0.9607\n",
      "Epoch 57/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1039 - auc_55: 0.9645 - val_loss: 0.1303 - val_auc_55: 0.9592\n",
      "Epoch 58/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1025 - auc_55: 0.9653 - val_loss: 0.1320 - val_auc_55: 0.9589\n",
      "Epoch 59/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1059 - auc_55: 0.9615 - val_loss: 0.1324 - val_auc_55: 0.9589\n",
      "Epoch 60/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0999 - auc_55: 0.9657 - val_loss: 0.1343 - val_auc_55: 0.9587\n",
      "Epoch 61/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0988 - auc_55: 0.9660 - val_loss: 0.1223 - val_auc_55: 0.9618\n",
      "Epoch 62/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0969 - auc_55: 0.9668 - val_loss: 0.1169 - val_auc_55: 0.9631\n",
      "Epoch 63/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0955 - auc_55: 0.9680 - val_loss: 0.1325 - val_auc_55: 0.9587\n",
      "Epoch 64/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0949 - auc_55: 0.9675 - val_loss: 0.1134 - val_auc_55: 0.9647\n",
      "Epoch 65/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0934 - auc_55: 0.9683 - val_loss: 0.1136 - val_auc_55: 0.9640\n",
      "Epoch 66/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0914 - auc_55: 0.9697 - val_loss: 0.1349 - val_auc_55: 0.9585\n",
      "Epoch 67/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0918 - auc_55: 0.9685 - val_loss: 0.1243 - val_auc_55: 0.9622\n",
      "Epoch 68/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0895 - auc_55: 0.9702 - val_loss: 0.1074 - val_auc_55: 0.9679\n",
      "Epoch 69/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0887 - auc_55: 0.9705 - val_loss: 0.1118 - val_auc_55: 0.9656\n",
      "Epoch 70/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0871 - auc_55: 0.9698 - val_loss: 0.1198 - val_auc_55: 0.9638\n",
      "Epoch 71/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0856 - auc_55: 0.9705 - val_loss: 0.1171 - val_auc_55: 0.9640\n",
      "Epoch 72/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0846 - auc_55: 0.9705 - val_loss: 0.1268 - val_auc_55: 0.9620\n",
      "Epoch 73/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0838 - auc_55: 0.9695 - val_loss: 0.1036 - val_auc_55: 0.9696\n",
      "Epoch 74/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0829 - auc_55: 0.9715 - val_loss: 0.1119 - val_auc_55: 0.9676\n",
      "Epoch 75/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0845 - auc_55: 0.9722 - val_loss: 0.1043 - val_auc_55: 0.9700\n",
      "Epoch 76/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0807 - auc_55: 0.9718 - val_loss: 0.1059 - val_auc_55: 0.9690\n",
      "Epoch 77/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0815 - auc_55: 0.9737 - val_loss: 0.1038 - val_auc_55: 0.9678\n",
      "Epoch 78/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0785 - auc_55: 0.9725 - val_loss: 0.1184 - val_auc_55: 0.9648\n",
      "Epoch 79/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0781 - auc_55: 0.9718 - val_loss: 0.1126 - val_auc_55: 0.9648\n",
      "Epoch 80/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0772 - auc_55: 0.9715 - val_loss: 0.0894 - val_auc_55: 0.9729\n",
      "Epoch 81/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0803 - auc_55: 0.9733 - val_loss: 0.0943 - val_auc_55: 0.9721\n",
      "Epoch 82/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0755 - auc_55: 0.9745 - val_loss: 0.1049 - val_auc_55: 0.9690\n",
      "Epoch 83/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0739 - auc_55: 0.9737 - val_loss: 0.1027 - val_auc_55: 0.9693\n",
      "Epoch 84/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0746 - auc_55: 0.9717 - val_loss: 0.1094 - val_auc_55: 0.9665\n",
      "Epoch 85/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0725 - auc_55: 0.9735 - val_loss: 0.1032 - val_auc_55: 0.9690\n",
      "Epoch 86/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0713 - auc_55: 0.9742 - val_loss: 0.0945 - val_auc_55: 0.9715\n",
      "Epoch 87/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0700 - auc_55: 0.9748 - val_loss: 0.1056 - val_auc_55: 0.9675\n",
      "Epoch 88/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0703 - auc_55: 0.9745 - val_loss: 0.0959 - val_auc_55: 0.9709\n",
      "Epoch 89/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0688 - auc_55: 0.9757 - val_loss: 0.1017 - val_auc_55: 0.9695\n",
      "Epoch 90/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0677 - auc_55: 0.9758 - val_loss: 0.0947 - val_auc_55: 0.9709\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.6238 - auc_56: 0.5210 - val_loss: 0.5045 - val_auc_56: 0.6018\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.4349 - auc_56: 0.7079 - val_loss: 0.3613 - val_auc_56: 0.7341\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3233 - auc_56: 0.8382 - val_loss: 0.2805 - val_auc_56: 0.7880\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2749 - auc_56: 0.8774 - val_loss: 0.2377 - val_auc_56: 0.8121\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2501 - auc_56: 0.8943 - val_loss: 0.2244 - val_auc_56: 0.8209\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2335 - auc_56: 0.9003 - val_loss: 0.2367 - val_auc_56: 0.8198\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2231 - auc_56: 0.9091 - val_loss: 0.2103 - val_auc_56: 0.8305\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2159 - auc_56: 0.9127 - val_loss: 0.1857 - val_auc_56: 0.8450\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2090 - auc_56: 0.9193 - val_loss: 0.1698 - val_auc_56: 0.8475\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2043 - auc_56: 0.9228 - val_loss: 0.2016 - val_auc_56: 0.8425\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1997 - auc_56: 0.9228 - val_loss: 0.1971 - val_auc_56: 0.8462\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1956 - auc_56: 0.9263 - val_loss: 0.1747 - val_auc_56: 0.8558\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1917 - auc_56: 0.9266 - val_loss: 0.1945 - val_auc_56: 0.8469\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1862 - auc_56: 0.9298 - val_loss: 0.1703 - val_auc_56: 0.8589\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1828 - auc_56: 0.9324 - val_loss: 0.1737 - val_auc_56: 0.8584\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1791 - auc_56: 0.9315 - val_loss: 0.1804 - val_auc_56: 0.8588\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1749 - auc_56: 0.9322 - val_loss: 0.1510 - val_auc_56: 0.8694\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1713 - auc_56: 0.9368 - val_loss: 0.1576 - val_auc_56: 0.8666\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1664 - auc_56: 0.9377 - val_loss: 0.1564 - val_auc_56: 0.8689\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1621 - auc_56: 0.9399 - val_loss: 0.1773 - val_auc_56: 0.8646\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1583 - auc_56: 0.9393 - val_loss: 0.1520 - val_auc_56: 0.8745\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1537 - auc_56: 0.9436 - val_loss: 0.1536 - val_auc_56: 0.8757\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1503 - auc_56: 0.9448 - val_loss: 0.1583 - val_auc_56: 0.8751\n",
      "Epoch 24/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1466 - auc_56: 0.9444 - val_loss: 0.1472 - val_auc_56: 0.8827\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1431 - auc_56: 0.9479 - val_loss: 0.1364 - val_auc_56: 0.8658\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1393 - auc_56: 0.9483 - val_loss: 0.1373 - val_auc_56: 0.8670\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1357 - auc_56: 0.9516 - val_loss: 0.1353 - val_auc_56: 0.8697\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1326 - auc_56: 0.9522 - val_loss: 0.1277 - val_auc_56: 0.8565\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1297 - auc_56: 0.9534 - val_loss: 0.1229 - val_auc_56: 0.8590\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1268 - auc_56: 0.9545 - val_loss: 0.1376 - val_auc_56: 0.8720\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1261 - auc_56: 0.9523 - val_loss: 0.1260 - val_auc_56: 0.8587\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1219 - auc_56: 0.9569 - val_loss: 0.1333 - val_auc_56: 0.8597\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1195 - auc_56: 0.9616 - val_loss: 0.1260 - val_auc_56: 0.8613\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1164 - auc_56: 0.9577 - val_loss: 0.1289 - val_auc_56: 0.8624\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1157 - auc_56: 0.9565 - val_loss: 0.1255 - val_auc_56: 0.8643\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1120 - auc_56: 0.9609 - val_loss: 0.1293 - val_auc_56: 0.8630\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1099 - auc_56: 0.9615 - val_loss: 0.1195 - val_auc_56: 0.8627\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1077 - auc_56: 0.9639 - val_loss: 0.1194 - val_auc_56: 0.8650\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1100 - auc_56: 0.9663 - val_loss: 0.1201 - val_auc_56: 0.8631\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1042 - auc_56: 0.9643 - val_loss: 0.1282 - val_auc_56: 0.8625\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1031 - auc_56: 0.9635 - val_loss: 0.1242 - val_auc_56: 0.8637\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1003 - auc_56: 0.9667 - val_loss: 0.1190 - val_auc_56: 0.8645\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0984 - auc_56: 0.9663 - val_loss: 0.1249 - val_auc_56: 0.8637\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0966 - auc_56: 0.9674 - val_loss: 0.1069 - val_auc_56: 0.8662\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0949 - auc_56: 0.9689 - val_loss: 0.1191 - val_auc_56: 0.8653\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0948 - auc_56: 0.9657 - val_loss: 0.1201 - val_auc_56: 0.8656\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0919 - auc_56: 0.9689 - val_loss: 0.1248 - val_auc_56: 0.8648\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0907 - auc_56: 0.9693 - val_loss: 0.1170 - val_auc_56: 0.8672\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0891 - auc_56: 0.9686 - val_loss: 0.1057 - val_auc_56: 0.8696\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0872 - auc_56: 0.9703 - val_loss: 0.1010 - val_auc_56: 0.8485\n",
      "Epoch 51/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0861 - auc_56: 0.9705 - val_loss: 0.1023 - val_auc_56: 0.8681\n",
      "Epoch 52/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0843 - auc_56: 0.9715 - val_loss: 0.1045 - val_auc_56: 0.8485\n",
      "Epoch 53/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0834 - auc_56: 0.9717 - val_loss: 0.0969 - val_auc_56: 0.8506\n",
      "Epoch 54/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0824 - auc_56: 0.9735 - val_loss: 0.1103 - val_auc_56: 0.8705\n",
      "Epoch 55/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0806 - auc_56: 0.9727 - val_loss: 0.1039 - val_auc_56: 0.8513\n",
      "Epoch 56/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0791 - auc_56: 0.9737 - val_loss: 0.0938 - val_auc_56: 0.8527\n",
      "Epoch 57/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0777 - auc_56: 0.9745 - val_loss: 0.0969 - val_auc_56: 0.8514\n",
      "Epoch 58/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0764 - auc_56: 0.9742 - val_loss: 0.0932 - val_auc_56: 0.8532\n",
      "Epoch 59/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0768 - auc_56: 0.9756 - val_loss: 0.0980 - val_auc_56: 0.8515\n",
      "Epoch 60/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0740 - auc_56: 0.9750 - val_loss: 0.1113 - val_auc_56: 0.8496\n",
      "Epoch 61/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0799 - auc_56: 0.9692 - val_loss: 0.0961 - val_auc_56: 0.8540\n",
      "Epoch 62/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0785 - auc_56: 0.9756 - val_loss: 0.0973 - val_auc_56: 0.8556\n",
      "Epoch 63/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0717 - auc_56: 0.9763 - val_loss: 0.0937 - val_auc_56: 0.8552\n",
      "Epoch 64/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0706 - auc_56: 0.9775 - val_loss: 0.1022 - val_auc_56: 0.8523\n",
      "Epoch 65/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0725 - auc_56: 0.9740 - val_loss: 0.1018 - val_auc_56: 0.8529\n",
      "Epoch 66/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0686 - auc_56: 0.9777 - val_loss: 0.0997 - val_auc_56: 0.8529\n",
      "Epoch 67/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0678 - auc_56: 0.9778 - val_loss: 0.0948 - val_auc_56: 0.8532\n",
      "Epoch 68/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0669 - auc_56: 0.9785 - val_loss: 0.0958 - val_auc_56: 0.8532\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.5455 - auc_57: 0.5983 - val_loss: 0.4388 - val_auc_57: 0.6527\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3881 - auc_57: 0.7833 - val_loss: 0.3164 - val_auc_57: 0.7737\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3075 - auc_57: 0.8574 - val_loss: 0.2747 - val_auc_57: 0.8009\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2665 - auc_57: 0.8834 - val_loss: 0.2491 - val_auc_57: 0.8184\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2432 - auc_57: 0.9018 - val_loss: 0.2668 - val_auc_57: 0.8151\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2278 - auc_57: 0.9047 - val_loss: 0.2074 - val_auc_57: 0.8406\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2168 - auc_57: 0.9131 - val_loss: 0.2144 - val_auc_57: 0.8399\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2081 - auc_57: 0.9173 - val_loss: 0.1858 - val_auc_57: 0.8513\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2015 - auc_57: 0.9256 - val_loss: 0.2068 - val_auc_57: 0.8470\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1960 - auc_57: 0.9242 - val_loss: 0.1963 - val_auc_57: 0.8501\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1891 - auc_57: 0.9288 - val_loss: 0.1652 - val_auc_57: 0.8604\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1840 - auc_57: 0.9344 - val_loss: 0.1880 - val_auc_57: 0.8581\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1787 - auc_57: 0.9323 - val_loss: 0.1539 - val_auc_57: 0.8636\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1803 - auc_57: 0.9387 - val_loss: 0.1538 - val_auc_57: 0.8665\n",
      "Epoch 15/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1720 - auc_57: 0.9393 - val_loss: 0.1824 - val_auc_57: 0.8591\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1677 - auc_57: 0.9374 - val_loss: 0.1593 - val_auc_57: 0.8689\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1632 - auc_57: 0.9393 - val_loss: 0.1507 - val_auc_57: 0.8671\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1599 - auc_57: 0.9415 - val_loss: 0.1542 - val_auc_57: 0.8642\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1563 - auc_57: 0.9423 - val_loss: 0.1530 - val_auc_57: 0.8661\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1522 - auc_57: 0.9452 - val_loss: 0.1529 - val_auc_57: 0.8674\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1493 - auc_57: 0.9453 - val_loss: 0.1320 - val_auc_57: 0.8743\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1455 - auc_57: 0.9472 - val_loss: 0.1302 - val_auc_57: 0.8767\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1415 - auc_57: 0.9499 - val_loss: 0.1498 - val_auc_57: 0.8698\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1388 - auc_57: 0.9501 - val_loss: 0.1373 - val_auc_57: 0.8774\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1358 - auc_57: 0.9529 - val_loss: 0.1353 - val_auc_57: 0.8769\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1339 - auc_57: 0.9507 - val_loss: 0.1388 - val_auc_57: 0.8832\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1291 - auc_57: 0.9539 - val_loss: 0.1268 - val_auc_57: 0.8846\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1262 - auc_57: 0.9545 - val_loss: 0.1259 - val_auc_57: 0.8857\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1236 - auc_57: 0.9572 - val_loss: 0.1249 - val_auc_57: 0.8854\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1210 - auc_57: 0.9586 - val_loss: 0.1276 - val_auc_57: 0.8848\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1178 - auc_57: 0.9574 - val_loss: 0.1364 - val_auc_57: 0.8832\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1198 - auc_57: 0.9549 - val_loss: 0.1350 - val_auc_57: 0.8712\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1132 - auc_57: 0.9616 - val_loss: 0.1232 - val_auc_57: 0.8765\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1102 - auc_57: 0.9616 - val_loss: 0.1196 - val_auc_57: 0.8578\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1077 - auc_57: 0.9626 - val_loss: 0.0976 - val_auc_57: 0.8643\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1124 - auc_57: 0.9641 - val_loss: 0.1013 - val_auc_57: 0.8588\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1042 - auc_57: 0.9650 - val_loss: 0.1075 - val_auc_57: 0.8633\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1015 - auc_57: 0.9650 - val_loss: 0.1076 - val_auc_57: 0.8617\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1012 - auc_57: 0.9660 - val_loss: 0.1041 - val_auc_57: 0.8598\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0977 - auc_57: 0.9655 - val_loss: 0.1106 - val_auc_57: 0.8616\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0953 - auc_57: 0.9678 - val_loss: 0.1073 - val_auc_57: 0.8622\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0941 - auc_57: 0.9669 - val_loss: 0.1090 - val_auc_57: 0.8641\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0917 - auc_57: 0.9694 - val_loss: 0.1052 - val_auc_57: 0.8639\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0899 - auc_57: 0.9695 - val_loss: 0.0970 - val_auc_57: 0.8659\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0885 - auc_57: 0.9707 - val_loss: 0.0993 - val_auc_57: 0.8666\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0864 - auc_57: 0.9704 - val_loss: 0.0966 - val_auc_57: 0.8660\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0868 - auc_57: 0.9697 - val_loss: 0.1120 - val_auc_57: 0.8650\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0834 - auc_57: 0.9714 - val_loss: 0.0983 - val_auc_57: 0.8660\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0819 - auc_57: 0.9721 - val_loss: 0.1068 - val_auc_57: 0.8662\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0814 - auc_57: 0.9706 - val_loss: 0.1048 - val_auc_57: 0.8660\n",
      "Epoch 51/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0790 - auc_57: 0.9739 - val_loss: 0.0944 - val_auc_57: 0.8686\n",
      "Epoch 52/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0770 - auc_57: 0.9730 - val_loss: 0.0898 - val_auc_57: 0.8712\n",
      "Epoch 53/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0757 - auc_57: 0.9736 - val_loss: 0.0974 - val_auc_57: 0.8674\n",
      "Epoch 54/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0745 - auc_57: 0.9745 - val_loss: 0.0922 - val_auc_57: 0.8706\n",
      "Epoch 55/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0727 - auc_57: 0.9750 - val_loss: 0.1030 - val_auc_57: 0.8660\n",
      "Epoch 56/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0731 - auc_57: 0.9732 - val_loss: 0.0967 - val_auc_57: 0.8682\n",
      "Epoch 57/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0715 - auc_57: 0.9740 - val_loss: 0.0967 - val_auc_57: 0.8690\n",
      "Epoch 58/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0693 - auc_57: 0.9757 - val_loss: 0.0939 - val_auc_57: 0.8711\n",
      "Epoch 59/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0677 - auc_57: 0.9755 - val_loss: 0.0865 - val_auc_57: 0.8721\n",
      "Epoch 60/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0663 - auc_57: 0.9773 - val_loss: 0.0941 - val_auc_57: 0.8694\n",
      "Epoch 61/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0653 - auc_57: 0.9758 - val_loss: 0.0842 - val_auc_57: 0.8740\n",
      "Epoch 62/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0640 - auc_57: 0.9778 - val_loss: 0.0930 - val_auc_57: 0.8704\n",
      "Epoch 63/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0630 - auc_57: 0.9773 - val_loss: 0.0872 - val_auc_57: 0.8727\n",
      "Epoch 64/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0621 - auc_57: 0.9788 - val_loss: 0.0863 - val_auc_57: 0.8740\n",
      "Epoch 65/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0604 - auc_57: 0.9782 - val_loss: 0.0852 - val_auc_57: 0.8753\n",
      "Epoch 66/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0591 - auc_57: 0.9788 - val_loss: 0.0875 - val_auc_57: 0.8747\n",
      "Epoch 67/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0585 - auc_57: 0.9787 - val_loss: 0.0837 - val_auc_57: 0.8752\n",
      "Epoch 68/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0573 - auc_57: 0.9800 - val_loss: 0.0755 - val_auc_57: 0.8184\n",
      "Epoch 69/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0561 - auc_57: 0.9800 - val_loss: 0.0785 - val_auc_57: 0.8379\n",
      "Epoch 70/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0551 - auc_57: 0.9807 - val_loss: 0.0758 - val_auc_57: 0.8180\n",
      "Epoch 71/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0542 - auc_57: 0.9810 - val_loss: 0.0873 - val_auc_57: 0.8557\n",
      "Epoch 72/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0534 - auc_57: 0.9808 - val_loss: 0.0824 - val_auc_57: 0.8165\n",
      "Epoch 73/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0522 - auc_57: 0.9805 - val_loss: 0.0818 - val_auc_57: 0.8166\n",
      "Epoch 74/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0514 - auc_57: 0.9812 - val_loss: 0.0814 - val_auc_57: 0.8174\n",
      "Epoch 75/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0532 - auc_57: 0.9805 - val_loss: 0.0936 - val_auc_57: 0.8543\n",
      "Epoch 76/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0499 - auc_57: 0.9812 - val_loss: 0.0882 - val_auc_57: 0.8154\n",
      "Epoch 77/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0488 - auc_57: 0.9812 - val_loss: 0.0757 - val_auc_57: 0.8221\n",
      "Epoch 78/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0491 - auc_57: 0.9835 - val_loss: 0.0746 - val_auc_57: 0.8229\n",
      "Epoch 79/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0472 - auc_57: 0.9832 - val_loss: 0.0758 - val_auc_57: 0.8228\n",
      "Epoch 80/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0461 - auc_57: 0.9837 - val_loss: 0.0732 - val_auc_57: 0.8237\n",
      "Epoch 81/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0452 - auc_57: 0.9833 - val_loss: 0.0706 - val_auc_57: 0.8228\n",
      "Epoch 82/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0477 - auc_57: 0.9845 - val_loss: 0.0733 - val_auc_57: 0.8237\n",
      "Epoch 83/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0436 - auc_57: 0.9843 - val_loss: 0.0727 - val_auc_57: 0.8237\n",
      "Epoch 84/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0430 - auc_57: 0.9848 - val_loss: 0.0699 - val_auc_57: 0.8240\n",
      "Epoch 85/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0492 - auc_57: 0.9853 - val_loss: 0.0681 - val_auc_57: 0.8260\n",
      "Epoch 86/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0422 - auc_57: 0.9858 - val_loss: 0.0820 - val_auc_57: 0.8221\n",
      "Epoch 87/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0416 - auc_57: 0.9847 - val_loss: 0.0809 - val_auc_57: 0.8225\n",
      "Epoch 88/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0406 - auc_57: 0.9850 - val_loss: 0.0725 - val_auc_57: 0.8253\n",
      "Epoch 89/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0397 - auc_57: 0.9863 - val_loss: 0.0790 - val_auc_57: 0.8231\n",
      "Epoch 90/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0393 - auc_57: 0.9852 - val_loss: 0.0756 - val_auc_57: 0.8239\n",
      "Epoch 91/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0389 - auc_57: 0.9860 - val_loss: 0.0828 - val_auc_57: 0.8214\n",
      "Epoch 92/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0387 - auc_57: 0.9857 - val_loss: 0.0772 - val_auc_57: 0.8233\n",
      "Epoch 93/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0378 - auc_57: 0.9860 - val_loss: 0.0737 - val_auc_57: 0.8259\n",
      "Epoch 94/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0369 - auc_57: 0.9882 - val_loss: 0.0781 - val_auc_57: 0.8239\n",
      "Epoch 95/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0364 - auc_57: 0.9872 - val_loss: 0.0714 - val_auc_57: 0.8264\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.6114 - auc_58: 0.5478 - val_loss: 0.4539 - val_auc_58: 0.6567\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.4325 - auc_58: 0.7452 - val_loss: 0.3553 - val_auc_58: 0.7636\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3412 - auc_58: 0.8301 - val_loss: 0.3154 - val_auc_58: 0.7824\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2924 - auc_58: 0.8663 - val_loss: 0.2610 - val_auc_58: 0.8085\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2637 - auc_58: 0.8840 - val_loss: 0.2518 - val_auc_58: 0.8166\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2446 - auc_58: 0.8969 - val_loss: 0.2145 - val_auc_58: 0.8319\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2320 - auc_58: 0.9046 - val_loss: 0.2650 - val_auc_58: 0.8276\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2266 - auc_58: 0.9009 - val_loss: 0.2218 - val_auc_58: 0.8385\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2161 - auc_58: 0.9136 - val_loss: 0.2139 - val_auc_58: 0.8436\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2092 - auc_58: 0.9163 - val_loss: 0.1875 - val_auc_58: 0.8548\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2047 - auc_58: 0.9199 - val_loss: 0.1925 - val_auc_58: 0.8549\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1998 - auc_58: 0.9215 - val_loss: 0.1778 - val_auc_58: 0.8612\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1946 - auc_58: 0.9254 - val_loss: 0.1866 - val_auc_58: 0.8621\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1902 - auc_58: 0.9263 - val_loss: 0.1852 - val_auc_58: 0.8652\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1861 - auc_58: 0.9277 - val_loss: 0.1808 - val_auc_58: 0.8680\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1825 - auc_58: 0.9306 - val_loss: 0.1796 - val_auc_58: 0.8692\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1784 - auc_58: 0.9317 - val_loss: 0.1676 - val_auc_58: 0.8724\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1735 - auc_58: 0.9347 - val_loss: 0.2136 - val_auc_58: 0.8584\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1797 - auc_58: 0.9274 - val_loss: 0.1836 - val_auc_58: 0.8675\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1677 - auc_58: 0.9364 - val_loss: 0.1653 - val_auc_58: 0.8727\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1643 - auc_58: 0.9388 - val_loss: 0.1567 - val_auc_58: 0.8769\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1638 - auc_58: 0.9437 - val_loss: 0.1575 - val_auc_58: 0.8769\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1573 - auc_58: 0.9433 - val_loss: 0.1527 - val_auc_58: 0.8832\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1542 - auc_58: 0.9432 - val_loss: 0.1585 - val_auc_58: 0.8811\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1508 - auc_58: 0.9440 - val_loss: 0.1544 - val_auc_58: 0.8821\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1475 - auc_58: 0.9460 - val_loss: 0.1417 - val_auc_58: 0.8862\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1446 - auc_58: 0.9463 - val_loss: 0.1366 - val_auc_58: 0.8896\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1419 - auc_58: 0.9493 - val_loss: 0.1410 - val_auc_58: 0.8887\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1390 - auc_58: 0.9495 - val_loss: 0.1311 - val_auc_58: 0.8941\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1395 - auc_58: 0.9532 - val_loss: 0.1341 - val_auc_58: 0.8928\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1341 - auc_58: 0.9520 - val_loss: 0.1502 - val_auc_58: 0.8885\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1329 - auc_58: 0.9498 - val_loss: 0.1360 - val_auc_58: 0.8953\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1283 - auc_58: 0.9552 - val_loss: 0.1245 - val_auc_58: 0.8973\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1259 - auc_58: 0.9561 - val_loss: 0.1352 - val_auc_58: 0.8966\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1235 - auc_58: 0.9544 - val_loss: 0.1232 - val_auc_58: 0.8822\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1212 - auc_58: 0.9574 - val_loss: 0.1278 - val_auc_58: 0.8806\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1192 - auc_58: 0.9572 - val_loss: 0.1266 - val_auc_58: 0.8817\n",
      "Epoch 38/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1167 - auc_58: 0.9597 - val_loss: 0.1313 - val_auc_58: 0.8809\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1146 - auc_58: 0.9606 - val_loss: 0.1242 - val_auc_58: 0.8661\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1135 - auc_58: 0.9595 - val_loss: 0.1217 - val_auc_58: 0.8680\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1106 - auc_58: 0.9621 - val_loss: 0.1189 - val_auc_58: 0.8707\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1087 - auc_58: 0.9637 - val_loss: 0.1177 - val_auc_58: 0.8686\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1107 - auc_58: 0.9629 - val_loss: 0.1033 - val_auc_58: 0.8702\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1052 - auc_58: 0.9651 - val_loss: 0.1190 - val_auc_58: 0.8684\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1030 - auc_58: 0.9654 - val_loss: 0.1150 - val_auc_58: 0.8673\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1014 - auc_58: 0.9658 - val_loss: 0.1166 - val_auc_58: 0.8678\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0995 - auc_58: 0.9654 - val_loss: 0.1036 - val_auc_58: 0.8717\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0985 - auc_58: 0.9677 - val_loss: 0.1114 - val_auc_58: 0.8704\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0964 - auc_58: 0.9680 - val_loss: 0.1141 - val_auc_58: 0.8698\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0948 - auc_58: 0.9682 - val_loss: 0.1158 - val_auc_58: 0.8683\n",
      "Epoch 51/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0933 - auc_58: 0.9681 - val_loss: 0.1137 - val_auc_58: 0.8693\n",
      "Epoch 52/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0920 - auc_58: 0.9688 - val_loss: 0.1107 - val_auc_58: 0.8709\n",
      "Epoch 53/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0905 - auc_58: 0.9697 - val_loss: 0.1137 - val_auc_58: 0.8696\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.5841 - auc_59: 0.5947 - val_loss: 0.4400 - val_auc_59: 0.6747\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.4366 - auc_59: 0.7403 - val_loss: 0.3617 - val_auc_59: 0.7257\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3483 - auc_59: 0.8207 - val_loss: 0.2978 - val_auc_59: 0.7793\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2936 - auc_59: 0.8635 - val_loss: 0.2621 - val_auc_59: 0.7952\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2594 - auc_59: 0.8892 - val_loss: 0.2262 - val_auc_59: 0.8176\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2379 - auc_59: 0.9002 - val_loss: 0.2339 - val_auc_59: 0.8260\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2238 - auc_59: 0.9055 - val_loss: 0.2058 - val_auc_59: 0.8369\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2134 - auc_59: 0.9145 - val_loss: 0.2059 - val_auc_59: 0.8418\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2060 - auc_59: 0.9168 - val_loss: 0.1923 - val_auc_59: 0.8493\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1988 - auc_59: 0.9235 - val_loss: 0.2039 - val_auc_59: 0.8464\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1994 - auc_59: 0.9162 - val_loss: 0.1834 - val_auc_59: 0.8585\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1891 - auc_59: 0.9261 - val_loss: 0.1634 - val_auc_59: 0.8688\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1847 - auc_59: 0.9310 - val_loss: 0.1753 - val_auc_59: 0.8636\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1829 - auc_59: 0.9259 - val_loss: 0.1552 - val_auc_59: 0.8721\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1792 - auc_59: 0.9333 - val_loss: 0.1571 - val_auc_59: 0.8750\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1746 - auc_59: 0.9347 - val_loss: 0.1656 - val_auc_59: 0.8724\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1724 - auc_59: 0.9324 - val_loss: 0.1772 - val_auc_59: 0.8684\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1697 - auc_59: 0.9323 - val_loss: 0.1675 - val_auc_59: 0.8729\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1654 - auc_59: 0.9385 - val_loss: 0.1509 - val_auc_59: 0.8812\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1641 - auc_59: 0.9407 - val_loss: 0.1712 - val_auc_59: 0.8737\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1606 - auc_59: 0.9397 - val_loss: 0.1739 - val_auc_59: 0.8734\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1574 - auc_59: 0.9403 - val_loss: 0.1460 - val_auc_59: 0.8629\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1551 - auc_59: 0.9418 - val_loss: 0.1517 - val_auc_59: 0.8647\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1523 - auc_59: 0.9436 - val_loss: 0.1552 - val_auc_59: 0.8791\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1501 - auc_59: 0.9440 - val_loss: 0.1495 - val_auc_59: 0.8799\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1469 - auc_59: 0.9445 - val_loss: 0.1376 - val_auc_59: 0.8678\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1443 - auc_59: 0.9456 - val_loss: 0.1280 - val_auc_59: 0.8739\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1421 - auc_59: 0.9462 - val_loss: 0.1270 - val_auc_59: 0.8551\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1396 - auc_59: 0.9484 - val_loss: 0.1312 - val_auc_59: 0.8700\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1366 - auc_59: 0.9499 - val_loss: 0.1450 - val_auc_59: 0.8841\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1372 - auc_59: 0.9449 - val_loss: 0.1346 - val_auc_59: 0.8869\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1322 - auc_59: 0.9503 - val_loss: 0.1361 - val_auc_59: 0.8870\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1302 - auc_59: 0.9506 - val_loss: 0.1259 - val_auc_59: 0.8757\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1276 - auc_59: 0.9530 - val_loss: 0.1245 - val_auc_59: 0.8765\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1258 - auc_59: 0.9533 - val_loss: 0.1169 - val_auc_59: 0.8454\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1257 - auc_59: 0.9580 - val_loss: 0.1365 - val_auc_59: 0.8766\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1215 - auc_59: 0.9571 - val_loss: 0.1406 - val_auc_59: 0.8943\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1196 - auc_59: 0.9574 - val_loss: 0.1439 - val_auc_59: 0.8912\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1178 - auc_59: 0.9572 - val_loss: 0.1218 - val_auc_59: 0.8809\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1152 - auc_59: 0.9587 - val_loss: 0.1271 - val_auc_59: 0.8793\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1130 - auc_59: 0.9590 - val_loss: 0.1299 - val_auc_59: 0.8788\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1110 - auc_59: 0.9584 - val_loss: 0.1030 - val_auc_59: 0.8518\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1118 - auc_59: 0.9625 - val_loss: 0.1094 - val_auc_59: 0.8694\n",
      "Epoch 44/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1076 - auc_59: 0.9614 - val_loss: 0.1021 - val_auc_59: 0.8525\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1059 - auc_59: 0.9610 - val_loss: 0.1058 - val_auc_59: 0.8507\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1038 - auc_59: 0.9632 - val_loss: 0.1146 - val_auc_59: 0.8684\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1014 - auc_59: 0.9625 - val_loss: 0.1026 - val_auc_59: 0.8522\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1002 - auc_59: 0.9655 - val_loss: 0.1146 - val_auc_59: 0.8679\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0979 - auc_59: 0.9645 - val_loss: 0.1127 - val_auc_59: 0.8492\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0961 - auc_59: 0.9647 - val_loss: 0.1046 - val_auc_59: 0.8527\n",
      "Epoch 51/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0946 - auc_59: 0.9670 - val_loss: 0.1021 - val_auc_59: 0.8538\n",
      "Epoch 52/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0936 - auc_59: 0.9664 - val_loss: 0.0940 - val_auc_59: 0.8574\n",
      "Epoch 53/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0909 - auc_59: 0.9668 - val_loss: 0.1001 - val_auc_59: 0.8550\n",
      "Epoch 54/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0894 - auc_59: 0.9696 - val_loss: 0.1034 - val_auc_59: 0.8533\n",
      "Epoch 55/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0874 - auc_59: 0.9684 - val_loss: 0.1075 - val_auc_59: 0.8526\n",
      "Epoch 56/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0864 - auc_59: 0.9691 - val_loss: 0.0986 - val_auc_59: 0.8563\n",
      "Epoch 57/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0843 - auc_59: 0.9701 - val_loss: 0.1163 - val_auc_59: 0.8699\n",
      "Epoch 58/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0855 - auc_59: 0.9700 - val_loss: 0.1121 - val_auc_59: 0.8702\n",
      "Epoch 59/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0825 - auc_59: 0.9694 - val_loss: 0.1038 - val_auc_59: 0.8546\n",
      "Epoch 60/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0797 - auc_59: 0.9736 - val_loss: 0.1001 - val_auc_59: 0.8558\n",
      "Epoch 61/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0783 - auc_59: 0.9738 - val_loss: 0.0931 - val_auc_59: 0.8576\n",
      "Epoch 62/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0770 - auc_59: 0.9729 - val_loss: 0.0919 - val_auc_59: 0.8575\n",
      "Epoch 63/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0753 - auc_59: 0.9749 - val_loss: 0.0905 - val_auc_59: 0.8576\n",
      "Epoch 64/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0740 - auc_59: 0.9748 - val_loss: 0.0867 - val_auc_59: 0.8586\n",
      "Epoch 65/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0726 - auc_59: 0.9768 - val_loss: 0.0824 - val_auc_59: 0.8612\n",
      "Epoch 66/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0741 - auc_59: 0.9759 - val_loss: 0.0850 - val_auc_59: 0.8601\n",
      "Epoch 67/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0697 - auc_59: 0.9766 - val_loss: 0.0900 - val_auc_59: 0.8588\n",
      "Epoch 68/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0684 - auc_59: 0.9763 - val_loss: 0.0868 - val_auc_59: 0.8599\n",
      "Epoch 69/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0669 - auc_59: 0.9772 - val_loss: 0.0777 - val_auc_59: 0.8624\n",
      "Epoch 70/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0676 - auc_59: 0.9787 - val_loss: 0.0861 - val_auc_59: 0.8605\n",
      "Epoch 71/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0652 - auc_59: 0.9778 - val_loss: 0.0928 - val_auc_59: 0.8584\n",
      "Epoch 72/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0654 - auc_59: 0.9748 - val_loss: 0.0898 - val_auc_59: 0.8597\n",
      "Epoch 73/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0621 - auc_59: 0.9782 - val_loss: 0.0838 - val_auc_59: 0.8608\n",
      "Epoch 74/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0608 - auc_59: 0.9792 - val_loss: 0.0841 - val_auc_59: 0.8611\n",
      "Epoch 75/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0597 - auc_59: 0.9778 - val_loss: 0.0783 - val_auc_59: 0.8620\n",
      "Epoch 76/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0587 - auc_59: 0.9802 - val_loss: 0.0890 - val_auc_59: 0.8600\n",
      "Epoch 77/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0575 - auc_59: 0.9802 - val_loss: 0.0825 - val_auc_59: 0.8638\n",
      "Epoch 78/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0580 - auc_59: 0.9788 - val_loss: 0.0866 - val_auc_59: 0.8626\n",
      "Epoch 79/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0557 - auc_59: 0.9803 - val_loss: 0.0756 - val_auc_59: 0.8637\n",
      "Epoch 80/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0542 - auc_59: 0.9815 - val_loss: 0.0808 - val_auc_59: 0.8619\n",
      "Epoch 81/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0536 - auc_59: 0.9808 - val_loss: 0.0763 - val_auc_59: 0.8637\n",
      "Epoch 82/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0521 - auc_59: 0.9815 - val_loss: 0.0810 - val_auc_59: 0.8616\n",
      "Epoch 83/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0519 - auc_59: 0.9830 - val_loss: 0.0765 - val_auc_59: 0.8622\n",
      "Epoch 84/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0506 - auc_59: 0.9827 - val_loss: 0.0775 - val_auc_59: 0.8633\n",
      "Epoch 85/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0493 - auc_59: 0.9818 - val_loss: 0.0679 - val_auc_59: 0.8655\n",
      "Epoch 86/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0485 - auc_59: 0.9838 - val_loss: 0.0786 - val_auc_59: 0.8634\n",
      "Epoch 87/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0476 - auc_59: 0.9835 - val_loss: 0.0730 - val_auc_59: 0.8638\n",
      "Epoch 88/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0465 - auc_59: 0.9843 - val_loss: 0.0840 - val_auc_59: 0.8640\n",
      "Epoch 89/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0513 - auc_59: 0.9807 - val_loss: 0.0778 - val_auc_59: 0.8651\n",
      "Epoch 90/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0457 - auc_59: 0.9840 - val_loss: 0.0757 - val_auc_59: 0.8634\n",
      "Epoch 91/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0443 - auc_59: 0.9853 - val_loss: 0.0767 - val_auc_59: 0.8631\n",
      "Epoch 92/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0438 - auc_59: 0.9853 - val_loss: 0.0674 - val_auc_59: 0.8666\n",
      "Epoch 93/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0441 - auc_59: 0.9853 - val_loss: 0.0749 - val_auc_59: 0.8642\n",
      "Epoch 94/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0422 - auc_59: 0.9852 - val_loss: 0.0686 - val_auc_59: 0.8683\n",
      "Epoch 95/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0415 - auc_59: 0.9867 - val_loss: 0.0759 - val_auc_59: 0.8643\n",
      "Epoch 96/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0406 - auc_59: 0.9867 - val_loss: 0.0726 - val_auc_59: 0.8660\n",
      "Epoch 97/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0401 - auc_59: 0.9873 - val_loss: 0.0780 - val_auc_59: 0.8637\n",
      "Epoch 98/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0391 - auc_59: 0.9865 - val_loss: 0.0694 - val_auc_59: 0.8674\n",
      "Epoch 99/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0383 - auc_59: 0.9872 - val_loss: 0.0742 - val_auc_59: 0.8656\n",
      "Epoch 100/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0376 - auc_59: 0.9870 - val_loss: 0.0727 - val_auc_59: 0.8662\n",
      "Epoch 101/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0372 - auc_59: 0.9868 - val_loss: 0.0686 - val_auc_59: 0.8251\n",
      "Epoch 102/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0365 - auc_59: 0.9877 - val_loss: 0.0746 - val_auc_59: 0.8654\n",
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 21ms/step - loss: 0.6347 - auc_60: 0.5450 - val_loss: 0.4606 - val_auc_60: 0.6393\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.4637 - auc_60: 0.7130 - val_loss: 0.3491 - val_auc_60: 0.7302\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3485 - auc_60: 0.8163 - val_loss: 0.2768 - val_auc_60: 0.7896\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2915 - auc_60: 0.8641 - val_loss: 0.2544 - val_auc_60: 0.8085\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2612 - auc_60: 0.8830 - val_loss: 0.2442 - val_auc_60: 0.8178\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2411 - auc_60: 0.8975 - val_loss: 0.2108 - val_auc_60: 0.8346\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2274 - auc_60: 0.9060 - val_loss: 0.2060 - val_auc_60: 0.8398\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2169 - auc_60: 0.9113 - val_loss: 0.2409 - val_auc_60: 0.8310\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2092 - auc_60: 0.9112 - val_loss: 0.2121 - val_auc_60: 0.8428\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2045 - auc_60: 0.9129 - val_loss: 0.1644 - val_auc_60: 0.8579\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1992 - auc_60: 0.9268 - val_loss: 0.1713 - val_auc_60: 0.8609\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1923 - auc_60: 0.9257 - val_loss: 0.1831 - val_auc_60: 0.8578\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1885 - auc_60: 0.9249 - val_loss: 0.1767 - val_auc_60: 0.8609\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1836 - auc_60: 0.9282 - val_loss: 0.1712 - val_auc_60: 0.8650\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1798 - auc_60: 0.9323 - val_loss: 0.1619 - val_auc_60: 0.8682\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1764 - auc_60: 0.9345 - val_loss: 0.1746 - val_auc_60: 0.8657\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1743 - auc_60: 0.9321 - val_loss: 0.1820 - val_auc_60: 0.8626\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1701 - auc_60: 0.9364 - val_loss: 0.1673 - val_auc_60: 0.8722\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1671 - auc_60: 0.9340 - val_loss: 0.1499 - val_auc_60: 0.8753\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1640 - auc_60: 0.9400 - val_loss: 0.1505 - val_auc_60: 0.8775\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1605 - auc_60: 0.9412 - val_loss: 0.1689 - val_auc_60: 0.8690\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1575 - auc_60: 0.9407 - val_loss: 0.1419 - val_auc_60: 0.8779\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.1549 - auc_60: 0.9459 - val_loss: 0.1414 - val_auc_60: 0.8794\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1527 - auc_60: 0.9473 - val_loss: 0.1403 - val_auc_60: 0.8801\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.1492 - auc_60: 0.9457 - val_loss: 0.1498 - val_auc_60: 0.8794\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1461 - auc_60: 0.9495 - val_loss: 0.1403 - val_auc_60: 0.8802\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1463 - auc_60: 0.9493 - val_loss: 0.1319 - val_auc_60: 0.8856\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1408 - auc_60: 0.9502 - val_loss: 0.1389 - val_auc_60: 0.8829\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1382 - auc_60: 0.9525 - val_loss: 0.1428 - val_auc_60: 0.8828\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1361 - auc_60: 0.9510 - val_loss: 0.1519 - val_auc_60: 0.8816\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1342 - auc_60: 0.9503 - val_loss: 0.1339 - val_auc_60: 0.8880\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1305 - auc_60: 0.9529 - val_loss: 0.1233 - val_auc_60: 0.8937\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1284 - auc_60: 0.9537 - val_loss: 0.1311 - val_auc_60: 0.8902\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1259 - auc_60: 0.9556 - val_loss: 0.1374 - val_auc_60: 0.8890\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1235 - auc_60: 0.9554 - val_loss: 0.1184 - val_auc_60: 0.8814\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1240 - auc_60: 0.9532 - val_loss: 0.1402 - val_auc_60: 0.8894\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1193 - auc_60: 0.9565 - val_loss: 0.1242 - val_auc_60: 0.8806\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1175 - auc_60: 0.9579 - val_loss: 0.1171 - val_auc_60: 0.8833\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1153 - auc_60: 0.9569 - val_loss: 0.1168 - val_auc_60: 0.8816\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1124 - auc_60: 0.9590 - val_loss: 0.1230 - val_auc_60: 0.8815\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1103 - auc_60: 0.9608 - val_loss: 0.1316 - val_auc_60: 0.8792\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1082 - auc_60: 0.9596 - val_loss: 0.1198 - val_auc_60: 0.8851\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1065 - auc_60: 0.9597 - val_loss: 0.1026 - val_auc_60: 0.8716\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1038 - auc_60: 0.9649 - val_loss: 0.1339 - val_auc_60: 0.8818\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1044 - auc_60: 0.9589 - val_loss: 0.1172 - val_auc_60: 0.8866\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1010 - auc_60: 0.9612 - val_loss: 0.1096 - val_auc_60: 0.8893\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0985 - auc_60: 0.9644 - val_loss: 0.1090 - val_auc_60: 0.8898\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0972 - auc_60: 0.9642 - val_loss: 0.1105 - val_auc_60: 0.8882\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0956 - auc_60: 0.9651 - val_loss: 0.1027 - val_auc_60: 0.8723\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0935 - auc_60: 0.9669 - val_loss: 0.1171 - val_auc_60: 0.8884\n",
      "Epoch 51/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.0922 - auc_60: 0.9660 - val_loss: 0.1172 - val_auc_60: 0.8891\n",
      "Epoch 52/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0900 - auc_60: 0.9685 - val_loss: 0.1137 - val_auc_60: 0.8896\n",
      "Epoch 53/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0886 - auc_60: 0.9670 - val_loss: 0.0920 - val_auc_60: 0.8588\n",
      "Epoch 54/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0867 - auc_60: 0.9704 - val_loss: 0.0963 - val_auc_60: 0.8575\n",
      "Epoch 55/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0850 - auc_60: 0.9694 - val_loss: 0.1066 - val_auc_60: 0.8748\n",
      "Epoch 56/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0837 - auc_60: 0.9716 - val_loss: 0.1000 - val_auc_60: 0.8564\n",
      "Epoch 57/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0825 - auc_60: 0.9724 - val_loss: 0.0976 - val_auc_60: 0.8581\n",
      "Epoch 58/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.0802 - auc_60: 0.9726 - val_loss: 0.1080 - val_auc_60: 0.8737\n",
      "Epoch 59/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0794 - auc_60: 0.9713 - val_loss: 0.0932 - val_auc_60: 0.8569\n",
      "Epoch 60/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0776 - auc_60: 0.9728 - val_loss: 0.0878 - val_auc_60: 0.8586\n",
      "Epoch 61/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0757 - auc_60: 0.9733 - val_loss: 0.0856 - val_auc_60: 0.8592\n",
      "Epoch 62/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0749 - auc_60: 0.9742 - val_loss: 0.0964 - val_auc_60: 0.8570\n",
      "Epoch 63/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0743 - auc_60: 0.9733 - val_loss: 0.0964 - val_auc_60: 0.8577\n",
      "Epoch 64/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0723 - auc_60: 0.9743 - val_loss: 0.0868 - val_auc_60: 0.8594\n",
      "Epoch 65/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0702 - auc_60: 0.9753 - val_loss: 0.0937 - val_auc_60: 0.8578\n",
      "Epoch 66/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0689 - auc_60: 0.9753 - val_loss: 0.0940 - val_auc_60: 0.8578\n",
      "Epoch 67/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0676 - auc_60: 0.9763 - val_loss: 0.0997 - val_auc_60: 0.8573\n",
      "Epoch 68/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0702 - auc_60: 0.9727 - val_loss: 0.0752 - val_auc_60: 0.8414\n",
      "Epoch 69/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0673 - auc_60: 0.9781 - val_loss: 0.0866 - val_auc_60: 0.8601\n",
      "Epoch 70/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0640 - auc_60: 0.9767 - val_loss: 0.0871 - val_auc_60: 0.8403\n",
      "Epoch 71/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0632 - auc_60: 0.9757 - val_loss: 0.0799 - val_auc_60: 0.8427\n",
      "Epoch 72/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0620 - auc_60: 0.9782 - val_loss: 0.0952 - val_auc_60: 0.8587\n",
      "Epoch 73/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0622 - auc_60: 0.9765 - val_loss: 0.0916 - val_auc_60: 0.8594\n",
      "Epoch 74/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0604 - auc_60: 0.9777 - val_loss: 0.0886 - val_auc_60: 0.8399\n",
      "Epoch 75/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0580 - auc_60: 0.9780 - val_loss: 0.0863 - val_auc_60: 0.8412\n",
      "Epoch 76/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0572 - auc_60: 0.9788 - val_loss: 0.0814 - val_auc_60: 0.8429\n",
      "Epoch 77/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0559 - auc_60: 0.9788 - val_loss: 0.0831 - val_auc_60: 0.8420\n",
      "Epoch 78/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0550 - auc_60: 0.9802 - val_loss: 0.0833 - val_auc_60: 0.8423\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.5912 - auc_61: 0.5813 - val_loss: 0.4421 - val_auc_61: 0.6898\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.4255 - auc_61: 0.7513 - val_loss: 0.3211 - val_auc_61: 0.8035\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3422 - auc_61: 0.8206 - val_loss: 0.2844 - val_auc_61: 0.8361\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2944 - auc_61: 0.8618 - val_loss: 0.2285 - val_auc_61: 0.8533\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2661 - auc_61: 0.8830 - val_loss: 0.2421 - val_auc_61: 0.8549\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2475 - auc_61: 0.8965 - val_loss: 0.2221 - val_auc_61: 0.8617\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2349 - auc_61: 0.9074 - val_loss: 0.2371 - val_auc_61: 0.8564\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2250 - auc_61: 0.9057 - val_loss: 0.2096 - val_auc_61: 0.8664\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2158 - auc_61: 0.9147 - val_loss: 0.1959 - val_auc_61: 0.8746\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2077 - auc_61: 0.9199 - val_loss: 0.1753 - val_auc_61: 0.8810\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2028 - auc_61: 0.9264 - val_loss: 0.2144 - val_auc_61: 0.8667\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1971 - auc_61: 0.9233 - val_loss: 0.1982 - val_auc_61: 0.8743\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1910 - auc_61: 0.9289 - val_loss: 0.2126 - val_auc_61: 0.8698\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1865 - auc_61: 0.9298 - val_loss: 0.1915 - val_auc_61: 0.8658\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1804 - auc_61: 0.9340 - val_loss: 0.2210 - val_auc_61: 0.8571\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1779 - auc_61: 0.9289 - val_loss: 0.1898 - val_auc_61: 0.8698\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1728 - auc_61: 0.9407 - val_loss: 0.1888 - val_auc_61: 0.8687\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1669 - auc_61: 0.9384 - val_loss: 0.1886 - val_auc_61: 0.8707\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1618 - auc_61: 0.9397 - val_loss: 0.1659 - val_auc_61: 0.8783\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1580 - auc_61: 0.9433 - val_loss: 0.1553 - val_auc_61: 0.8795\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1534 - auc_61: 0.9466 - val_loss: 0.1526 - val_auc_61: 0.8663\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1502 - auc_61: 0.9483 - val_loss: 0.1594 - val_auc_61: 0.8793\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1457 - auc_61: 0.9507 - val_loss: 0.1609 - val_auc_61: 0.8789\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1416 - auc_61: 0.9508 - val_loss: 0.1755 - val_auc_61: 0.8732\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1401 - auc_61: 0.9496 - val_loss: 0.1687 - val_auc_61: 0.8766\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1350 - auc_61: 0.9533 - val_loss: 0.1626 - val_auc_61: 0.8807\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1318 - auc_61: 0.9565 - val_loss: 0.1574 - val_auc_61: 0.8828\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1282 - auc_61: 0.9570 - val_loss: 0.1572 - val_auc_61: 0.8827\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1246 - auc_61: 0.9579 - val_loss: 0.1461 - val_auc_61: 0.8865\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1221 - auc_61: 0.9594 - val_loss: 0.1390 - val_auc_61: 0.8733\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1192 - auc_61: 0.9595 - val_loss: 0.1478 - val_auc_61: 0.8880\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1173 - auc_61: 0.9632 - val_loss: 0.1526 - val_auc_61: 0.8866\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1144 - auc_61: 0.9605 - val_loss: 0.1491 - val_auc_61: 0.8888\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1104 - auc_61: 0.9627 - val_loss: 0.1420 - val_auc_61: 0.8886\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1075 - auc_61: 0.9642 - val_loss: 0.1396 - val_auc_61: 0.8898\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1056 - auc_61: 0.9649 - val_loss: 0.1337 - val_auc_61: 0.8916\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1028 - auc_61: 0.9661 - val_loss: 0.1306 - val_auc_61: 0.8757\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1003 - auc_61: 0.9663 - val_loss: 0.1424 - val_auc_61: 0.8896\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0989 - auc_61: 0.9675 - val_loss: 0.1287 - val_auc_61: 0.8759\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0974 - auc_61: 0.9698 - val_loss: 0.1307 - val_auc_61: 0.8928\n",
      "Epoch 41/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0937 - auc_61: 0.9685 - val_loss: 0.1147 - val_auc_61: 0.8792\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0918 - auc_61: 0.9704 - val_loss: 0.1294 - val_auc_61: 0.8928\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0901 - auc_61: 0.9700 - val_loss: 0.1221 - val_auc_61: 0.8759\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0884 - auc_61: 0.9701 - val_loss: 0.1254 - val_auc_61: 0.8935\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0866 - auc_61: 0.9724 - val_loss: 0.1343 - val_auc_61: 0.8753\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0866 - auc_61: 0.9718 - val_loss: 0.1252 - val_auc_61: 0.8755\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0827 - auc_61: 0.9722 - val_loss: 0.1120 - val_auc_61: 0.8799\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0841 - auc_61: 0.9719 - val_loss: 0.1159 - val_auc_61: 0.8924\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0804 - auc_61: 0.9737 - val_loss: 0.1335 - val_auc_61: 0.8891\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0787 - auc_61: 0.9724 - val_loss: 0.1076 - val_auc_61: 0.8796\n",
      "Epoch 51/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0766 - auc_61: 0.9753 - val_loss: 0.1121 - val_auc_61: 0.8790\n",
      "Epoch 52/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0754 - auc_61: 0.9748 - val_loss: 0.1091 - val_auc_61: 0.8794\n",
      "Epoch 53/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0737 - auc_61: 0.9760 - val_loss: 0.1153 - val_auc_61: 0.8779\n",
      "Epoch 54/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0727 - auc_61: 0.9751 - val_loss: 0.1048 - val_auc_61: 0.8817\n",
      "Epoch 55/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0710 - auc_61: 0.9766 - val_loss: 0.1129 - val_auc_61: 0.8783\n",
      "Epoch 56/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0707 - auc_61: 0.9766 - val_loss: 0.1179 - val_auc_61: 0.8774\n",
      "Epoch 57/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0690 - auc_61: 0.9771 - val_loss: 0.1000 - val_auc_61: 0.8817\n",
      "Epoch 58/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0680 - auc_61: 0.9778 - val_loss: 0.1110 - val_auc_61: 0.8810\n",
      "Epoch 59/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0663 - auc_61: 0.9766 - val_loss: 0.1097 - val_auc_61: 0.8818\n",
      "Epoch 60/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0650 - auc_61: 0.9781 - val_loss: 0.1113 - val_auc_61: 0.8815\n",
      "Epoch 61/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0638 - auc_61: 0.9786 - val_loss: 0.1012 - val_auc_61: 0.8828\n",
      "Epoch 62/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0627 - auc_61: 0.9788 - val_loss: 0.1103 - val_auc_61: 0.8810\n",
      "Epoch 63/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0621 - auc_61: 0.9786 - val_loss: 0.1033 - val_auc_61: 0.8831\n",
      "Epoch 64/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0605 - auc_61: 0.9800 - val_loss: 0.1125 - val_auc_61: 0.8810\n",
      "Epoch 65/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0601 - auc_61: 0.9792 - val_loss: 0.1016 - val_auc_61: 0.8843\n",
      "Epoch 66/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0584 - auc_61: 0.9798 - val_loss: 0.0947 - val_auc_61: 0.8673\n",
      "Epoch 67/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0576 - auc_61: 0.9801 - val_loss: 0.1017 - val_auc_61: 0.8850\n",
      "Epoch 68/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0561 - auc_61: 0.9812 - val_loss: 0.1013 - val_auc_61: 0.8846\n",
      "Epoch 69/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0551 - auc_61: 0.9820 - val_loss: 0.1029 - val_auc_61: 0.8857\n",
      "Epoch 70/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0540 - auc_61: 0.9821 - val_loss: 0.0970 - val_auc_61: 0.8864\n",
      "Epoch 71/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0532 - auc_61: 0.9813 - val_loss: 0.1004 - val_auc_61: 0.8872\n",
      "Epoch 72/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0547 - auc_61: 0.9833 - val_loss: 0.0914 - val_auc_61: 0.8483\n",
      "Epoch 73/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0516 - auc_61: 0.9825 - val_loss: 0.1053 - val_auc_61: 0.8656\n",
      "Epoch 74/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0507 - auc_61: 0.9832 - val_loss: 0.1040 - val_auc_61: 0.8661\n",
      "Epoch 75/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0502 - auc_61: 0.9825 - val_loss: 0.1018 - val_auc_61: 0.8663\n",
      "Epoch 76/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0499 - auc_61: 0.9833 - val_loss: 0.0917 - val_auc_61: 0.8475\n",
      "Epoch 77/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0487 - auc_61: 0.9820 - val_loss: 0.0984 - val_auc_61: 0.8468\n",
      "Epoch 78/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0473 - auc_61: 0.9838 - val_loss: 0.0950 - val_auc_61: 0.8487\n",
      "Epoch 79/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0464 - auc_61: 0.9835 - val_loss: 0.0948 - val_auc_61: 0.8484\n",
      "Epoch 80/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0459 - auc_61: 0.9833 - val_loss: 0.0834 - val_auc_61: 0.8320\n",
      "Epoch 81/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0447 - auc_61: 0.9837 - val_loss: 0.0845 - val_auc_61: 0.8317\n",
      "Epoch 82/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0440 - auc_61: 0.9847 - val_loss: 0.0876 - val_auc_61: 0.8303\n",
      "Epoch 83/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0428 - auc_61: 0.9845 - val_loss: 0.0924 - val_auc_61: 0.8503\n",
      "Epoch 84/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0423 - auc_61: 0.9847 - val_loss: 0.0996 - val_auc_61: 0.8491\n",
      "Epoch 85/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0415 - auc_61: 0.9843 - val_loss: 0.0909 - val_auc_61: 0.8297\n",
      "Epoch 86/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0408 - auc_61: 0.9853 - val_loss: 0.0989 - val_auc_61: 0.8486\n",
      "Epoch 87/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0401 - auc_61: 0.9852 - val_loss: 0.0948 - val_auc_61: 0.8294\n",
      "Epoch 88/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0394 - auc_61: 0.9857 - val_loss: 0.0904 - val_auc_61: 0.8322\n",
      "Epoch 89/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0386 - auc_61: 0.9863 - val_loss: 0.0923 - val_auc_61: 0.8314\n",
      "Epoch 90/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0387 - auc_61: 0.9867 - val_loss: 0.0918 - val_auc_61: 0.8307\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 2s 20ms/step - loss: 0.5876 - auc_62: 0.5768 - val_loss: 0.4554 - val_auc_62: 0.6620\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.4420 - auc_62: 0.7222 - val_loss: 0.3584 - val_auc_62: 0.7801\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3560 - auc_62: 0.8083 - val_loss: 0.3358 - val_auc_62: 0.7948\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3100 - auc_62: 0.8437 - val_loss: 0.2705 - val_auc_62: 0.8371\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2823 - auc_62: 0.8715 - val_loss: 0.2776 - val_auc_62: 0.8371\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2635 - auc_62: 0.8799 - val_loss: 0.2499 - val_auc_62: 0.8500\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2487 - auc_62: 0.8932 - val_loss: 0.2261 - val_auc_62: 0.8616\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2378 - auc_62: 0.9016 - val_loss: 0.2395 - val_auc_62: 0.8576\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2325 - auc_62: 0.9041 - val_loss: 0.2481 - val_auc_62: 0.8571\n",
      "Epoch 10/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2242 - auc_62: 0.9104 - val_loss: 0.2056 - val_auc_62: 0.8747\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2177 - auc_62: 0.9106 - val_loss: 0.2161 - val_auc_62: 0.8732\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2123 - auc_62: 0.9149 - val_loss: 0.2271 - val_auc_62: 0.8710\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2078 - auc_62: 0.9193 - val_loss: 0.1919 - val_auc_62: 0.8780\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2025 - auc_62: 0.9250 - val_loss: 0.2357 - val_auc_62: 0.8671\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2012 - auc_62: 0.9227 - val_loss: 0.2685 - val_auc_62: 0.8575\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2002 - auc_62: 0.9182 - val_loss: 0.2040 - val_auc_62: 0.8755\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1911 - auc_62: 0.9312 - val_loss: 0.2043 - val_auc_62: 0.8762\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1874 - auc_62: 0.9279 - val_loss: 0.1979 - val_auc_62: 0.8543\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1842 - auc_62: 0.9303 - val_loss: 0.1994 - val_auc_62: 0.8683\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1810 - auc_62: 0.9351 - val_loss: 0.2383 - val_auc_62: 0.8678\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1783 - auc_62: 0.9309 - val_loss: 0.1924 - val_auc_62: 0.8550\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1739 - auc_62: 0.9384 - val_loss: 0.1844 - val_auc_62: 0.8580\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1709 - auc_62: 0.9392 - val_loss: 0.1928 - val_auc_62: 0.8567\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1679 - auc_62: 0.9406 - val_loss: 0.2024 - val_auc_62: 0.8536\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1641 - auc_62: 0.9409 - val_loss: 0.2044 - val_auc_62: 0.8527\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1615 - auc_62: 0.9441 - val_loss: 0.1921 - val_auc_62: 0.8573\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1586 - auc_62: 0.9435 - val_loss: 0.1904 - val_auc_62: 0.8544\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1560 - auc_62: 0.9451 - val_loss: 0.1937 - val_auc_62: 0.8581\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1531 - auc_62: 0.9468 - val_loss: 0.1639 - val_auc_62: 0.8639\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1512 - auc_62: 0.9496 - val_loss: 0.1568 - val_auc_62: 0.8666\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1482 - auc_62: 0.9506 - val_loss: 0.1773 - val_auc_62: 0.8607\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1463 - auc_62: 0.9531 - val_loss: 0.1683 - val_auc_62: 0.8644\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1441 - auc_62: 0.9503 - val_loss: 0.1660 - val_auc_62: 0.8647\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1403 - auc_62: 0.9531 - val_loss: 0.1603 - val_auc_62: 0.8657\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1380 - auc_62: 0.9546 - val_loss: 0.1485 - val_auc_62: 0.8708\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1361 - auc_62: 0.9540 - val_loss: 0.1487 - val_auc_62: 0.8702\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1374 - auc_62: 0.9582 - val_loss: 0.1599 - val_auc_62: 0.8662\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1311 - auc_62: 0.9558 - val_loss: 0.1518 - val_auc_62: 0.8693\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1325 - auc_62: 0.9597 - val_loss: 0.1601 - val_auc_62: 0.8667\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1274 - auc_62: 0.9570 - val_loss: 0.1636 - val_auc_62: 0.8669\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1250 - auc_62: 0.9585 - val_loss: 0.1436 - val_auc_62: 0.8718\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1234 - auc_62: 0.9595 - val_loss: 0.1580 - val_auc_62: 0.8672\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1209 - auc_62: 0.9608 - val_loss: 0.1543 - val_auc_62: 0.8694\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1196 - auc_62: 0.9619 - val_loss: 0.1538 - val_auc_62: 0.8705\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1172 - auc_62: 0.9612 - val_loss: 0.1481 - val_auc_62: 0.8726\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1167 - auc_62: 0.9636 - val_loss: 0.1456 - val_auc_62: 0.8715\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1148 - auc_62: 0.9627 - val_loss: 0.1260 - val_auc_62: 0.8787\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1130 - auc_62: 0.9672 - val_loss: 0.1575 - val_auc_62: 0.8704\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1103 - auc_62: 0.9626 - val_loss: 0.1519 - val_auc_62: 0.8730\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1085 - auc_62: 0.9646 - val_loss: 0.1505 - val_auc_62: 0.8731\n",
      "Epoch 51/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1069 - auc_62: 0.9639 - val_loss: 0.1429 - val_auc_62: 0.8754\n",
      "Epoch 52/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1051 - auc_62: 0.9643 - val_loss: 0.1272 - val_auc_62: 0.8812\n",
      "Epoch 53/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1090 - auc_62: 0.9686 - val_loss: 0.1290 - val_auc_62: 0.8758\n",
      "Epoch 54/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1032 - auc_62: 0.9683 - val_loss: 0.1326 - val_auc_62: 0.8783\n",
      "Epoch 55/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1012 - auc_62: 0.9672 - val_loss: 0.1326 - val_auc_62: 0.8786\n",
      "Epoch 56/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0993 - auc_62: 0.9680 - val_loss: 0.1403 - val_auc_62: 0.8763\n",
      "Epoch 57/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0983 - auc_62: 0.9682 - val_loss: 0.1445 - val_auc_62: 0.8764\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.6085 - auc_63: 0.6630 - val_loss: 0.3981 - val_auc_63: 0.7043\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.4536 - auc_63: 0.7537 - val_loss: 0.3356 - val_auc_63: 0.7951\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3618 - auc_63: 0.8130 - val_loss: 0.2815 - val_auc_63: 0.8300\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3169 - auc_63: 0.8557 - val_loss: 0.2747 - val_auc_63: 0.8360\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2878 - auc_63: 0.8660 - val_loss: 0.2454 - val_auc_63: 0.8521\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2664 - auc_63: 0.8832 - val_loss: 0.2548 - val_auc_63: 0.8491\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2516 - auc_63: 0.8984 - val_loss: 0.2348 - val_auc_63: 0.8579\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2388 - auc_63: 0.9000 - val_loss: 0.2035 - val_auc_63: 0.8721\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2306 - auc_63: 0.9088 - val_loss: 0.1901 - val_auc_63: 0.8794\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2212 - auc_63: 0.9142 - val_loss: 0.2180 - val_auc_63: 0.8662\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2137 - auc_63: 0.9140 - val_loss: 0.2161 - val_auc_63: 0.8694\n",
      "Epoch 12/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2090 - auc_63: 0.9143 - val_loss: 0.2073 - val_auc_63: 0.8710\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2006 - auc_63: 0.9247 - val_loss: 0.2111 - val_auc_63: 0.8720\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1941 - auc_63: 0.9269 - val_loss: 0.2505 - val_auc_63: 0.8563\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1958 - auc_63: 0.9186 - val_loss: 0.1963 - val_auc_63: 0.8558\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1869 - auc_63: 0.9330 - val_loss: 0.1790 - val_auc_63: 0.8588\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1805 - auc_63: 0.9332 - val_loss: 0.1951 - val_auc_63: 0.8550\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1765 - auc_63: 0.9338 - val_loss: 0.1775 - val_auc_63: 0.8611\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1720 - auc_63: 0.9372 - val_loss: 0.1813 - val_auc_63: 0.8607\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1680 - auc_63: 0.9381 - val_loss: 0.1759 - val_auc_63: 0.8622\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1635 - auc_63: 0.9409 - val_loss: 0.1662 - val_auc_63: 0.8624\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1593 - auc_63: 0.9409 - val_loss: 0.1709 - val_auc_63: 0.8608\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1551 - auc_63: 0.9454 - val_loss: 0.1815 - val_auc_63: 0.8603\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1530 - auc_63: 0.9452 - val_loss: 0.1851 - val_auc_63: 0.8573\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1485 - auc_63: 0.9463 - val_loss: 0.1695 - val_auc_63: 0.8618\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1439 - auc_63: 0.9505 - val_loss: 0.1727 - val_auc_63: 0.8618\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1407 - auc_63: 0.9495 - val_loss: 0.1565 - val_auc_63: 0.8650\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1377 - auc_63: 0.9514 - val_loss: 0.1509 - val_auc_63: 0.8662\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1390 - auc_63: 0.9549 - val_loss: 0.1449 - val_auc_63: 0.8677\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1317 - auc_63: 0.9556 - val_loss: 0.1404 - val_auc_63: 0.8680\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1285 - auc_63: 0.9556 - val_loss: 0.1345 - val_auc_63: 0.8701\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1253 - auc_63: 0.9565 - val_loss: 0.1487 - val_auc_63: 0.8668\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1222 - auc_63: 0.9584 - val_loss: 0.1497 - val_auc_63: 0.8673\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1196 - auc_63: 0.9599 - val_loss: 0.1527 - val_auc_63: 0.8662\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1169 - auc_63: 0.9604 - val_loss: 0.1417 - val_auc_63: 0.8702\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1140 - auc_63: 0.9613 - val_loss: 0.1259 - val_auc_63: 0.8753\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1173 - auc_63: 0.9636 - val_loss: 0.1474 - val_auc_63: 0.8667\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1108 - auc_63: 0.9623 - val_loss: 0.1300 - val_auc_63: 0.8713\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1080 - auc_63: 0.9638 - val_loss: 0.1292 - val_auc_63: 0.8720\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1055 - auc_63: 0.9657 - val_loss: 0.1314 - val_auc_63: 0.8712\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1034 - auc_63: 0.9663 - val_loss: 0.1315 - val_auc_63: 0.8717\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1014 - auc_63: 0.9670 - val_loss: 0.1330 - val_auc_63: 0.8713\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0994 - auc_63: 0.9676 - val_loss: 0.1382 - val_auc_63: 0.8696\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0985 - auc_63: 0.9666 - val_loss: 0.1307 - val_auc_63: 0.8734\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0957 - auc_63: 0.9685 - val_loss: 0.1242 - val_auc_63: 0.8760\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0942 - auc_63: 0.9690 - val_loss: 0.1389 - val_auc_63: 0.8710\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0937 - auc_63: 0.9676 - val_loss: 0.1293 - val_auc_63: 0.8748\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0913 - auc_63: 0.9686 - val_loss: 0.1091 - val_auc_63: 0.8609\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0995 - auc_63: 0.9718 - val_loss: 0.1191 - val_auc_63: 0.8760\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0895 - auc_63: 0.9697 - val_loss: 0.1171 - val_auc_63: 0.8761\n",
      "Epoch 51/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0867 - auc_63: 0.9726 - val_loss: 0.1189 - val_auc_63: 0.8747\n",
      "Epoch 52/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0846 - auc_63: 0.9728 - val_loss: 0.1207 - val_auc_63: 0.8742\n",
      "Epoch 53/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0833 - auc_63: 0.9719 - val_loss: 0.1124 - val_auc_63: 0.8770\n",
      "Epoch 54/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0818 - auc_63: 0.9726 - val_loss: 0.1062 - val_auc_63: 0.8598\n",
      "Epoch 55/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0804 - auc_63: 0.9741 - val_loss: 0.1153 - val_auc_63: 0.8772\n",
      "Epoch 56/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0789 - auc_63: 0.9741 - val_loss: 0.1032 - val_auc_63: 0.8618\n",
      "Epoch 57/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0816 - auc_63: 0.9746 - val_loss: 0.1028 - val_auc_63: 0.8801\n",
      "Epoch 58/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0769 - auc_63: 0.9741 - val_loss: 0.0962 - val_auc_63: 0.8625\n",
      "Epoch 59/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0838 - auc_63: 0.9745 - val_loss: 0.0997 - val_auc_63: 0.8616\n",
      "Epoch 60/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0758 - auc_63: 0.9751 - val_loss: 0.1037 - val_auc_63: 0.8607\n",
      "Epoch 61/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0733 - auc_63: 0.9751 - val_loss: 0.1068 - val_auc_63: 0.8592\n",
      "Epoch 62/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0724 - auc_63: 0.9746 - val_loss: 0.1012 - val_auc_63: 0.8598\n",
      "Epoch 63/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0710 - auc_63: 0.9765 - val_loss: 0.1052 - val_auc_63: 0.8574\n",
      "Epoch 64/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0699 - auc_63: 0.9753 - val_loss: 0.0992 - val_auc_63: 0.8612\n",
      "Epoch 65/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0689 - auc_63: 0.9770 - val_loss: 0.1059 - val_auc_63: 0.8590\n",
      "Epoch 66/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0679 - auc_63: 0.9771 - val_loss: 0.1158 - val_auc_63: 0.8543\n",
      "Epoch 67/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0671 - auc_63: 0.9765 - val_loss: 0.1097 - val_auc_63: 0.8583\n",
      "Epoch 68/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0655 - auc_63: 0.9780 - val_loss: 0.1129 - val_auc_63: 0.8568\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.6289 - auc_64: 0.5298 - val_loss: 0.4777 - val_auc_64: 0.6335\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.4763 - auc_64: 0.7036 - val_loss: 0.4030 - val_auc_64: 0.7517\n",
      "Epoch 3/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3893 - auc_64: 0.7806 - val_loss: 0.3378 - val_auc_64: 0.7972\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3386 - auc_64: 0.8205 - val_loss: 0.2959 - val_auc_64: 0.8305\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3080 - auc_64: 0.8477 - val_loss: 0.2950 - val_auc_64: 0.8271\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2851 - auc_64: 0.8664 - val_loss: 0.2728 - val_auc_64: 0.8425\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2680 - auc_64: 0.8815 - val_loss: 0.2409 - val_auc_64: 0.8519\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2546 - auc_64: 0.8925 - val_loss: 0.2402 - val_auc_64: 0.8592\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2440 - auc_64: 0.8996 - val_loss: 0.2263 - val_auc_64: 0.8671\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2351 - auc_64: 0.9040 - val_loss: 0.2289 - val_auc_64: 0.8675\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2274 - auc_64: 0.9070 - val_loss: 0.2298 - val_auc_64: 0.8662\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2201 - auc_64: 0.9142 - val_loss: 0.2195 - val_auc_64: 0.8731\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2137 - auc_64: 0.9150 - val_loss: 0.1799 - val_auc_64: 0.8888\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2087 - auc_64: 0.9201 - val_loss: 0.1864 - val_auc_64: 0.8868\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2032 - auc_64: 0.9234 - val_loss: 0.1887 - val_auc_64: 0.8871\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1998 - auc_64: 0.9289 - val_loss: 0.2041 - val_auc_64: 0.8823\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1933 - auc_64: 0.9263 - val_loss: 0.1727 - val_auc_64: 0.8918\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1894 - auc_64: 0.9296 - val_loss: 0.1988 - val_auc_64: 0.8831\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1858 - auc_64: 0.9305 - val_loss: 0.2036 - val_auc_64: 0.8852\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1802 - auc_64: 0.9321 - val_loss: 0.1961 - val_auc_64: 0.8876\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1768 - auc_64: 0.9323 - val_loss: 0.2057 - val_auc_64: 0.8871\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1707 - auc_64: 0.9364 - val_loss: 0.1986 - val_auc_64: 0.8864\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1661 - auc_64: 0.9389 - val_loss: 0.1669 - val_auc_64: 0.8895\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1612 - auc_64: 0.9435 - val_loss: 0.1460 - val_auc_64: 0.8979\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1568 - auc_64: 0.9470 - val_loss: 0.1613 - val_auc_64: 0.8913\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1557 - auc_64: 0.9508 - val_loss: 0.1731 - val_auc_64: 0.8918\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1500 - auc_64: 0.9468 - val_loss: 0.1621 - val_auc_64: 0.8928\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1456 - auc_64: 0.9498 - val_loss: 0.1472 - val_auc_64: 0.8838\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1441 - auc_64: 0.9527 - val_loss: 0.1464 - val_auc_64: 0.8856\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1408 - auc_64: 0.9538 - val_loss: 0.1440 - val_auc_64: 0.8867\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1367 - auc_64: 0.9520 - val_loss: 0.1514 - val_auc_64: 0.8841\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1331 - auc_64: 0.9554 - val_loss: 0.1603 - val_auc_64: 0.8820\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1311 - auc_64: 0.9542 - val_loss: 0.1469 - val_auc_64: 0.8861\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1302 - auc_64: 0.9582 - val_loss: 0.1347 - val_auc_64: 0.8742\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1308 - auc_64: 0.9629 - val_loss: 0.1423 - val_auc_64: 0.8883\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1252 - auc_64: 0.9622 - val_loss: 0.1427 - val_auc_64: 0.8886\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1213 - auc_64: 0.9597 - val_loss: 0.1399 - val_auc_64: 0.8726\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1186 - auc_64: 0.9626 - val_loss: 0.1595 - val_auc_64: 0.8844\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1179 - auc_64: 0.9607 - val_loss: 0.1368 - val_auc_64: 0.8755\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1153 - auc_64: 0.9625 - val_loss: 0.1329 - val_auc_64: 0.8766\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1170 - auc_64: 0.9642 - val_loss: 0.1392 - val_auc_64: 0.8727\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1115 - auc_64: 0.9646 - val_loss: 0.1307 - val_auc_64: 0.8766\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1123 - auc_64: 0.9678 - val_loss: 0.1386 - val_auc_64: 0.8751\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1103 - auc_64: 0.9657 - val_loss: 0.1413 - val_auc_64: 0.8743\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1067 - auc_64: 0.9669 - val_loss: 0.1393 - val_auc_64: 0.8761\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1049 - auc_64: 0.9663 - val_loss: 0.1467 - val_auc_64: 0.8741\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1030 - auc_64: 0.9670 - val_loss: 0.1306 - val_auc_64: 0.8798\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1015 - auc_64: 0.9673 - val_loss: 0.1320 - val_auc_64: 0.8800\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1000 - auc_64: 0.9680 - val_loss: 0.1327 - val_auc_64: 0.8805\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0984 - auc_64: 0.9690 - val_loss: 0.1344 - val_auc_64: 0.8797\n",
      "Epoch 51/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0968 - auc_64: 0.9687 - val_loss: 0.1266 - val_auc_64: 0.8824\n",
      "Epoch 52/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0954 - auc_64: 0.9701 - val_loss: 0.1220 - val_auc_64: 0.8844\n",
      "Epoch 53/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0941 - auc_64: 0.9699 - val_loss: 0.1218 - val_auc_64: 0.8838\n",
      "Epoch 54/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0923 - auc_64: 0.9714 - val_loss: 0.1278 - val_auc_64: 0.8825\n",
      "Epoch 55/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0911 - auc_64: 0.9716 - val_loss: 0.1282 - val_auc_64: 0.8834\n",
      "Epoch 56/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0900 - auc_64: 0.9709 - val_loss: 0.1254 - val_auc_64: 0.8845\n",
      "Epoch 57/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0904 - auc_64: 0.9706 - val_loss: 0.1169 - val_auc_64: 0.8848\n",
      "Epoch 58/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0872 - auc_64: 0.9718 - val_loss: 0.1144 - val_auc_64: 0.8848\n",
      "Epoch 59/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0858 - auc_64: 0.9731 - val_loss: 0.1192 - val_auc_64: 0.8849\n",
      "Epoch 60/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0842 - auc_64: 0.9733 - val_loss: 0.1275 - val_auc_64: 0.8845\n",
      "Epoch 61/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0830 - auc_64: 0.9731 - val_loss: 0.1198 - val_auc_64: 0.8855\n",
      "Epoch 62/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0819 - auc_64: 0.9725 - val_loss: 0.1201 - val_auc_64: 0.8851\n",
      "Epoch 63/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0807 - auc_64: 0.9735 - val_loss: 0.1200 - val_auc_64: 0.8850\n",
      "Epoch 64/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0796 - auc_64: 0.9735 - val_loss: 0.1135 - val_auc_64: 0.8868\n",
      "Epoch 65/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0783 - auc_64: 0.9748 - val_loss: 0.1117 - val_auc_64: 0.8868\n",
      "Epoch 66/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0770 - auc_64: 0.9745 - val_loss: 0.1101 - val_auc_64: 0.8878\n",
      "Epoch 67/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0760 - auc_64: 0.9751 - val_loss: 0.1100 - val_auc_64: 0.8880\n",
      "Epoch 68/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0752 - auc_64: 0.9746 - val_loss: 0.1089 - val_auc_64: 0.8897\n",
      "Epoch 69/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0739 - auc_64: 0.9750 - val_loss: 0.1172 - val_auc_64: 0.8874\n",
      "Epoch 70/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0727 - auc_64: 0.9751 - val_loss: 0.1110 - val_auc_64: 0.8890\n",
      "Epoch 71/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0715 - auc_64: 0.9763 - val_loss: 0.1181 - val_auc_64: 0.8866\n",
      "Epoch 72/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0708 - auc_64: 0.9756 - val_loss: 0.1126 - val_auc_64: 0.8878\n",
      "Epoch 73/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0698 - auc_64: 0.9765 - val_loss: 0.1118 - val_auc_64: 0.8891\n",
      "Epoch 74/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0696 - auc_64: 0.9753 - val_loss: 0.1167 - val_auc_64: 0.8879\n",
      "Epoch 75/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0679 - auc_64: 0.9766 - val_loss: 0.1119 - val_auc_64: 0.8894\n",
      "Epoch 76/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0666 - auc_64: 0.9770 - val_loss: 0.1213 - val_auc_64: 0.8873\n",
      "Epoch 77/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0662 - auc_64: 0.9767 - val_loss: 0.1071 - val_auc_64: 0.8897\n",
      "Epoch 78/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0648 - auc_64: 0.9778 - val_loss: 0.1113 - val_auc_64: 0.8881\n",
      "Epoch 79/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0638 - auc_64: 0.9775 - val_loss: 0.0999 - val_auc_64: 0.8903\n",
      "Epoch 80/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0626 - auc_64: 0.9778 - val_loss: 0.1004 - val_auc_64: 0.8923\n",
      "Epoch 81/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0617 - auc_64: 0.9783 - val_loss: 0.1055 - val_auc_64: 0.8903\n",
      "Epoch 82/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0609 - auc_64: 0.9783 - val_loss: 0.1011 - val_auc_64: 0.8907\n",
      "Epoch 83/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0600 - auc_64: 0.9790 - val_loss: 0.1095 - val_auc_64: 0.8890\n",
      "Epoch 84/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0592 - auc_64: 0.9785 - val_loss: 0.0959 - val_auc_64: 0.8934\n",
      "Epoch 85/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0584 - auc_64: 0.9795 - val_loss: 0.0909 - val_auc_64: 0.8940\n",
      "Epoch 86/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0575 - auc_64: 0.9798 - val_loss: 0.1032 - val_auc_64: 0.8906\n",
      "Epoch 87/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0567 - auc_64: 0.9797 - val_loss: 0.0991 - val_auc_64: 0.8925\n",
      "Epoch 88/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0559 - auc_64: 0.9800 - val_loss: 0.1082 - val_auc_64: 0.8895\n",
      "Epoch 89/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0549 - auc_64: 0.9800 - val_loss: 0.0915 - val_auc_64: 0.8949\n",
      "Epoch 90/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0546 - auc_64: 0.9805 - val_loss: 0.1063 - val_auc_64: 0.8903\n",
      "Epoch 91/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0539 - auc_64: 0.9803 - val_loss: 0.0969 - val_auc_64: 0.8924\n",
      "Epoch 92/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0527 - auc_64: 0.9813 - val_loss: 0.1001 - val_auc_64: 0.8921\n",
      "Epoch 93/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0517 - auc_64: 0.9813 - val_loss: 0.0929 - val_auc_64: 0.8742\n",
      "Epoch 94/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0509 - auc_64: 0.9822 - val_loss: 0.1029 - val_auc_64: 0.8914\n",
      "Epoch 95/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0505 - auc_64: 0.9815 - val_loss: 0.0905 - val_auc_64: 0.8752\n",
      "Epoch 96/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0500 - auc_64: 0.9818 - val_loss: 0.0944 - val_auc_64: 0.8745\n",
      "Epoch 97/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0488 - auc_64: 0.9825 - val_loss: 0.0931 - val_auc_64: 0.8752\n",
      "Epoch 98/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0479 - auc_64: 0.9837 - val_loss: 0.0990 - val_auc_64: 0.8733\n",
      "Epoch 99/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0473 - auc_64: 0.9832 - val_loss: 0.0917 - val_auc_64: 0.8557\n",
      "Epoch 100/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0508 - auc_64: 0.9832 - val_loss: 0.0940 - val_auc_64: 0.8759\n",
      "Epoch 101/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0474 - auc_64: 0.9827 - val_loss: 0.0928 - val_auc_64: 0.8766\n",
      "Epoch 102/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0481 - auc_64: 0.9850 - val_loss: 0.0905 - val_auc_64: 0.8776\n",
      "Epoch 103/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0448 - auc_64: 0.9837 - val_loss: 0.0906 - val_auc_64: 0.8571\n",
      "Epoch 104/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0442 - auc_64: 0.9840 - val_loss: 0.0940 - val_auc_64: 0.8774\n",
      "Epoch 105/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0437 - auc_64: 0.9842 - val_loss: 0.0871 - val_auc_64: 0.8581\n",
      "Epoch 106/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0436 - auc_64: 0.9852 - val_loss: 0.0916 - val_auc_64: 0.8572\n",
      "Epoch 107/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0427 - auc_64: 0.9847 - val_loss: 0.0932 - val_auc_64: 0.8577\n",
      "Epoch 108/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0422 - auc_64: 0.9845 - val_loss: 0.0914 - val_auc_64: 0.8587\n",
      "Epoch 109/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0412 - auc_64: 0.9850 - val_loss: 0.0869 - val_auc_64: 0.8595\n",
      "Epoch 110/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0407 - auc_64: 0.9857 - val_loss: 0.0841 - val_auc_64: 0.8609\n",
      "Epoch 111/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0404 - auc_64: 0.9862 - val_loss: 0.0859 - val_auc_64: 0.8607\n",
      "Epoch 112/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0398 - auc_64: 0.9860 - val_loss: 0.0868 - val_auc_64: 0.8611\n",
      "Epoch 113/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0439 - auc_64: 0.9882 - val_loss: 0.0951 - val_auc_64: 0.8590\n",
      "Epoch 114/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0394 - auc_64: 0.9863 - val_loss: 0.0884 - val_auc_64: 0.8617\n",
      "Epoch 115/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0385 - auc_64: 0.9870 - val_loss: 0.0891 - val_auc_64: 0.8816\n",
      "Epoch 116/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0384 - auc_64: 0.9865 - val_loss: 0.0962 - val_auc_64: 0.8805\n",
      "Epoch 117/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0374 - auc_64: 0.9863 - val_loss: 0.0813 - val_auc_64: 0.8619\n",
      "Epoch 118/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0372 - auc_64: 0.9872 - val_loss: 0.0793 - val_auc_64: 0.8837\n",
      "Epoch 119/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0396 - auc_64: 0.9888 - val_loss: 0.0834 - val_auc_64: 0.8828\n",
      "Epoch 120/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0363 - auc_64: 0.9873 - val_loss: 0.0904 - val_auc_64: 0.8820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0359 - auc_64: 0.9877 - val_loss: 0.0847 - val_auc_64: 0.8831\n",
      "Epoch 122/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0357 - auc_64: 0.9880 - val_loss: 0.0829 - val_auc_64: 0.8843\n",
      "Epoch 123/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0349 - auc_64: 0.9878 - val_loss: 0.0823 - val_auc_64: 0.8852\n",
      "Epoch 124/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0354 - auc_64: 0.9887 - val_loss: 0.0869 - val_auc_64: 0.8834\n",
      "Epoch 125/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0342 - auc_64: 0.9880 - val_loss: 0.0873 - val_auc_64: 0.8834\n",
      "Epoch 126/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0337 - auc_64: 0.9882 - val_loss: 0.0882 - val_auc_64: 0.8839\n",
      "Epoch 127/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0333 - auc_64: 0.9888 - val_loss: 0.0911 - val_auc_64: 0.8845\n",
      "Epoch 128/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0331 - auc_64: 0.9877 - val_loss: 0.0834 - val_auc_64: 0.8847\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.6568 - auc_65: 0.5373 - val_loss: 0.4851 - val_auc_65: 0.6394\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.5064 - auc_65: 0.6974 - val_loss: 0.4016 - val_auc_65: 0.7595\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.4127 - auc_65: 0.7782 - val_loss: 0.3449 - val_auc_65: 0.8140\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3537 - auc_65: 0.8190 - val_loss: 0.2764 - val_auc_65: 0.8390\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3192 - auc_65: 0.8579 - val_loss: 0.2872 - val_auc_65: 0.8353\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2932 - auc_65: 0.8668 - val_loss: 0.2323 - val_auc_65: 0.8573\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2745 - auc_65: 0.8853 - val_loss: 0.2252 - val_auc_65: 0.8624\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2595 - auc_65: 0.8947 - val_loss: 0.2460 - val_auc_65: 0.8529\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2484 - auc_65: 0.8979 - val_loss: 0.2267 - val_auc_65: 0.8620\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2396 - auc_65: 0.9048 - val_loss: 0.2264 - val_auc_65: 0.8647\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2313 - auc_65: 0.9097 - val_loss: 0.2174 - val_auc_65: 0.8674\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2245 - auc_65: 0.9098 - val_loss: 0.2137 - val_auc_65: 0.8728\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2185 - auc_65: 0.9133 - val_loss: 0.2064 - val_auc_65: 0.8755\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2124 - auc_65: 0.9204 - val_loss: 0.2098 - val_auc_65: 0.8760\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2088 - auc_65: 0.9187 - val_loss: 0.2106 - val_auc_65: 0.8767\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2053 - auc_65: 0.9255 - val_loss: 0.1831 - val_auc_65: 0.8834\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2009 - auc_65: 0.9288 - val_loss: 0.2084 - val_auc_65: 0.8784\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1955 - auc_65: 0.9259 - val_loss: 0.1960 - val_auc_65: 0.8812\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1917 - auc_65: 0.9293 - val_loss: 0.2093 - val_auc_65: 0.8772\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1895 - auc_65: 0.9292 - val_loss: 0.2098 - val_auc_65: 0.8780\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1850 - auc_65: 0.9308 - val_loss: 0.1803 - val_auc_65: 0.8876\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1867 - auc_65: 0.9370 - val_loss: 0.1766 - val_auc_65: 0.8864\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1801 - auc_65: 0.9371 - val_loss: 0.1733 - val_auc_65: 0.8889\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1761 - auc_65: 0.9381 - val_loss: 0.2133 - val_auc_65: 0.8774\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1736 - auc_65: 0.9363 - val_loss: 0.1881 - val_auc_65: 0.8883\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1702 - auc_65: 0.9405 - val_loss: 0.1866 - val_auc_65: 0.8897\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1665 - auc_65: 0.9415 - val_loss: 0.1875 - val_auc_65: 0.8893\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1637 - auc_65: 0.9412 - val_loss: 0.1735 - val_auc_65: 0.8931\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1609 - auc_65: 0.9430 - val_loss: 0.1714 - val_auc_65: 0.8760\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1583 - auc_65: 0.9461 - val_loss: 0.1813 - val_auc_65: 0.8903\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1549 - auc_65: 0.9458 - val_loss: 0.1952 - val_auc_65: 0.8892\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1521 - auc_65: 0.9452 - val_loss: 0.1786 - val_auc_65: 0.8601\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1487 - auc_65: 0.9474 - val_loss: 0.1650 - val_auc_65: 0.8646\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1483 - auc_65: 0.9529 - val_loss: 0.1893 - val_auc_65: 0.8913\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1429 - auc_65: 0.9506 - val_loss: 0.1693 - val_auc_65: 0.8642\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1397 - auc_65: 0.9500 - val_loss: 0.1708 - val_auc_65: 0.8644\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1367 - auc_65: 0.9522 - val_loss: 0.1639 - val_auc_65: 0.8672\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1339 - auc_65: 0.9535 - val_loss: 0.1586 - val_auc_65: 0.8694\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1315 - auc_65: 0.9560 - val_loss: 0.1565 - val_auc_65: 0.8695\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1286 - auc_65: 0.9549 - val_loss: 0.1444 - val_auc_65: 0.8735\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1258 - auc_65: 0.9565 - val_loss: 0.1316 - val_auc_65: 0.8759\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1247 - auc_65: 0.9582 - val_loss: 0.1505 - val_auc_65: 0.8726\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1210 - auc_65: 0.9573 - val_loss: 0.1277 - val_auc_65: 0.8764\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1267 - auc_65: 0.9631 - val_loss: 0.1396 - val_auc_65: 0.8733\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1175 - auc_65: 0.9601 - val_loss: 0.1487 - val_auc_65: 0.8747\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1149 - auc_65: 0.9594 - val_loss: 0.1366 - val_auc_65: 0.8766\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1129 - auc_65: 0.9608 - val_loss: 0.1379 - val_auc_65: 0.8768\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1106 - auc_65: 0.9624 - val_loss: 0.1446 - val_auc_65: 0.8761\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1092 - auc_65: 0.9624 - val_loss: 0.1274 - val_auc_65: 0.8797\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1095 - auc_65: 0.9637 - val_loss: 0.1132 - val_auc_65: 0.8858\n",
      "Epoch 51/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1094 - auc_65: 0.9667 - val_loss: 0.1303 - val_auc_65: 0.8801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1035 - auc_65: 0.9653 - val_loss: 0.1268 - val_auc_65: 0.8802\n",
      "Epoch 53/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1027 - auc_65: 0.9667 - val_loss: 0.1206 - val_auc_65: 0.8832\n",
      "Epoch 54/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1032 - auc_65: 0.9696 - val_loss: 0.1338 - val_auc_65: 0.8771\n",
      "Epoch 55/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0992 - auc_65: 0.9675 - val_loss: 0.1265 - val_auc_65: 0.8804\n",
      "Epoch 56/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0971 - auc_65: 0.9681 - val_loss: 0.1246 - val_auc_65: 0.8826\n",
      "Epoch 57/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0956 - auc_65: 0.9686 - val_loss: 0.1183 - val_auc_65: 0.8853\n",
      "Epoch 58/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0943 - auc_65: 0.9698 - val_loss: 0.1349 - val_auc_65: 0.8814\n",
      "Epoch 59/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0950 - auc_65: 0.9669 - val_loss: 0.1236 - val_auc_65: 0.8865\n",
      "Epoch 60/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0921 - auc_65: 0.9683 - val_loss: 0.1211 - val_auc_65: 0.8855\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.6029 - auc_66: 0.5801 - val_loss: 0.4291 - val_auc_66: 0.7025\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.4592 - auc_66: 0.7573 - val_loss: 0.3480 - val_auc_66: 0.7661\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3786 - auc_66: 0.8095 - val_loss: 0.2822 - val_auc_66: 0.8191\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3312 - auc_66: 0.8410 - val_loss: 0.2576 - val_auc_66: 0.8404\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3001 - auc_66: 0.8677 - val_loss: 0.2779 - val_auc_66: 0.8376\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2778 - auc_66: 0.8791 - val_loss: 0.2577 - val_auc_66: 0.8423\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2602 - auc_66: 0.8872 - val_loss: 0.2193 - val_auc_66: 0.8586\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2456 - auc_66: 0.8953 - val_loss: 0.2053 - val_auc_66: 0.8522\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2329 - auc_66: 0.9017 - val_loss: 0.2007 - val_auc_66: 0.8546\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2224 - auc_66: 0.9084 - val_loss: 0.2040 - val_auc_66: 0.8584\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2130 - auc_66: 0.9129 - val_loss: 0.1933 - val_auc_66: 0.8535\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2081 - auc_66: 0.9127 - val_loss: 0.1913 - val_auc_66: 0.8527\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2001 - auc_66: 0.9221 - val_loss: 0.1963 - val_auc_66: 0.8523\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1951 - auc_66: 0.9214 - val_loss: 0.1625 - val_auc_66: 0.8637\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1902 - auc_66: 0.9269 - val_loss: 0.1817 - val_auc_66: 0.8569\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1854 - auc_66: 0.9239 - val_loss: 0.1601 - val_auc_66: 0.8509\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1824 - auc_66: 0.9287 - val_loss: 0.1536 - val_auc_66: 0.8533\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1781 - auc_66: 0.9307 - val_loss: 0.1779 - val_auc_66: 0.8465\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1790 - auc_66: 0.9241 - val_loss: 0.1713 - val_auc_66: 0.8467\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1716 - auc_66: 0.9329 - val_loss: 0.1659 - val_auc_66: 0.8493\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1686 - auc_66: 0.9354 - val_loss: 0.1550 - val_auc_66: 0.8546\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1700 - auc_66: 0.9366 - val_loss: 0.1502 - val_auc_66: 0.8543\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1634 - auc_66: 0.9353 - val_loss: 0.1653 - val_auc_66: 0.8511\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1613 - auc_66: 0.9362 - val_loss: 0.1499 - val_auc_66: 0.8560\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1586 - auc_66: 0.9356 - val_loss: 0.1407 - val_auc_66: 0.8574\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1558 - auc_66: 0.9370 - val_loss: 0.1435 - val_auc_66: 0.8575\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1530 - auc_66: 0.9375 - val_loss: 0.1492 - val_auc_66: 0.8571\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1508 - auc_66: 0.9406 - val_loss: 0.1487 - val_auc_66: 0.8579\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1484 - auc_66: 0.9417 - val_loss: 0.1448 - val_auc_66: 0.8595\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1462 - auc_66: 0.9428 - val_loss: 0.1459 - val_auc_66: 0.8577\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1439 - auc_66: 0.9420 - val_loss: 0.1528 - val_auc_66: 0.8583\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1420 - auc_66: 0.9431 - val_loss: 0.1610 - val_auc_66: 0.8563\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1397 - auc_66: 0.9426 - val_loss: 0.1353 - val_auc_66: 0.8628\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1372 - auc_66: 0.9460 - val_loss: 0.1532 - val_auc_66: 0.8573\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1353 - auc_66: 0.9451 - val_loss: 0.1366 - val_auc_66: 0.8633\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1340 - auc_66: 0.9459 - val_loss: 0.1609 - val_auc_66: 0.8559\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1359 - auc_66: 0.9436 - val_loss: 0.1332 - val_auc_66: 0.8620\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1299 - auc_66: 0.9477 - val_loss: 0.1498 - val_auc_66: 0.8589\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1269 - auc_66: 0.9484 - val_loss: 0.1199 - val_auc_66: 0.8506\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1260 - auc_66: 0.9560 - val_loss: 0.1299 - val_auc_66: 0.8480\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1218 - auc_66: 0.9521 - val_loss: 0.1193 - val_auc_66: 0.8520\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1198 - auc_66: 0.9527 - val_loss: 0.1268 - val_auc_66: 0.8495\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1176 - auc_66: 0.9537 - val_loss: 0.1203 - val_auc_66: 0.8525\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1187 - auc_66: 0.9583 - val_loss: 0.1180 - val_auc_66: 0.8547\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1144 - auc_66: 0.9565 - val_loss: 0.1347 - val_auc_66: 0.8498\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1133 - auc_66: 0.9532 - val_loss: 0.1149 - val_auc_66: 0.8560\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1106 - auc_66: 0.9577 - val_loss: 0.1079 - val_auc_66: 0.8581\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1093 - auc_66: 0.9590 - val_loss: 0.1101 - val_auc_66: 0.8582\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1072 - auc_66: 0.9602 - val_loss: 0.1157 - val_auc_66: 0.8568\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1053 - auc_66: 0.9586 - val_loss: 0.1155 - val_auc_66: 0.8568\n",
      "Epoch 51/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1034 - auc_66: 0.9593 - val_loss: 0.1176 - val_auc_66: 0.8566\n",
      "Epoch 52/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1027 - auc_66: 0.9602 - val_loss: 0.1050 - val_auc_66: 0.8604\n",
      "Epoch 53/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1001 - auc_66: 0.9604 - val_loss: 0.1062 - val_auc_66: 0.8597\n",
      "Epoch 54/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0983 - auc_66: 0.9616 - val_loss: 0.1041 - val_auc_66: 0.8610\n",
      "Epoch 55/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0962 - auc_66: 0.9641 - val_loss: 0.1133 - val_auc_66: 0.8587\n",
      "Epoch 56/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0951 - auc_66: 0.9620 - val_loss: 0.1142 - val_auc_66: 0.8586\n",
      "Epoch 57/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0944 - auc_66: 0.9619 - val_loss: 0.1152 - val_auc_66: 0.8588\n",
      "Epoch 58/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0919 - auc_66: 0.9640 - val_loss: 0.1117 - val_auc_66: 0.8599\n",
      "Epoch 59/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0907 - auc_66: 0.9642 - val_loss: 0.1059 - val_auc_66: 0.8625\n",
      "Epoch 60/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0907 - auc_66: 0.9645 - val_loss: 0.1054 - val_auc_66: 0.8636\n",
      "Epoch 61/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0877 - auc_66: 0.9662 - val_loss: 0.1011 - val_auc_66: 0.8649\n",
      "Epoch 62/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0864 - auc_66: 0.9673 - val_loss: 0.0932 - val_auc_66: 0.8663\n",
      "Epoch 63/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0850 - auc_66: 0.9670 - val_loss: 0.0973 - val_auc_66: 0.8659\n",
      "Epoch 64/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0836 - auc_66: 0.9677 - val_loss: 0.0968 - val_auc_66: 0.8659\n",
      "Epoch 65/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0822 - auc_66: 0.9692 - val_loss: 0.1049 - val_auc_66: 0.8655\n",
      "Epoch 66/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0813 - auc_66: 0.9687 - val_loss: 0.1051 - val_auc_66: 0.8662\n",
      "Epoch 67/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0796 - auc_66: 0.9687 - val_loss: 0.0912 - val_auc_66: 0.8682\n",
      "Epoch 68/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0787 - auc_66: 0.9699 - val_loss: 0.0925 - val_auc_66: 0.8683\n",
      "Epoch 69/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0780 - auc_66: 0.9701 - val_loss: 0.1113 - val_auc_66: 0.8652\n",
      "Epoch 70/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0764 - auc_66: 0.9691 - val_loss: 0.0911 - val_auc_66: 0.8683\n",
      "Epoch 71/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0749 - auc_66: 0.9721 - val_loss: 0.1108 - val_auc_66: 0.8664\n",
      "Epoch 72/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0748 - auc_66: 0.9704 - val_loss: 0.0966 - val_auc_66: 0.8674\n",
      "Epoch 73/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0724 - auc_66: 0.9715 - val_loss: 0.0832 - val_auc_66: 0.8721\n",
      "Epoch 74/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0771 - auc_66: 0.9721 - val_loss: 0.0839 - val_auc_66: 0.8703\n",
      "Epoch 75/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0714 - auc_66: 0.9741 - val_loss: 0.0920 - val_auc_66: 0.8691\n",
      "Epoch 76/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0692 - auc_66: 0.9728 - val_loss: 0.0923 - val_auc_66: 0.8698\n",
      "Epoch 77/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0681 - auc_66: 0.9735 - val_loss: 0.0962 - val_auc_66: 0.8683\n",
      "Epoch 78/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0682 - auc_66: 0.9728 - val_loss: 0.0901 - val_auc_66: 0.8704\n",
      "Epoch 79/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0661 - auc_66: 0.9738 - val_loss: 0.0856 - val_auc_66: 0.8720\n",
      "Epoch 80/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0652 - auc_66: 0.9747 - val_loss: 0.0929 - val_auc_66: 0.8698\n",
      "Epoch 81/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0644 - auc_66: 0.9740 - val_loss: 0.0980 - val_auc_66: 0.8687\n",
      "Epoch 82/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0669 - auc_66: 0.9705 - val_loss: 0.0943 - val_auc_66: 0.8696\n",
      "Epoch 83/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0629 - auc_66: 0.9742 - val_loss: 0.0806 - val_auc_66: 0.8721\n",
      "Epoch 84/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0619 - auc_66: 0.9753 - val_loss: 0.0918 - val_auc_66: 0.8706\n",
      "Epoch 85/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0614 - auc_66: 0.9748 - val_loss: 0.0852 - val_auc_66: 0.8734\n",
      "Epoch 86/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0604 - auc_66: 0.9768 - val_loss: 0.0906 - val_auc_66: 0.8719\n",
      "Epoch 87/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0595 - auc_66: 0.9752 - val_loss: 0.0885 - val_auc_66: 0.8726\n",
      "Epoch 88/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0582 - auc_66: 0.9770 - val_loss: 0.0836 - val_auc_66: 0.8748\n",
      "Epoch 89/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0573 - auc_66: 0.9772 - val_loss: 0.0781 - val_auc_66: 0.8749\n",
      "Epoch 90/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0567 - auc_66: 0.9782 - val_loss: 0.0908 - val_auc_66: 0.8727\n",
      "Epoch 91/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0565 - auc_66: 0.9763 - val_loss: 0.0919 - val_auc_66: 0.8723\n",
      "Epoch 92/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0552 - auc_66: 0.9782 - val_loss: 0.0832 - val_auc_66: 0.8748\n",
      "Epoch 93/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0546 - auc_66: 0.9775 - val_loss: 0.0858 - val_auc_66: 0.8745\n",
      "Epoch 94/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0538 - auc_66: 0.9792 - val_loss: 0.0843 - val_auc_66: 0.8752\n",
      "Epoch 95/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0527 - auc_66: 0.9782 - val_loss: 0.0846 - val_auc_66: 0.8752\n",
      "Epoch 96/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0548 - auc_66: 0.9817 - val_loss: 0.0800 - val_auc_66: 0.8768\n",
      "Epoch 97/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0511 - auc_66: 0.9790 - val_loss: 0.0888 - val_auc_66: 0.8748\n",
      "Epoch 98/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0514 - auc_66: 0.9797 - val_loss: 0.0799 - val_auc_66: 0.8770\n",
      "Epoch 99/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0496 - auc_66: 0.9800 - val_loss: 0.0905 - val_auc_66: 0.8745\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.6778 - auc_67: 0.4983 - val_loss: 0.5723 - val_auc_67: 0.5199\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.4971 - auc_67: 0.6446 - val_loss: 0.4196 - val_auc_67: 0.7297\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3872 - auc_67: 0.7994 - val_loss: 0.3213 - val_auc_67: 0.8081\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3340 - auc_67: 0.8474 - val_loss: 0.2752 - val_auc_67: 0.8318\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3033 - auc_67: 0.8662 - val_loss: 0.2543 - val_auc_67: 0.8457\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2828 - auc_67: 0.8801 - val_loss: 0.2182 - val_auc_67: 0.8524\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2682 - auc_67: 0.8881 - val_loss: 0.2588 - val_auc_67: 0.8454\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2559 - auc_67: 0.8944 - val_loss: 0.2293 - val_auc_67: 0.8492\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2442 - auc_67: 0.9003 - val_loss: 0.2471 - val_auc_67: 0.8370\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2352 - auc_67: 0.9037 - val_loss: 0.1837 - val_auc_67: 0.8503\n",
      "Epoch 11/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2271 - auc_67: 0.9149 - val_loss: 0.2072 - val_auc_67: 0.8452\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2185 - auc_67: 0.9139 - val_loss: 0.1932 - val_auc_67: 0.8509\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2109 - auc_67: 0.9179 - val_loss: 0.1722 - val_auc_67: 0.8543\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2051 - auc_67: 0.9207 - val_loss: 0.1839 - val_auc_67: 0.8505\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1989 - auc_67: 0.9249 - val_loss: 0.2051 - val_auc_67: 0.8454\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1934 - auc_67: 0.9278 - val_loss: 0.2072 - val_auc_67: 0.8462\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1889 - auc_67: 0.9256 - val_loss: 0.1724 - val_auc_67: 0.8566\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1844 - auc_67: 0.9298 - val_loss: 0.1695 - val_auc_67: 0.8587\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1803 - auc_67: 0.9313 - val_loss: 0.1586 - val_auc_67: 0.8485\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1761 - auc_67: 0.9334 - val_loss: 0.1690 - val_auc_67: 0.8456\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1727 - auc_67: 0.9358 - val_loss: 0.1665 - val_auc_67: 0.8468\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1689 - auc_67: 0.9371 - val_loss: 0.1546 - val_auc_67: 0.8467\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1654 - auc_67: 0.9364 - val_loss: 0.1573 - val_auc_67: 0.8455\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1620 - auc_67: 0.9403 - val_loss: 0.1632 - val_auc_67: 0.8454\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1590 - auc_67: 0.9402 - val_loss: 0.1441 - val_auc_67: 0.8508\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1555 - auc_67: 0.9434 - val_loss: 0.1696 - val_auc_67: 0.8428\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1563 - auc_67: 0.9381 - val_loss: 0.1461 - val_auc_67: 0.8495\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1549 - auc_67: 0.9462 - val_loss: 0.1410 - val_auc_67: 0.8526\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1479 - auc_67: 0.9440 - val_loss: 0.1302 - val_auc_67: 0.8560\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1452 - auc_67: 0.9457 - val_loss: 0.1474 - val_auc_67: 0.8528\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1446 - auc_67: 0.9424 - val_loss: 0.1352 - val_auc_67: 0.8554\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1418 - auc_67: 0.9483 - val_loss: 0.1318 - val_auc_67: 0.8572\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1387 - auc_67: 0.9488 - val_loss: 0.1320 - val_auc_67: 0.8581\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1367 - auc_67: 0.9501 - val_loss: 0.1440 - val_auc_67: 0.8536\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1340 - auc_67: 0.9510 - val_loss: 0.1230 - val_auc_67: 0.8590\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1323 - auc_67: 0.9532 - val_loss: 0.1400 - val_auc_67: 0.8557\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1339 - auc_67: 0.9491 - val_loss: 0.1557 - val_auc_67: 0.8505\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1285 - auc_67: 0.9531 - val_loss: 0.1361 - val_auc_67: 0.8565\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1278 - auc_67: 0.9518 - val_loss: 0.1175 - val_auc_67: 0.8618\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1277 - auc_67: 0.9579 - val_loss: 0.1245 - val_auc_67: 0.8620\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1235 - auc_67: 0.9576 - val_loss: 0.1347 - val_auc_67: 0.8582\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1241 - auc_67: 0.9522 - val_loss: 0.1422 - val_auc_67: 0.8564\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1219 - auc_67: 0.9552 - val_loss: 0.1343 - val_auc_67: 0.8594\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1194 - auc_67: 0.9568 - val_loss: 0.1100 - val_auc_67: 0.8652\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1172 - auc_67: 0.9583 - val_loss: 0.1240 - val_auc_67: 0.8613\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1160 - auc_67: 0.9581 - val_loss: 0.1315 - val_auc_67: 0.8577\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1158 - auc_67: 0.9581 - val_loss: 0.1282 - val_auc_67: 0.8600\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1126 - auc_67: 0.9606 - val_loss: 0.1235 - val_auc_67: 0.8625\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1114 - auc_67: 0.9606 - val_loss: 0.1193 - val_auc_67: 0.8649\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1100 - auc_67: 0.9610 - val_loss: 0.1071 - val_auc_67: 0.8708\n",
      "Epoch 51/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1175 - auc_67: 0.9644 - val_loss: 0.1128 - val_auc_67: 0.8495\n",
      "Epoch 52/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1098 - auc_67: 0.9614 - val_loss: 0.1055 - val_auc_67: 0.8696\n",
      "Epoch 53/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1137 - auc_67: 0.9613 - val_loss: 0.1106 - val_auc_67: 0.8688\n",
      "Epoch 54/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1066 - auc_67: 0.9622 - val_loss: 0.1114 - val_auc_67: 0.8678\n",
      "Epoch 55/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1054 - auc_67: 0.9624 - val_loss: 0.1035 - val_auc_67: 0.8519\n",
      "Epoch 56/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.1036 - auc_67: 0.9621 - val_loss: 0.1032 - val_auc_67: 0.8526\n",
      "Epoch 57/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1028 - auc_67: 0.9639 - val_loss: 0.1135 - val_auc_67: 0.8684\n",
      "Epoch 58/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1013 - auc_67: 0.9644 - val_loss: 0.1152 - val_auc_67: 0.8678\n",
      "Epoch 59/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1002 - auc_67: 0.9651 - val_loss: 0.1207 - val_auc_67: 0.8674\n",
      "Epoch 60/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0992 - auc_67: 0.9638 - val_loss: 0.1092 - val_auc_67: 0.8711\n",
      "Epoch 61/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0984 - auc_67: 0.9640 - val_loss: 0.1106 - val_auc_67: 0.8707\n",
      "Epoch 62/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0980 - auc_67: 0.9637 - val_loss: 0.1054 - val_auc_67: 0.8529\n",
      "Epoch 63/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1010 - auc_67: 0.9653 - val_loss: 0.1022 - val_auc_67: 0.8530\n",
      "Epoch 64/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0959 - auc_67: 0.9656 - val_loss: 0.1055 - val_auc_67: 0.8531\n",
      "Epoch 65/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0944 - auc_67: 0.9655 - val_loss: 0.1046 - val_auc_67: 0.8742\n",
      "Epoch 66/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0932 - auc_67: 0.9663 - val_loss: 0.1108 - val_auc_67: 0.8717\n",
      "Epoch 67/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0925 - auc_67: 0.9655 - val_loss: 0.0975 - val_auc_67: 0.8380\n",
      "Epoch 68/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0914 - auc_67: 0.9673 - val_loss: 0.1158 - val_auc_67: 0.8700\n",
      "Epoch 69/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0912 - auc_67: 0.9666 - val_loss: 0.1108 - val_auc_67: 0.8726\n",
      "Epoch 70/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0895 - auc_67: 0.9677 - val_loss: 0.1117 - val_auc_67: 0.8534\n",
      "Epoch 71/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0888 - auc_67: 0.9670 - val_loss: 0.1063 - val_auc_67: 0.8562\n",
      "Epoch 72/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0878 - auc_67: 0.9670 - val_loss: 0.1005 - val_auc_67: 0.8374\n",
      "Epoch 73/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0868 - auc_67: 0.9689 - val_loss: 0.1164 - val_auc_67: 0.8522\n",
      "Epoch 74/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0861 - auc_67: 0.9681 - val_loss: 0.0966 - val_auc_67: 0.8380\n",
      "Epoch 75/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0850 - auc_67: 0.9696 - val_loss: 0.1090 - val_auc_67: 0.8568\n",
      "Epoch 76/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0844 - auc_67: 0.9687 - val_loss: 0.1011 - val_auc_67: 0.8400\n",
      "Epoch 77/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0833 - auc_67: 0.9689 - val_loss: 0.1023 - val_auc_67: 0.8396\n",
      "Epoch 78/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0825 - auc_67: 0.9689 - val_loss: 0.0924 - val_auc_67: 0.8402\n",
      "Epoch 79/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0826 - auc_67: 0.9706 - val_loss: 0.0914 - val_auc_67: 0.8406\n",
      "Epoch 80/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0810 - auc_67: 0.9703 - val_loss: 0.1012 - val_auc_67: 0.8392\n",
      "Epoch 81/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0811 - auc_67: 0.9706 - val_loss: 0.1022 - val_auc_67: 0.8386\n",
      "Epoch 82/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0795 - auc_67: 0.9708 - val_loss: 0.1035 - val_auc_67: 0.8387\n",
      "Epoch 83/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0783 - auc_67: 0.9713 - val_loss: 0.1055 - val_auc_67: 0.8375\n",
      "Epoch 84/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0774 - auc_67: 0.9708 - val_loss: 0.0871 - val_auc_67: 0.8410\n",
      "Epoch 85/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0893 - auc_67: 0.9735 - val_loss: 0.0866 - val_auc_67: 0.8414\n",
      "Epoch 86/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0768 - auc_67: 0.9711 - val_loss: 0.1005 - val_auc_67: 0.8400\n",
      "Epoch 87/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0769 - auc_67: 0.9706 - val_loss: 0.1096 - val_auc_67: 0.8575\n",
      "Epoch 88/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0757 - auc_67: 0.9712 - val_loss: 0.1028 - val_auc_67: 0.8397\n",
      "Epoch 89/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0742 - auc_67: 0.9723 - val_loss: 0.0891 - val_auc_67: 0.8430\n",
      "Epoch 90/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0739 - auc_67: 0.9723 - val_loss: 0.0898 - val_auc_67: 0.8422\n",
      "Epoch 91/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0726 - auc_67: 0.9725 - val_loss: 0.0887 - val_auc_67: 0.8430\n",
      "Epoch 92/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0727 - auc_67: 0.9728 - val_loss: 0.0931 - val_auc_67: 0.8419\n",
      "Epoch 93/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0712 - auc_67: 0.9723 - val_loss: 0.0785 - val_auc_67: 0.8260\n",
      "Epoch 94/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0756 - auc_67: 0.9765 - val_loss: 0.0928 - val_auc_67: 0.8421\n",
      "Epoch 95/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0716 - auc_67: 0.9727 - val_loss: 0.1027 - val_auc_67: 0.8397\n",
      "Epoch 96/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0696 - auc_67: 0.9745 - val_loss: 0.0931 - val_auc_67: 0.8427\n",
      "Epoch 97/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0691 - auc_67: 0.9737 - val_loss: 0.0911 - val_auc_67: 0.8432\n",
      "Epoch 98/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0686 - auc_67: 0.9755 - val_loss: 0.0906 - val_auc_67: 0.8439\n",
      "Epoch 99/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0674 - auc_67: 0.9737 - val_loss: 0.0875 - val_auc_67: 0.8450\n",
      "Epoch 100/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0673 - auc_67: 0.9765 - val_loss: 0.1059 - val_auc_67: 0.8405\n",
      "Epoch 101/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0671 - auc_67: 0.9740 - val_loss: 0.0903 - val_auc_67: 0.8442\n",
      "Epoch 102/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0657 - auc_67: 0.9753 - val_loss: 0.0898 - val_auc_67: 0.8440\n",
      "Epoch 103/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0660 - auc_67: 0.9753 - val_loss: 0.0972 - val_auc_67: 0.8425\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.6213 - auc_68: 0.5416 - val_loss: 0.4575 - val_auc_68: 0.6245\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.4728 - auc_68: 0.7415 - val_loss: 0.3790 - val_auc_68: 0.7485\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3771 - auc_68: 0.8093 - val_loss: 0.3011 - val_auc_68: 0.8064\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3218 - auc_68: 0.8476 - val_loss: 0.2654 - val_auc_68: 0.8324\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2905 - auc_68: 0.8710 - val_loss: 0.2492 - val_auc_68: 0.8360\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2693 - auc_68: 0.8849 - val_loss: 0.2374 - val_auc_68: 0.8532\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2542 - auc_68: 0.8941 - val_loss: 0.2261 - val_auc_68: 0.8460\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2428 - auc_68: 0.8952 - val_loss: 0.1954 - val_auc_68: 0.8478\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2316 - auc_68: 0.9070 - val_loss: 0.1959 - val_auc_68: 0.8469\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2236 - auc_68: 0.9087 - val_loss: 0.1896 - val_auc_68: 0.8507\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2160 - auc_68: 0.9144 - val_loss: 0.2090 - val_auc_68: 0.8453\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2137 - auc_68: 0.9119 - val_loss: 0.1853 - val_auc_68: 0.8534\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2052 - auc_68: 0.9173 - val_loss: 0.1578 - val_auc_68: 0.8494\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2019 - auc_68: 0.9226 - val_loss: 0.1672 - val_auc_68: 0.8470\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1964 - auc_68: 0.9233 - val_loss: 0.1769 - val_auc_68: 0.8431\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1920 - auc_68: 0.9246 - val_loss: 0.1740 - val_auc_68: 0.8441\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1873 - auc_68: 0.9272 - val_loss: 0.1630 - val_auc_68: 0.8474\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1835 - auc_68: 0.9291 - val_loss: 0.1666 - val_auc_68: 0.8462\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1798 - auc_68: 0.9307 - val_loss: 0.1695 - val_auc_68: 0.8460\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1769 - auc_68: 0.9313 - val_loss: 0.1501 - val_auc_68: 0.8516\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1730 - auc_68: 0.9337 - val_loss: 0.1536 - val_auc_68: 0.8510\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1703 - auc_68: 0.9344 - val_loss: 0.1675 - val_auc_68: 0.8475\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1681 - auc_68: 0.9333 - val_loss: 0.1455 - val_auc_68: 0.8543\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1647 - auc_68: 0.9380 - val_loss: 0.1711 - val_auc_68: 0.8467\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1612 - auc_68: 0.9375 - val_loss: 0.1618 - val_auc_68: 0.8495\n",
      "Epoch 26/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1581 - auc_68: 0.9407 - val_loss: 0.1676 - val_auc_68: 0.8480\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1562 - auc_68: 0.9390 - val_loss: 0.1604 - val_auc_68: 0.8509\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1528 - auc_68: 0.9395 - val_loss: 0.1342 - val_auc_68: 0.8574\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1511 - auc_68: 0.9444 - val_loss: 0.1591 - val_auc_68: 0.8512\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1514 - auc_68: 0.9418 - val_loss: 0.1424 - val_auc_68: 0.8534\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1455 - auc_68: 0.9462 - val_loss: 0.1407 - val_auc_68: 0.8554\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1432 - auc_68: 0.9459 - val_loss: 0.1413 - val_auc_68: 0.8556\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1416 - auc_68: 0.9472 - val_loss: 0.1419 - val_auc_68: 0.8545\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1419 - auc_68: 0.9460 - val_loss: 0.1499 - val_auc_68: 0.8525\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1367 - auc_68: 0.9492 - val_loss: 0.1406 - val_auc_68: 0.8552\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1355 - auc_68: 0.9489 - val_loss: 0.1462 - val_auc_68: 0.8545\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1327 - auc_68: 0.9498 - val_loss: 0.1202 - val_auc_68: 0.8627\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1321 - auc_68: 0.9528 - val_loss: 0.1422 - val_auc_68: 0.8544\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1283 - auc_68: 0.9517 - val_loss: 0.1376 - val_auc_68: 0.8588\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1293 - auc_68: 0.9552 - val_loss: 0.1251 - val_auc_68: 0.8608\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1249 - auc_68: 0.9522 - val_loss: 0.1232 - val_auc_68: 0.8639\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1227 - auc_68: 0.9536 - val_loss: 0.1242 - val_auc_68: 0.8457\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1206 - auc_68: 0.9546 - val_loss: 0.1330 - val_auc_68: 0.8428\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1192 - auc_68: 0.9554 - val_loss: 0.1189 - val_auc_68: 0.8492\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1182 - auc_68: 0.9562 - val_loss: 0.1474 - val_auc_68: 0.8580\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1158 - auc_68: 0.9551 - val_loss: 0.1224 - val_auc_68: 0.8488\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1142 - auc_68: 0.9572 - val_loss: 0.1270 - val_auc_68: 0.8487\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1119 - auc_68: 0.9578 - val_loss: 0.1140 - val_auc_68: 0.8501\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1104 - auc_68: 0.9580 - val_loss: 0.1069 - val_auc_68: 0.8533\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1122 - auc_68: 0.9598 - val_loss: 0.1057 - val_auc_68: 0.8324\n",
      "Epoch 51/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1076 - auc_68: 0.9592 - val_loss: 0.1083 - val_auc_68: 0.8532\n",
      "Epoch 52/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1058 - auc_68: 0.9604 - val_loss: 0.1172 - val_auc_68: 0.8512\n",
      "Epoch 53/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1045 - auc_68: 0.9613 - val_loss: 0.1077 - val_auc_68: 0.8545\n",
      "Epoch 54/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1028 - auc_68: 0.9619 - val_loss: 0.1161 - val_auc_68: 0.8515\n",
      "Epoch 55/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1013 - auc_68: 0.9616 - val_loss: 0.1221 - val_auc_68: 0.8487\n",
      "Epoch 56/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1000 - auc_68: 0.9613 - val_loss: 0.1062 - val_auc_68: 0.8543\n",
      "Epoch 57/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0984 - auc_68: 0.9637 - val_loss: 0.1082 - val_auc_68: 0.8554\n",
      "Epoch 58/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0976 - auc_68: 0.9644 - val_loss: 0.1170 - val_auc_68: 0.8521\n",
      "Epoch 59/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0958 - auc_68: 0.9638 - val_loss: 0.1070 - val_auc_68: 0.8546\n",
      "Epoch 60/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0962 - auc_68: 0.9634 - val_loss: 0.1106 - val_auc_68: 0.8527\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.6210 - auc_69: 0.6030 - val_loss: 0.4023 - val_auc_69: 0.6999\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.4609 - auc_69: 0.7432 - val_loss: 0.2974 - val_auc_69: 0.7841\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3685 - auc_69: 0.8326 - val_loss: 0.2452 - val_auc_69: 0.8372\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3112 - auc_69: 0.8617 - val_loss: 0.2571 - val_auc_69: 0.8383\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2767 - auc_69: 0.8752 - val_loss: 0.2142 - val_auc_69: 0.8603\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2548 - auc_69: 0.8900 - val_loss: 0.1998 - val_auc_69: 0.8635\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2391 - auc_69: 0.9007 - val_loss: 0.2168 - val_auc_69: 0.8601\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2278 - auc_69: 0.9041 - val_loss: 0.1856 - val_auc_69: 0.8563\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2173 - auc_69: 0.9125 - val_loss: 0.2154 - val_auc_69: 0.8461\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2093 - auc_69: 0.9154 - val_loss: 0.1923 - val_auc_69: 0.8562\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2025 - auc_69: 0.9164 - val_loss: 0.1561 - val_auc_69: 0.8642\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1961 - auc_69: 0.9210 - val_loss: 0.1623 - val_auc_69: 0.8625\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1908 - auc_69: 0.9242 - val_loss: 0.1819 - val_auc_69: 0.8549\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1851 - auc_69: 0.9258 - val_loss: 0.1612 - val_auc_69: 0.8494\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1800 - auc_69: 0.9296 - val_loss: 0.1645 - val_auc_69: 0.8470\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1755 - auc_69: 0.9318 - val_loss: 0.1600 - val_auc_69: 0.8502\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1715 - auc_69: 0.9313 - val_loss: 0.1465 - val_auc_69: 0.8529\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1705 - auc_69: 0.9370 - val_loss: 0.1698 - val_auc_69: 0.8471\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1683 - auc_69: 0.9326 - val_loss: 0.1482 - val_auc_69: 0.8537\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1625 - auc_69: 0.9415 - val_loss: 0.1671 - val_auc_69: 0.8476\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1590 - auc_69: 0.9355 - val_loss: 0.1458 - val_auc_69: 0.8558\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1548 - auc_69: 0.9400 - val_loss: 0.1493 - val_auc_69: 0.8547\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1523 - auc_69: 0.9415 - val_loss: 0.1463 - val_auc_69: 0.8567\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1493 - auc_69: 0.9402 - val_loss: 0.1334 - val_auc_69: 0.8601\n",
      "Epoch 25/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1457 - auc_69: 0.9432 - val_loss: 0.1467 - val_auc_69: 0.8570\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1436 - auc_69: 0.9441 - val_loss: 0.1526 - val_auc_69: 0.8561\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1411 - auc_69: 0.9442 - val_loss: 0.1345 - val_auc_69: 0.8590\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1378 - auc_69: 0.9470 - val_loss: 0.1341 - val_auc_69: 0.8598\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1357 - auc_69: 0.9481 - val_loss: 0.1249 - val_auc_69: 0.8624\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1326 - auc_69: 0.9485 - val_loss: 0.1200 - val_auc_69: 0.8641\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1306 - auc_69: 0.9502 - val_loss: 0.1382 - val_auc_69: 0.8592\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1278 - auc_69: 0.9518 - val_loss: 0.1310 - val_auc_69: 0.8615\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1259 - auc_69: 0.9518 - val_loss: 0.1360 - val_auc_69: 0.8604\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1236 - auc_69: 0.9536 - val_loss: 0.1139 - val_auc_69: 0.8490\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1211 - auc_69: 0.9555 - val_loss: 0.1074 - val_auc_69: 0.8516\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1214 - auc_69: 0.9584 - val_loss: 0.1235 - val_auc_69: 0.8646\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1184 - auc_69: 0.9582 - val_loss: 0.1154 - val_auc_69: 0.8484\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1148 - auc_69: 0.9587 - val_loss: 0.1222 - val_auc_69: 0.8475\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1126 - auc_69: 0.9589 - val_loss: 0.1266 - val_auc_69: 0.8464\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1113 - auc_69: 0.9586 - val_loss: 0.1209 - val_auc_69: 0.8488\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1093 - auc_69: 0.9599 - val_loss: 0.1163 - val_auc_69: 0.8490\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1069 - auc_69: 0.9593 - val_loss: 0.1133 - val_auc_69: 0.8529\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1053 - auc_69: 0.9608 - val_loss: 0.1006 - val_auc_69: 0.8559\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1066 - auc_69: 0.9648 - val_loss: 0.1193 - val_auc_69: 0.8514\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1029 - auc_69: 0.9606 - val_loss: 0.1007 - val_auc_69: 0.8580\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1006 - auc_69: 0.9638 - val_loss: 0.1233 - val_auc_69: 0.8495\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0991 - auc_69: 0.9632 - val_loss: 0.1066 - val_auc_69: 0.8550\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0965 - auc_69: 0.9642 - val_loss: 0.1102 - val_auc_69: 0.8543\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0984 - auc_69: 0.9600 - val_loss: 0.0894 - val_auc_69: 0.8596\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0942 - auc_69: 0.9670 - val_loss: 0.1054 - val_auc_69: 0.8561\n",
      "Epoch 51/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0921 - auc_69: 0.9666 - val_loss: 0.0956 - val_auc_69: 0.8594\n",
      "Epoch 52/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0956 - auc_69: 0.9685 - val_loss: 0.0968 - val_auc_69: 0.8579\n",
      "Epoch 53/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0893 - auc_69: 0.9683 - val_loss: 0.1038 - val_auc_69: 0.8579\n",
      "Epoch 54/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0885 - auc_69: 0.9666 - val_loss: 0.0941 - val_auc_69: 0.8398\n",
      "Epoch 55/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0869 - auc_69: 0.9681 - val_loss: 0.1075 - val_auc_69: 0.8581\n",
      "Epoch 56/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0856 - auc_69: 0.9681 - val_loss: 0.0986 - val_auc_69: 0.8594\n",
      "Epoch 57/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0837 - auc_69: 0.9696 - val_loss: 0.0965 - val_auc_69: 0.8405\n",
      "Epoch 58/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0827 - auc_69: 0.9698 - val_loss: 0.0983 - val_auc_69: 0.8399\n",
      "Epoch 59/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0812 - auc_69: 0.9706 - val_loss: 0.1021 - val_auc_69: 0.8597\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 2s 21ms/step - loss: 0.5904 - auc_70: 0.5725 - val_loss: 0.4464 - val_auc_70: 0.6954\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.4119 - auc_70: 0.7705 - val_loss: 0.3256 - val_auc_70: 0.8051\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3327 - auc_70: 0.8362 - val_loss: 0.2846 - val_auc_70: 0.8245\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2934 - auc_70: 0.8608 - val_loss: 0.2470 - val_auc_70: 0.8455\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2685 - auc_70: 0.8848 - val_loss: 0.2476 - val_auc_70: 0.8452\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2499 - auc_70: 0.8943 - val_loss: 0.2142 - val_auc_70: 0.8640\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2354 - auc_70: 0.9043 - val_loss: 0.2241 - val_auc_70: 0.8477\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2228 - auc_70: 0.9061 - val_loss: 0.1979 - val_auc_70: 0.8474\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2122 - auc_70: 0.9144 - val_loss: 0.1760 - val_auc_70: 0.8537\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2069 - auc_70: 0.9151 - val_loss: 0.1866 - val_auc_70: 0.8553\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1983 - auc_70: 0.9212 - val_loss: 0.1822 - val_auc_70: 0.8543\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1925 - auc_70: 0.9255 - val_loss: 0.1832 - val_auc_70: 0.8559\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1875 - auc_70: 0.9273 - val_loss: 0.1786 - val_auc_70: 0.8583\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1824 - auc_70: 0.9313 - val_loss: 0.1831 - val_auc_70: 0.8572\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1782 - auc_70: 0.9296 - val_loss: 0.1650 - val_auc_70: 0.8500\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1735 - auc_70: 0.9302 - val_loss: 0.1380 - val_auc_70: 0.8590\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1703 - auc_70: 0.9368 - val_loss: 0.1727 - val_auc_70: 0.8488\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1678 - auc_70: 0.9346 - val_loss: 0.1832 - val_auc_70: 0.8467\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1692 - auc_70: 0.9319 - val_loss: 0.1637 - val_auc_70: 0.8518\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1609 - auc_70: 0.9375 - val_loss: 0.1431 - val_auc_70: 0.8589\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1578 - auc_70: 0.9401 - val_loss: 0.1386 - val_auc_70: 0.8598\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1563 - auc_70: 0.9436 - val_loss: 0.1314 - val_auc_70: 0.8608\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1516 - auc_70: 0.9429 - val_loss: 0.1225 - val_auc_70: 0.8639\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1527 - auc_70: 0.9465 - val_loss: 0.1436 - val_auc_70: 0.8594\n",
      "Epoch 25/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1468 - auc_70: 0.9444 - val_loss: 0.1474 - val_auc_70: 0.8572\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1450 - auc_70: 0.9421 - val_loss: 0.1461 - val_auc_70: 0.8554\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1423 - auc_70: 0.9443 - val_loss: 0.1391 - val_auc_70: 0.8585\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1392 - auc_70: 0.9478 - val_loss: 0.1363 - val_auc_70: 0.8591\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1370 - auc_70: 0.9479 - val_loss: 0.1200 - val_auc_70: 0.8628\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1360 - auc_70: 0.9516 - val_loss: 0.1348 - val_auc_70: 0.8582\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1325 - auc_70: 0.9490 - val_loss: 0.1223 - val_auc_70: 0.8620\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1302 - auc_70: 0.9519 - val_loss: 0.1252 - val_auc_70: 0.8614\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1273 - auc_70: 0.9530 - val_loss: 0.1355 - val_auc_70: 0.8588\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1257 - auc_70: 0.9529 - val_loss: 0.1198 - val_auc_70: 0.8657\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1234 - auc_70: 0.9551 - val_loss: 0.1141 - val_auc_70: 0.8485\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1216 - auc_70: 0.9568 - val_loss: 0.1045 - val_auc_70: 0.8523\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1195 - auc_70: 0.9564 - val_loss: 0.1068 - val_auc_70: 0.8516\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1180 - auc_70: 0.9565 - val_loss: 0.1169 - val_auc_70: 0.8500\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1147 - auc_70: 0.9590 - val_loss: 0.1267 - val_auc_70: 0.8468\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1127 - auc_70: 0.9571 - val_loss: 0.1135 - val_auc_70: 0.8521\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1108 - auc_70: 0.9579 - val_loss: 0.1219 - val_auc_70: 0.8491\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1090 - auc_70: 0.9590 - val_loss: 0.1008 - val_auc_70: 0.8560\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1075 - auc_70: 0.9612 - val_loss: 0.1266 - val_auc_70: 0.8478\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1139 - auc_70: 0.9532 - val_loss: 0.1239 - val_auc_70: 0.8465\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1057 - auc_70: 0.9622 - val_loss: 0.1162 - val_auc_70: 0.8505\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1020 - auc_70: 0.9616 - val_loss: 0.1055 - val_auc_70: 0.8548\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1002 - auc_70: 0.9636 - val_loss: 0.1226 - val_auc_70: 0.8513\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0990 - auc_70: 0.9634 - val_loss: 0.1029 - val_auc_70: 0.8570\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0977 - auc_70: 0.9634 - val_loss: 0.1107 - val_auc_70: 0.8540\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0961 - auc_70: 0.9651 - val_loss: 0.1136 - val_auc_70: 0.8539\n",
      "Epoch 51/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0946 - auc_70: 0.9651 - val_loss: 0.1026 - val_auc_70: 0.8581\n",
      "Epoch 52/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0933 - auc_70: 0.9656 - val_loss: 0.1010 - val_auc_70: 0.8578\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.5739 - auc_71: 0.5656 - val_loss: 0.4428 - val_auc_71: 0.6690\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.4048 - auc_71: 0.7813 - val_loss: 0.3534 - val_auc_71: 0.7096\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3191 - auc_71: 0.8459 - val_loss: 0.2762 - val_auc_71: 0.7451\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2733 - auc_71: 0.8770 - val_loss: 0.2499 - val_auc_71: 0.7512\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2464 - auc_71: 0.9035 - val_loss: 0.2535 - val_auc_71: 0.7500\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2301 - auc_71: 0.9014 - val_loss: 0.2420 - val_auc_71: 0.7503\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2143 - auc_71: 0.9122 - val_loss: 0.2177 - val_auc_71: 0.7578\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2028 - auc_71: 0.9202 - val_loss: 0.2015 - val_auc_71: 0.7533\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1984 - auc_71: 0.9321 - val_loss: 0.2050 - val_auc_71: 0.7603\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1875 - auc_71: 0.9345 - val_loss: 0.1985 - val_auc_71: 0.7670\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1812 - auc_71: 0.9345 - val_loss: 0.1904 - val_auc_71: 0.7724\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1758 - auc_71: 0.9389 - val_loss: 0.2115 - val_auc_71: 0.7706\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1740 - auc_71: 0.9364 - val_loss: 0.2033 - val_auc_71: 0.7746\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1675 - auc_71: 0.9398 - val_loss: 0.1965 - val_auc_71: 0.7771\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1630 - auc_71: 0.9431 - val_loss: 0.1830 - val_auc_71: 0.7691\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1603 - auc_71: 0.9466 - val_loss: 0.1803 - val_auc_71: 0.7717\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1560 - auc_71: 0.9459 - val_loss: 0.1826 - val_auc_71: 0.7593\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1531 - auc_71: 0.9488 - val_loss: 0.1951 - val_auc_71: 0.7585\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1506 - auc_71: 0.9485 - val_loss: 0.2010 - val_auc_71: 0.7582\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1468 - auc_71: 0.9496 - val_loss: 0.1815 - val_auc_71: 0.7635\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1443 - auc_71: 0.9524 - val_loss: 0.1789 - val_auc_71: 0.7651\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1416 - auc_71: 0.9509 - val_loss: 0.1806 - val_auc_71: 0.7654\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1404 - auc_71: 0.9514 - val_loss: 0.1769 - val_auc_71: 0.7693\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1365 - auc_71: 0.9559 - val_loss: 0.1610 - val_auc_71: 0.7737\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1400 - auc_71: 0.9585 - val_loss: 0.1680 - val_auc_71: 0.7753\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1337 - auc_71: 0.9564 - val_loss: 0.1672 - val_auc_71: 0.7595\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1323 - auc_71: 0.9585 - val_loss: 0.1731 - val_auc_71: 0.7597\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1293 - auc_71: 0.9575 - val_loss: 0.1807 - val_auc_71: 0.7594\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1273 - auc_71: 0.9591 - val_loss: 0.1809 - val_auc_71: 0.7605\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1254 - auc_71: 0.9600 - val_loss: 0.1941 - val_auc_71: 0.7586\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1245 - auc_71: 0.9570 - val_loss: 0.1797 - val_auc_71: 0.7607\n",
      "Epoch 32/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1218 - auc_71: 0.9598 - val_loss: 0.1740 - val_auc_71: 0.7643\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1209 - auc_71: 0.9608 - val_loss: 0.1676 - val_auc_71: 0.7479\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1185 - auc_71: 0.9614 - val_loss: 0.1677 - val_auc_71: 0.7496\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.6156 - auc_72: 0.5417 - val_loss: 0.4695 - val_auc_72: 0.6292\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.4577 - auc_72: 0.7194 - val_loss: 0.3806 - val_auc_72: 0.7049\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3486 - auc_72: 0.8128 - val_loss: 0.3011 - val_auc_72: 0.7302\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2855 - auc_72: 0.8672 - val_loss: 0.2731 - val_auc_72: 0.7459\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2484 - auc_72: 0.8912 - val_loss: 0.2305 - val_auc_72: 0.7507\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2298 - auc_72: 0.9165 - val_loss: 0.2350 - val_auc_72: 0.7550\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2129 - auc_72: 0.9121 - val_loss: 0.2166 - val_auc_72: 0.7636\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2010 - auc_72: 0.9198 - val_loss: 0.2220 - val_auc_72: 0.7525\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1903 - auc_72: 0.9263 - val_loss: 0.1998 - val_auc_72: 0.7611\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1824 - auc_72: 0.9302 - val_loss: 0.2098 - val_auc_72: 0.7667\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1754 - auc_72: 0.9329 - val_loss: 0.1924 - val_auc_72: 0.7442\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1695 - auc_72: 0.9373 - val_loss: 0.1881 - val_auc_72: 0.7509\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1639 - auc_72: 0.9434 - val_loss: 0.2004 - val_auc_72: 0.7507\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1593 - auc_72: 0.9425 - val_loss: 0.1789 - val_auc_72: 0.7609\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1554 - auc_72: 0.9472 - val_loss: 0.2035 - val_auc_72: 0.7573\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1518 - auc_72: 0.9470 - val_loss: 0.1876 - val_auc_72: 0.7494\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1475 - auc_72: 0.9499 - val_loss: 0.1909 - val_auc_72: 0.7498\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1446 - auc_72: 0.9530 - val_loss: 0.1714 - val_auc_72: 0.7572\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1417 - auc_72: 0.9551 - val_loss: 0.1680 - val_auc_72: 0.7565\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1460 - auc_72: 0.9568 - val_loss: 0.1803 - val_auc_72: 0.7565\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1386 - auc_72: 0.9517 - val_loss: 0.1772 - val_auc_72: 0.7574\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1348 - auc_72: 0.9541 - val_loss: 0.1701 - val_auc_72: 0.7600\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1328 - auc_72: 0.9556 - val_loss: 0.1648 - val_auc_72: 0.7605\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1308 - auc_72: 0.9572 - val_loss: 0.1644 - val_auc_72: 0.7636\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1291 - auc_72: 0.9578 - val_loss: 0.1724 - val_auc_72: 0.7646\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1266 - auc_72: 0.9580 - val_loss: 0.1603 - val_auc_72: 0.7348\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1249 - auc_72: 0.9592 - val_loss: 0.1748 - val_auc_72: 0.7508\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1229 - auc_72: 0.9607 - val_loss: 0.1747 - val_auc_72: 0.7527\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1210 - auc_72: 0.9603 - val_loss: 0.1706 - val_auc_72: 0.7389\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1192 - auc_72: 0.9622 - val_loss: 0.1736 - val_auc_72: 0.7386\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1179 - auc_72: 0.9619 - val_loss: 0.1750 - val_auc_72: 0.7395\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1175 - auc_72: 0.9605 - val_loss: 0.1670 - val_auc_72: 0.7382\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1137 - auc_72: 0.9648 - val_loss: 0.1854 - val_auc_72: 0.7382\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1125 - auc_72: 0.9636 - val_loss: 0.1673 - val_auc_72: 0.7463\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1103 - auc_72: 0.9645 - val_loss: 0.1390 - val_auc_72: 0.7514\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1149 - auc_72: 0.9664 - val_loss: 0.1474 - val_auc_72: 0.7512\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1076 - auc_72: 0.9664 - val_loss: 0.1529 - val_auc_72: 0.7495\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1059 - auc_72: 0.9659 - val_loss: 0.1652 - val_auc_72: 0.7487\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1042 - auc_72: 0.9666 - val_loss: 0.1497 - val_auc_72: 0.7516\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1039 - auc_72: 0.9689 - val_loss: 0.1533 - val_auc_72: 0.7317\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1015 - auc_72: 0.9686 - val_loss: 0.1507 - val_auc_72: 0.7333\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0994 - auc_72: 0.9681 - val_loss: 0.1591 - val_auc_72: 0.7516\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0987 - auc_72: 0.9681 - val_loss: 0.1481 - val_auc_72: 0.7344\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0972 - auc_72: 0.9690 - val_loss: 0.1523 - val_auc_72: 0.7355\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0957 - auc_72: 0.9686 - val_loss: 0.1582 - val_auc_72: 0.7346\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.5973 - auc_73: 0.6353 - val_loss: 0.3786 - val_auc_73: 0.6997\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.4022 - auc_73: 0.7947 - val_loss: 0.2922 - val_auc_73: 0.7254\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3139 - auc_73: 0.8566 - val_loss: 0.2468 - val_auc_73: 0.7534\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2611 - auc_73: 0.8858 - val_loss: 0.2349 - val_auc_73: 0.7623\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2292 - auc_73: 0.8998 - val_loss: 0.2115 - val_auc_73: 0.7669\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2092 - auc_73: 0.9200 - val_loss: 0.2068 - val_auc_73: 0.7634\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1941 - auc_73: 0.9270 - val_loss: 0.2031 - val_auc_73: 0.7663\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1832 - auc_73: 0.9257 - val_loss: 0.1954 - val_auc_73: 0.7614\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1750 - auc_73: 0.9329 - val_loss: 0.2010 - val_auc_73: 0.7628\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1677 - auc_73: 0.9352 - val_loss: 0.1819 - val_auc_73: 0.7594\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1620 - auc_73: 0.9405 - val_loss: 0.1874 - val_auc_73: 0.7608\n",
      "Epoch 12/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1561 - auc_73: 0.9429 - val_loss: 0.1767 - val_auc_73: 0.7519\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1513 - auc_73: 0.9463 - val_loss: 0.1834 - val_auc_73: 0.7526\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1467 - auc_73: 0.9494 - val_loss: 0.1853 - val_auc_73: 0.7539\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1431 - auc_73: 0.9505 - val_loss: 0.1973 - val_auc_73: 0.7529\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1403 - auc_73: 0.9493 - val_loss: 0.1715 - val_auc_73: 0.7627\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1351 - auc_73: 0.9525 - val_loss: 0.1624 - val_auc_73: 0.7663\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1320 - auc_73: 0.9554 - val_loss: 0.1727 - val_auc_73: 0.7651\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1290 - auc_73: 0.9562 - val_loss: 0.1601 - val_auc_73: 0.7692\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1287 - auc_73: 0.9585 - val_loss: 0.1596 - val_auc_73: 0.7725\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1244 - auc_73: 0.9574 - val_loss: 0.1378 - val_auc_73: 0.7463\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1252 - auc_73: 0.9595 - val_loss: 0.1577 - val_auc_73: 0.7547\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1185 - auc_73: 0.9578 - val_loss: 0.1473 - val_auc_73: 0.7430\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1164 - auc_73: 0.9615 - val_loss: 0.1554 - val_auc_73: 0.7422\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1139 - auc_73: 0.9634 - val_loss: 0.1675 - val_auc_73: 0.7415\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1127 - auc_73: 0.9623 - val_loss: 0.1599 - val_auc_73: 0.7442\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1099 - auc_73: 0.9642 - val_loss: 0.1613 - val_auc_73: 0.7457\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1090 - auc_73: 0.9618 - val_loss: 0.1587 - val_auc_73: 0.7477\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1062 - auc_73: 0.9644 - val_loss: 0.1561 - val_auc_73: 0.7494\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1065 - auc_73: 0.9670 - val_loss: 0.1525 - val_auc_73: 0.7497\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1025 - auc_73: 0.9667 - val_loss: 0.1605 - val_auc_73: 0.7503\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.5761 - auc_74: 0.5814 - val_loss: 0.4378 - val_auc_74: 0.6903\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.4173 - auc_74: 0.7630 - val_loss: 0.3637 - val_auc_74: 0.7184\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3252 - auc_74: 0.8457 - val_loss: 0.2644 - val_auc_74: 0.7424\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2673 - auc_74: 0.8828 - val_loss: 0.2391 - val_auc_74: 0.7556\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2366 - auc_74: 0.9072 - val_loss: 0.2202 - val_auc_74: 0.7640\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2151 - auc_74: 0.9130 - val_loss: 0.1906 - val_auc_74: 0.7534\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2015 - auc_74: 0.9241 - val_loss: 0.2009 - val_auc_74: 0.7568\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1896 - auc_74: 0.9294 - val_loss: 0.2141 - val_auc_74: 0.7491\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1811 - auc_74: 0.9305 - val_loss: 0.2015 - val_auc_74: 0.7569\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1738 - auc_74: 0.9361 - val_loss: 0.1837 - val_auc_74: 0.7523\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1676 - auc_74: 0.9411 - val_loss: 0.1715 - val_auc_74: 0.7461\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1619 - auc_74: 0.9444 - val_loss: 0.1746 - val_auc_74: 0.7484\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1560 - auc_74: 0.9458 - val_loss: 0.1781 - val_auc_74: 0.7501\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1529 - auc_74: 0.9486 - val_loss: 0.1831 - val_auc_74: 0.7515\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1488 - auc_74: 0.9483 - val_loss: 0.1848 - val_auc_74: 0.7539\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1445 - auc_74: 0.9510 - val_loss: 0.1762 - val_auc_74: 0.7588\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1406 - auc_74: 0.9536 - val_loss: 0.1787 - val_auc_74: 0.7586\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1374 - auc_74: 0.9546 - val_loss: 0.1873 - val_auc_74: 0.7632\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1345 - auc_74: 0.9548 - val_loss: 0.1806 - val_auc_74: 0.7648\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1309 - auc_74: 0.9575 - val_loss: 0.1791 - val_auc_74: 0.7647\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1276 - auc_74: 0.9572 - val_loss: 0.1581 - val_auc_74: 0.7734\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1249 - auc_74: 0.9611 - val_loss: 0.1883 - val_auc_74: 0.7683\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1240 - auc_74: 0.9569 - val_loss: 0.1647 - val_auc_74: 0.7556\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1198 - auc_74: 0.9609 - val_loss: 0.1624 - val_auc_74: 0.7589\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1172 - auc_74: 0.9614 - val_loss: 0.1515 - val_auc_74: 0.7643\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1155 - auc_74: 0.9628 - val_loss: 0.1554 - val_auc_74: 0.7463\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1185 - auc_74: 0.9655 - val_loss: 0.1585 - val_auc_74: 0.7473\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1109 - auc_74: 0.9640 - val_loss: 0.1542 - val_auc_74: 0.7507\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1086 - auc_74: 0.9657 - val_loss: 0.1576 - val_auc_74: 0.7503\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1067 - auc_74: 0.9659 - val_loss: 0.1354 - val_auc_74: 0.7549\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1131 - auc_74: 0.9648 - val_loss: 0.1371 - val_auc_74: 0.7520\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1050 - auc_74: 0.9670 - val_loss: 0.1385 - val_auc_74: 0.7566\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1074 - auc_74: 0.9676 - val_loss: 0.1538 - val_auc_74: 0.7569\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1018 - auc_74: 0.9638 - val_loss: 0.1471 - val_auc_74: 0.7578\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0993 - auc_74: 0.9672 - val_loss: 0.1522 - val_auc_74: 0.7582\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0974 - auc_74: 0.9683 - val_loss: 0.1398 - val_auc_74: 0.7583\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0968 - auc_74: 0.9694 - val_loss: 0.1425 - val_auc_74: 0.7578\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1002 - auc_74: 0.9708 - val_loss: 0.1441 - val_auc_74: 0.7611\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0937 - auc_74: 0.9703 - val_loss: 0.1480 - val_auc_74: 0.7623\n",
      "Epoch 40/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0926 - auc_74: 0.9696 - val_loss: 0.1463 - val_auc_74: 0.7639\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.6034 - auc_75: 0.5595 - val_loss: 0.4773 - val_auc_75: 0.6554\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.4280 - auc_75: 0.7392 - val_loss: 0.3792 - val_auc_75: 0.7443\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3326 - auc_75: 0.8277 - val_loss: 0.2961 - val_auc_75: 0.7626\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2786 - auc_75: 0.8718 - val_loss: 0.2556 - val_auc_75: 0.7723\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2456 - auc_75: 0.8913 - val_loss: 0.2354 - val_auc_75: 0.7712\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2237 - auc_75: 0.9083 - val_loss: 0.2122 - val_auc_75: 0.7760\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2080 - auc_75: 0.9172 - val_loss: 0.2275 - val_auc_75: 0.7746\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1957 - auc_75: 0.9226 - val_loss: 0.2011 - val_auc_75: 0.7721\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1886 - auc_75: 0.9321 - val_loss: 0.1984 - val_auc_75: 0.7770\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1788 - auc_75: 0.9349 - val_loss: 0.1929 - val_auc_75: 0.7684\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1724 - auc_75: 0.9402 - val_loss: 0.2242 - val_auc_75: 0.7703\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1682 - auc_75: 0.9386 - val_loss: 0.2100 - val_auc_75: 0.7708\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1639 - auc_75: 0.9401 - val_loss: 0.2004 - val_auc_75: 0.7773\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1597 - auc_75: 0.9433 - val_loss: 0.2018 - val_auc_75: 0.7764\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1551 - auc_75: 0.9463 - val_loss: 0.2014 - val_auc_75: 0.7811\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1519 - auc_75: 0.9476 - val_loss: 0.1942 - val_auc_75: 0.7688\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1490 - auc_75: 0.9503 - val_loss: 0.1797 - val_auc_75: 0.7735\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1464 - auc_75: 0.9496 - val_loss: 0.1775 - val_auc_75: 0.7781\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1431 - auc_75: 0.9529 - val_loss: 0.1819 - val_auc_75: 0.7620\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1403 - auc_75: 0.9524 - val_loss: 0.1721 - val_auc_75: 0.7629\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1384 - auc_75: 0.9538 - val_loss: 0.1803 - val_auc_75: 0.7632\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1356 - auc_75: 0.9549 - val_loss: 0.1686 - val_auc_75: 0.7700\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1337 - auc_75: 0.9576 - val_loss: 0.1732 - val_auc_75: 0.7701\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1315 - auc_75: 0.9589 - val_loss: 0.1846 - val_auc_75: 0.7690\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1296 - auc_75: 0.9566 - val_loss: 0.1975 - val_auc_75: 0.7666\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1298 - auc_75: 0.9566 - val_loss: 0.1852 - val_auc_75: 0.7534\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1254 - auc_75: 0.9606 - val_loss: 0.1960 - val_auc_75: 0.7505\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1239 - auc_75: 0.9610 - val_loss: 0.1902 - val_auc_75: 0.7541\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1216 - auc_75: 0.9621 - val_loss: 0.1762 - val_auc_75: 0.7597\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1203 - auc_75: 0.9623 - val_loss: 0.1761 - val_auc_75: 0.7616\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1179 - auc_75: 0.9633 - val_loss: 0.1549 - val_auc_75: 0.7513\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1167 - auc_75: 0.9636 - val_loss: 0.1763 - val_auc_75: 0.7465\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1147 - auc_75: 0.9644 - val_loss: 0.2039 - val_auc_75: 0.7587\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1170 - auc_75: 0.9616 - val_loss: 0.1829 - val_auc_75: 0.7493\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1118 - auc_75: 0.9634 - val_loss: 0.1604 - val_auc_75: 0.7567\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1108 - auc_75: 0.9653 - val_loss: 0.1643 - val_auc_75: 0.7568\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1114 - auc_75: 0.9671 - val_loss: 0.1677 - val_auc_75: 0.7572\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1079 - auc_75: 0.9672 - val_loss: 0.1654 - val_auc_75: 0.7566\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1065 - auc_75: 0.9672 - val_loss: 0.1570 - val_auc_75: 0.7571\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1052 - auc_75: 0.9677 - val_loss: 0.1630 - val_auc_75: 0.7574\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1043 - auc_75: 0.9667 - val_loss: 0.1639 - val_auc_75: 0.7581\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.6065 - auc_76: 0.5521 - val_loss: 0.4774 - val_auc_76: 0.6462\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.4488 - auc_76: 0.7062 - val_loss: 0.3730 - val_auc_76: 0.7627\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3660 - auc_76: 0.8017 - val_loss: 0.3072 - val_auc_76: 0.7951\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3179 - auc_76: 0.8540 - val_loss: 0.2778 - val_auc_76: 0.8188\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2863 - auc_76: 0.8744 - val_loss: 0.2460 - val_auc_76: 0.8387\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2658 - auc_76: 0.8859 - val_loss: 0.2571 - val_auc_76: 0.8372\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2508 - auc_76: 0.8903 - val_loss: 0.2347 - val_auc_76: 0.8479\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2395 - auc_76: 0.8998 - val_loss: 0.2209 - val_auc_76: 0.8567\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2335 - auc_76: 0.9084 - val_loss: 0.2271 - val_auc_76: 0.8559\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2243 - auc_76: 0.9075 - val_loss: 0.2192 - val_auc_76: 0.8609\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2189 - auc_76: 0.9151 - val_loss: 0.2179 - val_auc_76: 0.8620\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2158 - auc_76: 0.9092 - val_loss: 0.2221 - val_auc_76: 0.8620\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2091 - auc_76: 0.9152 - val_loss: 0.1968 - val_auc_76: 0.8637\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2072 - auc_76: 0.9229 - val_loss: 0.2136 - val_auc_76: 0.8633\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2008 - auc_76: 0.9236 - val_loss: 0.2226 - val_auc_76: 0.8622\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1969 - auc_76: 0.9233 - val_loss: 0.1980 - val_auc_76: 0.8647\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1969 - auc_76: 0.9288 - val_loss: 0.2225 - val_auc_76: 0.8565\n",
      "Epoch 18/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1911 - auc_76: 0.9241 - val_loss: 0.1970 - val_auc_76: 0.8648\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1879 - auc_76: 0.9294 - val_loss: 0.1838 - val_auc_76: 0.8685\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1851 - auc_76: 0.9345 - val_loss: 0.1944 - val_auc_76: 0.8658\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1859 - auc_76: 0.9347 - val_loss: 0.1952 - val_auc_76: 0.8649\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1789 - auc_76: 0.9304 - val_loss: 0.1793 - val_auc_76: 0.8660\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1769 - auc_76: 0.9324 - val_loss: 0.1899 - val_auc_76: 0.8655\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1736 - auc_76: 0.9345 - val_loss: 0.1906 - val_auc_76: 0.8656\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1713 - auc_76: 0.9347 - val_loss: 0.1839 - val_auc_76: 0.8689\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1695 - auc_76: 0.9373 - val_loss: 0.1633 - val_auc_76: 0.8612\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1679 - auc_76: 0.9406 - val_loss: 0.1776 - val_auc_76: 0.8550\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1646 - auc_76: 0.9408 - val_loss: 0.1833 - val_auc_76: 0.8711\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1616 - auc_76: 0.9396 - val_loss: 0.1788 - val_auc_76: 0.8560\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1592 - auc_76: 0.9412 - val_loss: 0.1887 - val_auc_76: 0.8572\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1573 - auc_76: 0.9419 - val_loss: 0.1848 - val_auc_76: 0.8547\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1551 - auc_76: 0.9477 - val_loss: 0.2011 - val_auc_76: 0.8529\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1535 - auc_76: 0.9427 - val_loss: 0.1854 - val_auc_76: 0.8562\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1503 - auc_76: 0.9448 - val_loss: 0.1833 - val_auc_76: 0.8562\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1495 - auc_76: 0.9435 - val_loss: 0.1778 - val_auc_76: 0.8572\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1465 - auc_76: 0.9459 - val_loss: 0.1912 - val_auc_76: 0.8538\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.6806 - auc_77: 0.5065 - val_loss: 0.5204 - val_auc_77: 0.6143\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.4993 - auc_77: 0.6825 - val_loss: 0.4290 - val_auc_77: 0.6897\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3961 - auc_77: 0.7680 - val_loss: 0.3385 - val_auc_77: 0.7460\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3358 - auc_77: 0.8258 - val_loss: 0.2877 - val_auc_77: 0.7793\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2993 - auc_77: 0.8571 - val_loss: 0.2700 - val_auc_77: 0.7980\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2748 - auc_77: 0.8728 - val_loss: 0.2586 - val_auc_77: 0.8117\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2616 - auc_77: 0.8776 - val_loss: 0.2616 - val_auc_77: 0.8147\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2479 - auc_77: 0.8851 - val_loss: 0.2621 - val_auc_77: 0.8190\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2355 - auc_77: 0.8978 - val_loss: 0.2331 - val_auc_77: 0.8318\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2256 - auc_77: 0.9027 - val_loss: 0.2228 - val_auc_77: 0.8387\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2181 - auc_77: 0.9087 - val_loss: 0.2208 - val_auc_77: 0.8394\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2095 - auc_77: 0.9118 - val_loss: 0.1908 - val_auc_77: 0.8484\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2038 - auc_77: 0.9199 - val_loss: 0.2131 - val_auc_77: 0.8470\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1971 - auc_77: 0.9211 - val_loss: 0.2253 - val_auc_77: 0.8445\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1919 - auc_77: 0.9218 - val_loss: 0.2090 - val_auc_77: 0.8517\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1870 - auc_77: 0.9244 - val_loss: 0.2185 - val_auc_77: 0.8491\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1856 - auc_77: 0.9228 - val_loss: 0.1920 - val_auc_77: 0.8422\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1787 - auc_77: 0.9327 - val_loss: 0.1771 - val_auc_77: 0.8470\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1751 - auc_77: 0.9366 - val_loss: 0.1969 - val_auc_77: 0.8464\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1699 - auc_77: 0.9371 - val_loss: 0.2019 - val_auc_77: 0.8453\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1674 - auc_77: 0.9323 - val_loss: 0.1974 - val_auc_77: 0.8469\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1625 - auc_77: 0.9377 - val_loss: 0.1962 - val_auc_77: 0.8476\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1598 - auc_77: 0.9362 - val_loss: 0.1924 - val_auc_77: 0.8500\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1567 - auc_77: 0.9389 - val_loss: 0.1687 - val_auc_77: 0.8512\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1561 - auc_77: 0.9479 - val_loss: 0.1826 - val_auc_77: 0.8518\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1497 - auc_77: 0.9426 - val_loss: 0.1845 - val_auc_77: 0.8535\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1481 - auc_77: 0.9432 - val_loss: 0.1649 - val_auc_77: 0.8572\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1452 - auc_77: 0.9462 - val_loss: 0.1705 - val_auc_77: 0.8577\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1410 - auc_77: 0.9490 - val_loss: 0.1917 - val_auc_77: 0.8525\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1389 - auc_77: 0.9466 - val_loss: 0.1727 - val_auc_77: 0.8584\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1361 - auc_77: 0.9505 - val_loss: 0.1660 - val_auc_77: 0.8584\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1333 - auc_77: 0.9508 - val_loss: 0.1603 - val_auc_77: 0.8602\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1309 - auc_77: 0.9550 - val_loss: 0.1662 - val_auc_77: 0.8604\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1281 - auc_77: 0.9535 - val_loss: 0.1751 - val_auc_77: 0.8593\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1259 - auc_77: 0.9529 - val_loss: 0.1489 - val_auc_77: 0.8469\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1234 - auc_77: 0.9565 - val_loss: 0.1621 - val_auc_77: 0.8455\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1207 - auc_77: 0.9566 - val_loss: 0.1515 - val_auc_77: 0.8481\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1192 - auc_77: 0.9589 - val_loss: 0.1604 - val_auc_77: 0.8458\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1165 - auc_77: 0.9586 - val_loss: 0.1704 - val_auc_77: 0.8480\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1141 - auc_77: 0.9599 - val_loss: 0.1648 - val_auc_77: 0.8311\n",
      "Epoch 41/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1123 - auc_77: 0.9602 - val_loss: 0.1560 - val_auc_77: 0.8346\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1108 - auc_77: 0.9598 - val_loss: 0.1660 - val_auc_77: 0.8337\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1081 - auc_77: 0.9627 - val_loss: 0.1539 - val_auc_77: 0.8345\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1056 - auc_77: 0.9633 - val_loss: 0.1390 - val_auc_77: 0.8222\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1038 - auc_77: 0.9650 - val_loss: 0.1324 - val_auc_77: 0.8232\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1019 - auc_77: 0.9649 - val_loss: 0.1405 - val_auc_77: 0.8208\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1005 - auc_77: 0.9633 - val_loss: 0.1444 - val_auc_77: 0.8205\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0982 - auc_77: 0.9671 - val_loss: 0.1396 - val_auc_77: 0.8221\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0965 - auc_77: 0.9680 - val_loss: 0.1392 - val_auc_77: 0.8225\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0950 - auc_77: 0.9663 - val_loss: 0.1377 - val_auc_77: 0.8238\n",
      "Epoch 51/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0928 - auc_77: 0.9699 - val_loss: 0.1291 - val_auc_77: 0.8275\n",
      "Epoch 52/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0914 - auc_77: 0.9698 - val_loss: 0.1371 - val_auc_77: 0.8250\n",
      "Epoch 53/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0896 - auc_77: 0.9691 - val_loss: 0.1499 - val_auc_77: 0.8239\n",
      "Epoch 54/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0885 - auc_77: 0.9705 - val_loss: 0.1272 - val_auc_77: 0.8297\n",
      "Epoch 55/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0862 - auc_77: 0.9710 - val_loss: 0.1176 - val_auc_77: 0.8342\n",
      "Epoch 56/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0865 - auc_77: 0.9726 - val_loss: 0.1180 - val_auc_77: 0.8346\n",
      "Epoch 57/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0841 - auc_77: 0.9728 - val_loss: 0.1341 - val_auc_77: 0.8285\n",
      "Epoch 58/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0820 - auc_77: 0.9722 - val_loss: 0.1379 - val_auc_77: 0.8301\n",
      "Epoch 59/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0806 - auc_77: 0.9728 - val_loss: 0.1351 - val_auc_77: 0.8294\n",
      "Epoch 60/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0792 - auc_77: 0.9730 - val_loss: 0.1236 - val_auc_77: 0.8334\n",
      "Epoch 61/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0777 - auc_77: 0.9732 - val_loss: 0.1100 - val_auc_77: 0.8371\n",
      "Epoch 62/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0885 - auc_77: 0.9732 - val_loss: 0.1242 - val_auc_77: 0.8340\n",
      "Epoch 63/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0767 - auc_77: 0.9740 - val_loss: 0.1172 - val_auc_77: 0.8351\n",
      "Epoch 64/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0751 - auc_77: 0.9758 - val_loss: 0.1311 - val_auc_77: 0.8320\n",
      "Epoch 65/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0738 - auc_77: 0.9752 - val_loss: 0.1073 - val_auc_77: 0.8386\n",
      "Epoch 66/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0756 - auc_77: 0.9757 - val_loss: 0.1177 - val_auc_77: 0.8367\n",
      "Epoch 67/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0719 - auc_77: 0.9768 - val_loss: 0.1231 - val_auc_77: 0.8361\n",
      "Epoch 68/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0709 - auc_77: 0.9772 - val_loss: 0.1210 - val_auc_77: 0.8352\n",
      "Epoch 69/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0700 - auc_77: 0.9768 - val_loss: 0.1199 - val_auc_77: 0.8362\n",
      "Epoch 70/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0690 - auc_77: 0.9780 - val_loss: 0.1288 - val_auc_77: 0.8347\n",
      "Epoch 71/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0684 - auc_77: 0.9775 - val_loss: 0.1154 - val_auc_77: 0.8374\n",
      "Epoch 72/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0685 - auc_77: 0.9792 - val_loss: 0.1266 - val_auc_77: 0.8364\n",
      "Epoch 73/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0675 - auc_77: 0.9765 - val_loss: 0.1225 - val_auc_77: 0.8377\n",
      "Epoch 74/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0667 - auc_77: 0.9768 - val_loss: 0.1217 - val_auc_77: 0.8385\n",
      "Epoch 75/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0662 - auc_77: 0.9777 - val_loss: 0.1072 - val_auc_77: 0.8418\n",
      "Epoch 76/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0646 - auc_77: 0.9778 - val_loss: 0.1177 - val_auc_77: 0.8403\n",
      "Epoch 77/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0637 - auc_77: 0.9783 - val_loss: 0.1120 - val_auc_77: 0.8405\n",
      "Epoch 78/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0626 - auc_77: 0.9797 - val_loss: 0.1070 - val_auc_77: 0.8417\n",
      "Epoch 79/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0618 - auc_77: 0.9787 - val_loss: 0.1088 - val_auc_77: 0.8418\n",
      "Epoch 80/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0614 - auc_77: 0.9797 - val_loss: 0.1176 - val_auc_77: 0.8401\n",
      "Epoch 81/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0604 - auc_77: 0.9788 - val_loss: 0.1118 - val_auc_77: 0.8405\n",
      "Epoch 82/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0595 - auc_77: 0.9797 - val_loss: 0.1010 - val_auc_77: 0.8429\n",
      "Epoch 83/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0591 - auc_77: 0.9800 - val_loss: 0.0950 - val_auc_77: 0.8436\n",
      "Epoch 84/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0694 - auc_77: 0.9807 - val_loss: 0.1007 - val_auc_77: 0.8416\n",
      "Epoch 85/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0594 - auc_77: 0.9810 - val_loss: 0.1158 - val_auc_77: 0.8422\n",
      "Epoch 86/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0578 - auc_77: 0.9798 - val_loss: 0.1105 - val_auc_77: 0.8418\n",
      "Epoch 87/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0569 - auc_77: 0.9808 - val_loss: 0.1139 - val_auc_77: 0.8416\n",
      "Epoch 88/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0562 - auc_77: 0.9813 - val_loss: 0.1149 - val_auc_77: 0.8415\n",
      "Epoch 89/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0559 - auc_77: 0.9807 - val_loss: 0.1199 - val_auc_77: 0.8413\n",
      "Epoch 90/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0550 - auc_77: 0.9818 - val_loss: 0.1112 - val_auc_77: 0.8426\n",
      "Epoch 91/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0542 - auc_77: 0.9815 - val_loss: 0.1023 - val_auc_77: 0.8442\n",
      "Epoch 92/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0550 - auc_77: 0.9827 - val_loss: 0.1026 - val_auc_77: 0.8448\n",
      "Epoch 93/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0528 - auc_77: 0.9825 - val_loss: 0.1072 - val_auc_77: 0.8435\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 2s 21ms/step - loss: 0.6693 - auc_78: 0.5228 - val_loss: 0.4761 - val_auc_78: 0.5876\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.5052 - auc_78: 0.6864 - val_loss: 0.3718 - val_auc_78: 0.7160\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3935 - auc_78: 0.7987 - val_loss: 0.3292 - val_auc_78: 0.7718\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3274 - auc_78: 0.8507 - val_loss: 0.3053 - val_auc_78: 0.7773\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2904 - auc_78: 0.8643 - val_loss: 0.2675 - val_auc_78: 0.8026\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2660 - auc_78: 0.8849 - val_loss: 0.2868 - val_auc_78: 0.8040\n",
      "Epoch 7/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2489 - auc_78: 0.8919 - val_loss: 0.2233 - val_auc_78: 0.8291\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2371 - auc_78: 0.9030 - val_loss: 0.2075 - val_auc_78: 0.8388\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2278 - auc_78: 0.9093 - val_loss: 0.2253 - val_auc_78: 0.8375\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2192 - auc_78: 0.9105 - val_loss: 0.2060 - val_auc_78: 0.8478\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2132 - auc_78: 0.9161 - val_loss: 0.1880 - val_auc_78: 0.8539\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2062 - auc_78: 0.9192 - val_loss: 0.2274 - val_auc_78: 0.8430\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2009 - auc_78: 0.9198 - val_loss: 0.2151 - val_auc_78: 0.8469\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1958 - auc_78: 0.9226 - val_loss: 0.1938 - val_auc_78: 0.8558\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1917 - auc_78: 0.9284 - val_loss: 0.2018 - val_auc_78: 0.8551\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1877 - auc_78: 0.9260 - val_loss: 0.1949 - val_auc_78: 0.8579\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1837 - auc_78: 0.9341 - val_loss: 0.2143 - val_auc_78: 0.8532\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1850 - auc_78: 0.9278 - val_loss: 0.2164 - val_auc_78: 0.8541\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1772 - auc_78: 0.9322 - val_loss: 0.2115 - val_auc_78: 0.8420\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1731 - auc_78: 0.9350 - val_loss: 0.1958 - val_auc_78: 0.8455\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1692 - auc_78: 0.9349 - val_loss: 0.1904 - val_auc_78: 0.8481\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.5606 - auc_79: 0.6254 - val_loss: 0.4279 - val_auc_79: 0.6867\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.4139 - auc_79: 0.7674 - val_loss: 0.3668 - val_auc_79: 0.7587\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3368 - auc_79: 0.8268 - val_loss: 0.2970 - val_auc_79: 0.7854\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2966 - auc_79: 0.8529 - val_loss: 0.2659 - val_auc_79: 0.8081\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2703 - auc_79: 0.8776 - val_loss: 0.2654 - val_auc_79: 0.8171\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2522 - auc_79: 0.8852 - val_loss: 0.2614 - val_auc_79: 0.8237\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2384 - auc_79: 0.8946 - val_loss: 0.2133 - val_auc_79: 0.8399\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2277 - auc_79: 0.9064 - val_loss: 0.2568 - val_auc_79: 0.8357\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2200 - auc_79: 0.9055 - val_loss: 0.2069 - val_auc_79: 0.8505\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2106 - auc_79: 0.9147 - val_loss: 0.2152 - val_auc_79: 0.8500\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2035 - auc_79: 0.9192 - val_loss: 0.2089 - val_auc_79: 0.8537\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1971 - auc_79: 0.9208 - val_loss: 0.2232 - val_auc_79: 0.8521\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1915 - auc_79: 0.9213 - val_loss: 0.1614 - val_auc_79: 0.8715\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1904 - auc_79: 0.9325 - val_loss: 0.1828 - val_auc_79: 0.8637\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1821 - auc_79: 0.9313 - val_loss: 0.1922 - val_auc_79: 0.8613\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1775 - auc_79: 0.9327 - val_loss: 0.2011 - val_auc_79: 0.8585\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1735 - auc_79: 0.9358 - val_loss: 0.2065 - val_auc_79: 0.8574\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1692 - auc_79: 0.9368 - val_loss: 0.1866 - val_auc_79: 0.8504\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1654 - auc_79: 0.9394 - val_loss: 0.1829 - val_auc_79: 0.8519\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1621 - auc_79: 0.9401 - val_loss: 0.1972 - val_auc_79: 0.8470\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1576 - auc_79: 0.9422 - val_loss: 0.1953 - val_auc_79: 0.8488\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1547 - auc_79: 0.9425 - val_loss: 0.1805 - val_auc_79: 0.8527\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1513 - auc_79: 0.9441 - val_loss: 0.1719 - val_auc_79: 0.8530\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.5880 - auc_80: 0.5459 - val_loss: 0.4663 - val_auc_80: 0.6695\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.4353 - auc_80: 0.7370 - val_loss: 0.3640 - val_auc_80: 0.7648\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3419 - auc_80: 0.8289 - val_loss: 0.3008 - val_auc_80: 0.7919\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2994 - auc_80: 0.8598 - val_loss: 0.2868 - val_auc_80: 0.8063\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2782 - auc_80: 0.8843 - val_loss: 0.2810 - val_auc_80: 0.8138\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2616 - auc_80: 0.8901 - val_loss: 0.3015 - val_auc_80: 0.8206\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2509 - auc_80: 0.8901 - val_loss: 0.2439 - val_auc_80: 0.8348\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2402 - auc_80: 0.8998 - val_loss: 0.2487 - val_auc_80: 0.8369\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2316 - auc_80: 0.9064 - val_loss: 0.2836 - val_auc_80: 0.8337\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2295 - auc_80: 0.9017 - val_loss: 0.2566 - val_auc_80: 0.8392\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2210 - auc_80: 0.9100 - val_loss: 0.2323 - val_auc_80: 0.8473\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2150 - auc_80: 0.91 - 1s 14ms/step - loss: 0.2150 - auc_80: 0.9161 - val_loss: 0.2453 - val_auc_80: 0.8428\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2101 - auc_80: 0.9179 - val_loss: 0.2158 - val_auc_80: 0.8533\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2086 - auc_80: 0.9257 - val_loss: 0.2331 - val_auc_80: 0.8509\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2015 - auc_80: 0.9211 - val_loss: 0.2116 - val_auc_80: 0.8599\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1978 - auc_80: 0.9247 - val_loss: 0.2056 - val_auc_80: 0.8616\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1956 - auc_80: 0.9256 - val_loss: 0.1937 - val_auc_80: 0.8632\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1916 - auc_80: 0.9298 - val_loss: 0.2070 - val_auc_80: 0.8593\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1866 - auc_80: 0.9285 - val_loss: 0.1964 - val_auc_80: 0.8642\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1833 - auc_80: 0.9313 - val_loss: 0.2074 - val_auc_80: 0.8618\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1840 - auc_80: 0.9263 - val_loss: 0.1991 - val_auc_80: 0.8618\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1770 - auc_80: 0.9357 - val_loss: 0.2001 - val_auc_80: 0.8617\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1742 - auc_80: 0.9347 - val_loss: 0.2044 - val_auc_80: 0.8618\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1703 - auc_80: 0.9371 - val_loss: 0.2075 - val_auc_80: 0.8622\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1684 - auc_80: 0.9352 - val_loss: 0.2115 - val_auc_80: 0.8621\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1664 - auc_80: 0.9354 - val_loss: 0.1836 - val_auc_80: 0.8711\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1616 - auc_80: 0.9411 - val_loss: 0.1931 - val_auc_80: 0.8679\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1589 - auc_80: 0.94 - 1s 14ms/step - loss: 0.1589 - auc_80: 0.9428 - val_loss: 0.1918 - val_auc_80: 0.8699\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1560 - auc_80: 0.9435 - val_loss: 0.1978 - val_auc_80: 0.8665\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1541 - auc_80: 0.9427 - val_loss: 0.1820 - val_auc_80: 0.8709\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1511 - auc_80: 0.9448 - val_loss: 0.1822 - val_auc_80: 0.8717\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1483 - auc_80: 0.9496 - val_loss: 0.1886 - val_auc_80: 0.8707\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1474 - auc_80: 0.9469 - val_loss: 0.1720 - val_auc_80: 0.8431\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1447 - auc_80: 0.9512 - val_loss: 0.1644 - val_auc_80: 0.8428\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1413 - auc_80: 0.9508 - val_loss: 0.1668 - val_auc_80: 0.8456\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1395 - auc_80: 0.9506 - val_loss: 0.1612 - val_auc_80: 0.8461\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1366 - auc_80: 0.9543 - val_loss: 0.1838 - val_auc_80: 0.8431\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1349 - auc_80: 0.9535 - val_loss: 0.1844 - val_auc_80: 0.8442\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1328 - auc_80: 0.9549 - val_loss: 0.1824 - val_auc_80: 0.8447\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1305 - auc_80: 0.9555 - val_loss: 0.1902 - val_auc_80: 0.8434\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1288 - auc_80: 0.9554 - val_loss: 0.1773 - val_auc_80: 0.8451\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1269 - auc_80: 0.9558 - val_loss: 0.1735 - val_auc_80: 0.8459\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1247 - auc_80: 0.9570 - val_loss: 0.1702 - val_auc_80: 0.8451\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1231 - auc_80: 0.9582 - val_loss: 0.1690 - val_auc_80: 0.8458\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1211 - auc_80: 0.9574 - val_loss: 0.1665 - val_auc_80: 0.8471\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1203 - auc_80: 0.9578 - val_loss: 0.1580 - val_auc_80: 0.8481\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1190 - auc_80: 0.9619 - val_loss: 0.1619 - val_auc_80: 0.8479\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1161 - auc_80: 0.9593 - val_loss: 0.1484 - val_auc_80: 0.8514\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1143 - auc_80: 0.9612 - val_loss: 0.1721 - val_auc_80: 0.8459\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1155 - auc_80: 0.9596 - val_loss: 0.1786 - val_auc_80: 0.8455\n",
      "Epoch 51/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1133 - auc_80: 0.9581 - val_loss: 0.1449 - val_auc_80: 0.8537\n",
      "Epoch 52/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1112 - auc_80: 0.9648 - val_loss: 0.1535 - val_auc_80: 0.8518\n",
      "Epoch 53/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1084 - auc_80: 0.9626 - val_loss: 0.1504 - val_auc_80: 0.8341\n",
      "Epoch 54/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1075 - auc_80: 0.9635 - val_loss: 0.1676 - val_auc_80: 0.8497\n",
      "Epoch 55/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1056 - auc_80: 0.9642 - val_loss: 0.1532 - val_auc_80: 0.8335\n",
      "Epoch 56/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1040 - auc_80: 0.9647 - val_loss: 0.1507 - val_auc_80: 0.8346\n",
      "Epoch 57/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1029 - auc_80: 0.9645 - val_loss: 0.1493 - val_auc_80: 0.8362\n",
      "Epoch 58/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1013 - auc_80: 0.9670 - val_loss: 0.1443 - val_auc_80: 0.8369\n",
      "Epoch 59/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1002 - auc_80: 0.9668 - val_loss: 0.1511 - val_auc_80: 0.8358\n",
      "Epoch 60/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0999 - auc_80: 0.9648 - val_loss: 0.1543 - val_auc_80: 0.8357\n",
      "Epoch 61/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0975 - auc_80: 0.9668 - val_loss: 0.1351 - val_auc_80: 0.8389\n",
      "Epoch 62/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0962 - auc_80: 0.9687 - val_loss: 0.1365 - val_auc_80: 0.8385\n",
      "Epoch 63/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0954 - auc_80: 0.9678 - val_loss: 0.1332 - val_auc_80: 0.8402\n",
      "Epoch 64/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0941 - auc_80: 0.9688 - val_loss: 0.1340 - val_auc_80: 0.8407\n",
      "Epoch 65/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0925 - auc_80: 0.9705 - val_loss: 0.1486 - val_auc_80: 0.8383\n",
      "Epoch 66/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0919 - auc_80: 0.9680 - val_loss: 0.1406 - val_auc_80: 0.8394\n",
      "Epoch 67/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0907 - auc_80: 0.9702 - val_loss: 0.1262 - val_auc_80: 0.8434\n",
      "Epoch 68/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0899 - auc_80: 0.9702 - val_loss: 0.1251 - val_auc_80: 0.8450\n",
      "Epoch 69/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0884 - auc_80: 0.9717 - val_loss: 0.1331 - val_auc_80: 0.8432\n",
      "Epoch 70/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0874 - auc_80: 0.9713 - val_loss: 0.1349 - val_auc_80: 0.8427\n",
      "Epoch 71/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0870 - auc_80: 0.9717 - val_loss: 0.1423 - val_auc_80: 0.8414\n",
      "Epoch 72/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0855 - auc_80: 0.9722 - val_loss: 0.1263 - val_auc_80: 0.8454\n",
      "Epoch 73/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0863 - auc_80: 0.9717 - val_loss: 0.1307 - val_auc_80: 0.8453\n",
      "Epoch 74/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0838 - auc_80: 0.9728 - val_loss: 0.1315 - val_auc_80: 0.8439\n",
      "Epoch 75/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0821 - auc_80: 0.9730 - val_loss: 0.1228 - val_auc_80: 0.8262\n",
      "Epoch 76/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0814 - auc_80: 0.9737 - val_loss: 0.1240 - val_auc_80: 0.8253\n",
      "Epoch 77/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0806 - auc_80: 0.9735 - val_loss: 0.1333 - val_auc_80: 0.8443\n",
      "Epoch 78/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0801 - auc_80: 0.9740 - val_loss: 0.1335 - val_auc_80: 0.8452\n",
      "Epoch 79/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0794 - auc_80: 0.9737 - val_loss: 0.1421 - val_auc_80: 0.8463\n",
      "Epoch 80/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0820 - auc_80: 0.9730 - val_loss: 0.1506 - val_auc_80: 0.8455\n",
      "Epoch 81/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0781 - auc_80: 0.9747 - val_loss: 0.1201 - val_auc_80: 0.8474\n",
      "Epoch 82/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0764 - auc_80: 0.9767 - val_loss: 0.1254 - val_auc_80: 0.8462\n",
      "Epoch 83/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0757 - auc_80: 0.9763 - val_loss: 0.1272 - val_auc_80: 0.8464\n",
      "Epoch 84/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0747 - auc_80: 0.9762 - val_loss: 0.1194 - val_auc_80: 0.8278\n",
      "Epoch 85/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0739 - auc_80: 0.9768 - val_loss: 0.1118 - val_auc_80: 0.8310\n",
      "Epoch 86/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0731 - auc_80: 0.9770 - val_loss: 0.1164 - val_auc_80: 0.8296\n",
      "Epoch 87/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0724 - auc_80: 0.9772 - val_loss: 0.1189 - val_auc_80: 0.8296\n",
      "Epoch 88/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0720 - auc_80: 0.9763 - val_loss: 0.1211 - val_auc_80: 0.8294\n",
      "Epoch 89/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0708 - auc_80: 0.9778 - val_loss: 0.1176 - val_auc_80: 0.8306\n",
      "Epoch 90/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0702 - auc_80: 0.9778 - val_loss: 0.1255 - val_auc_80: 0.8282\n",
      "Epoch 91/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0696 - auc_80: 0.9770 - val_loss: 0.1195 - val_auc_80: 0.8305\n",
      "Epoch 92/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0687 - auc_80: 0.9778 - val_loss: 0.1165 - val_auc_80: 0.8114\n",
      "Epoch 93/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0680 - auc_80: 0.9782 - val_loss: 0.1121 - val_auc_80: 0.7919\n",
      "Epoch 94/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0677 - auc_80: 0.9783 - val_loss: 0.1222 - val_auc_80: 0.8101\n",
      "Epoch 95/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0668 - auc_80: 0.9792 - val_loss: 0.1266 - val_auc_80: 0.8104\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.6385 - auc_81: 0.5462 - val_loss: 0.5042 - val_auc_81: 0.6415\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.4771 - auc_81: 0.7199 - val_loss: 0.3941 - val_auc_81: 0.7534\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3876 - auc_81: 0.8040 - val_loss: 0.3416 - val_auc_81: 0.8016\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3397 - auc_81: 0.8385 - val_loss: 0.3031 - val_auc_81: 0.8309\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3143 - auc_81: 0.8538 - val_loss: 0.2570 - val_auc_81: 0.8502\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2968 - auc_81: 0.8698 - val_loss: 0.2467 - val_auc_81: 0.8645\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2840 - auc_81: 0.8801 - val_loss: 0.2380 - val_auc_81: 0.8695\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2731 - auc_81: 0.8824 - val_loss: 0.2324 - val_auc_81: 0.8760\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2654 - auc_81: 0.8913 - val_loss: 0.2512 - val_auc_81: 0.8712\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2576 - auc_81: 0.8907 - val_loss: 0.2033 - val_auc_81: 0.8835\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2515 - auc_81: 0.8954 - val_loss: 0.2075 - val_auc_81: 0.8822\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2451 - auc_81: 0.9020 - val_loss: 0.2424 - val_auc_81: 0.8777\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2413 - auc_81: 0.9008 - val_loss: 0.2000 - val_auc_81: 0.8855\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2352 - auc_81: 0.9065 - val_loss: 0.2141 - val_auc_81: 0.8862\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2318 - auc_81: 0.9075 - val_loss: 0.1840 - val_auc_81: 0.8938\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2271 - auc_81: 0.9081 - val_loss: 0.1969 - val_auc_81: 0.8882\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2230 - auc_81: 0.9101 - val_loss: 0.1910 - val_auc_81: 0.8921\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2198 - auc_81: 0.9105 - val_loss: 0.1825 - val_auc_81: 0.8947\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2156 - auc_81: 0.9153 - val_loss: 0.1992 - val_auc_81: 0.8899\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2126 - auc_81: 0.9174 - val_loss: 0.1746 - val_auc_81: 0.8994\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2090 - auc_81: 0.9187 - val_loss: 0.1866 - val_auc_81: 0.8952\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2059 - auc_81: 0.9193 - val_loss: 0.1778 - val_auc_81: 0.8968\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2030 - auc_81: 0.9206 - val_loss: 0.1682 - val_auc_81: 0.8996\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2010 - auc_81: 0.9248 - val_loss: 0.1909 - val_auc_81: 0.8926\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1979 - auc_81: 0.9214 - val_loss: 0.1555 - val_auc_81: 0.9003\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1976 - auc_81: 0.9272 - val_loss: 0.1711 - val_auc_81: 0.8967\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1921 - auc_81: 0.9237 - val_loss: 0.1687 - val_auc_81: 0.8983\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1894 - auc_81: 0.9268 - val_loss: 0.1676 - val_auc_81: 0.8993\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1870 - auc_81: 0.9272 - val_loss: 0.1474 - val_auc_81: 0.8971\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1879 - auc_81: 0.9316 - val_loss: 0.1751 - val_auc_81: 0.8967\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1839 - auc_81: 0.9294 - val_loss: 0.1986 - val_auc_81: 0.8904\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1834 - auc_81: 0.9283 - val_loss: 0.1801 - val_auc_81: 0.8964\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1787 - auc_81: 0.9315 - val_loss: 0.1759 - val_auc_81: 0.8981\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1765 - auc_81: 0.9331 - val_loss: 0.1474 - val_auc_81: 0.8991\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1741 - auc_81: 0.9368 - val_loss: 0.1767 - val_auc_81: 0.8977\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1715 - auc_81: 0.9360 - val_loss: 0.1545 - val_auc_81: 0.8967\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1698 - auc_81: 0.9360 - val_loss: 0.1590 - val_auc_81: 0.8950\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1676 - auc_81: 0.9391 - val_loss: 0.1724 - val_auc_81: 0.8974\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1661 - auc_81: 0.9384 - val_loss: 0.1691 - val_auc_81: 0.8988\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.5809 - auc_82: 0.5695 - val_loss: 0.4572 - val_auc_82: 0.6686\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.4298 - auc_82: 0.7435 - val_loss: 0.3520 - val_auc_82: 0.7835\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3489 - auc_82: 0.8232 - val_loss: 0.3008 - val_auc_82: 0.8288\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3126 - auc_82: 0.8525 - val_loss: 0.2800 - val_auc_82: 0.8500\n",
      "Epoch 5/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2948 - auc_82: 0.8623 - val_loss: 0.2696 - val_auc_82: 0.8568\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2810 - auc_82: 0.8748 - val_loss: 0.2489 - val_auc_82: 0.8706\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2689 - auc_82: 0.8842 - val_loss: 0.2038 - val_auc_82: 0.8929\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2605 - auc_82: 0.8924 - val_loss: 0.2462 - val_auc_82: 0.8773\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2537 - auc_82: 0.8932 - val_loss: 0.2042 - val_auc_82: 0.8950\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2511 - auc_82: 0.8991 - val_loss: 0.1750 - val_auc_82: 0.9039\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2428 - auc_82: 0.9039 - val_loss: 0.2024 - val_auc_82: 0.8910\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2357 - auc_82: 0.9047 - val_loss: 0.1927 - val_auc_82: 0.8952\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2308 - auc_82: 0.9077 - val_loss: 0.1799 - val_auc_82: 0.9022\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2262 - auc_82: 0.9116 - val_loss: 0.1911 - val_auc_82: 0.8987\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2214 - auc_82: 0.9121 - val_loss: 0.2071 - val_auc_82: 0.8905\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2166 - auc_82: 0.9134 - val_loss: 0.1900 - val_auc_82: 0.8959\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2109 - auc_82: 0.9150 - val_loss: 0.1772 - val_auc_82: 0.8998\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2060 - auc_82: 0.9185 - val_loss: 0.1758 - val_auc_82: 0.9008\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2013 - auc_82: 0.9247 - val_loss: 0.1856 - val_auc_82: 0.8971\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1978 - auc_82: 0.9208 - val_loss: 0.1878 - val_auc_82: 0.8962\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.6658 - auc_83: 0.5005 - val_loss: 0.5691 - val_auc_83: 0.5164\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.5007 - auc_83: 0.6410 - val_loss: 0.4365 - val_auc_83: 0.7367\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3987 - auc_83: 0.7889 - val_loss: 0.3357 - val_auc_83: 0.8071\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3446 - auc_83: 0.8322 - val_loss: 0.3157 - val_auc_83: 0.8286\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3141 - auc_83: 0.8503 - val_loss: 0.2606 - val_auc_83: 0.8605\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2950 - auc_83: 0.8724 - val_loss: 0.2537 - val_auc_83: 0.8660\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2821 - auc_83: 0.8793 - val_loss: 0.2179 - val_auc_83: 0.8849\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2732 - auc_83: 0.8877 - val_loss: 0.2118 - val_auc_83: 0.8888\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2638 - auc_83: 0.8901 - val_loss: 0.2168 - val_auc_83: 0.8882\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2572 - auc_83: 0.8962 - val_loss: 0.2368 - val_auc_83: 0.8808\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2551 - auc_83: 0.8909 - val_loss: 0.2279 - val_auc_83: 0.8859\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2456 - auc_83: 0.9005 - val_loss: 0.1981 - val_auc_83: 0.8929\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2422 - auc_83: 0.9064 - val_loss: 0.2091 - val_auc_83: 0.8892\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2371 - auc_83: 0.9061 - val_loss: 0.1877 - val_auc_83: 0.9003\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2334 - auc_83: 0.9095 - val_loss: 0.1938 - val_auc_83: 0.8981\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2296 - auc_83: 0.9118 - val_loss: 0.2104 - val_auc_83: 0.8917\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2263 - auc_83: 0.9119 - val_loss: 0.1851 - val_auc_83: 0.9037\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2219 - auc_83: 0.9142 - val_loss: 0.2036 - val_auc_83: 0.8956\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2182 - auc_83: 0.9180 - val_loss: 0.2101 - val_auc_83: 0.8939\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2143 - auc_83: 0.9175 - val_loss: 0.1968 - val_auc_83: 0.9005\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2109 - auc_83: 0.9206 - val_loss: 0.1597 - val_auc_83: 0.9019\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2076 - auc_83: 0.9230 - val_loss: 0.1690 - val_auc_83: 0.8989\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2036 - auc_83: 0.9227 - val_loss: 0.1794 - val_auc_83: 0.8961\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1997 - auc_83: 0.9237 - val_loss: 0.1799 - val_auc_83: 0.8956\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1967 - auc_83: 0.9232 - val_loss: 0.1582 - val_auc_83: 0.9010\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1942 - auc_83: 0.9280 - val_loss: 0.1572 - val_auc_83: 0.9021\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1922 - auc_83: 0.9310 - val_loss: 0.1503 - val_auc_83: 0.9043\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1882 - auc_83: 0.9290 - val_loss: 0.1528 - val_auc_83: 0.9037\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1847 - auc_83: 0.9309 - val_loss: 0.1519 - val_auc_83: 0.9006\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1824 - auc_83: 0.9315 - val_loss: 0.1872 - val_auc_83: 0.8915\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1808 - auc_83: 0.9294 - val_loss: 0.1553 - val_auc_83: 0.8991\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1763 - auc_83: 0.9359 - val_loss: 0.1670 - val_auc_83: 0.8990\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1735 - auc_83: 0.9360 - val_loss: 0.1548 - val_auc_83: 0.9015\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1711 - auc_83: 0.9362 - val_loss: 0.1590 - val_auc_83: 0.9007\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1682 - auc_83: 0.9367 - val_loss: 0.1635 - val_auc_83: 0.8989\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1664 - auc_83: 0.9357 - val_loss: 0.1724 - val_auc_83: 0.8997\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1638 - auc_83: 0.9379 - val_loss: 0.1547 - val_auc_83: 0.9014\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.6189 - auc_84: 0.5567 - val_loss: 0.4534 - val_auc_84: 0.6902\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.4297 - auc_84: 0.7544 - val_loss: 0.3608 - val_auc_84: 0.7968\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3565 - auc_84: 0.8196 - val_loss: 0.3162 - val_auc_84: 0.8283\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3197 - auc_84: 0.8418 - val_loss: 0.2711 - val_auc_84: 0.8579\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2968 - auc_84: 0.8652 - val_loss: 0.2349 - val_auc_84: 0.8794\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2866 - auc_84: 0.8773 - val_loss: 0.2187 - val_auc_84: 0.8877\n",
      "Epoch 7/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2735 - auc_84: 0.8781 - val_loss: 0.1945 - val_auc_84: 0.9002\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2641 - auc_84: 0.8876 - val_loss: 0.2185 - val_auc_84: 0.8913\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2566 - auc_84: 0.8916 - val_loss: 0.2085 - val_auc_84: 0.8954\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2496 - auc_84: 0.8947 - val_loss: 0.2132 - val_auc_84: 0.8950\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2432 - auc_84: 0.8995 - val_loss: 0.1936 - val_auc_84: 0.9040\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2373 - auc_84: 0.9033 - val_loss: 0.1937 - val_auc_84: 0.9049\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2332 - auc_84: 0.9066 - val_loss: 0.2027 - val_auc_84: 0.9016\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2276 - auc_84: 0.9050 - val_loss: 0.1753 - val_auc_84: 0.9103\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2228 - auc_84: 0.9088 - val_loss: 0.1930 - val_auc_84: 0.9043\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2179 - auc_84: 0.9107 - val_loss: 0.1978 - val_auc_84: 0.9021\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2148 - auc_84: 0.9085 - val_loss: 0.1561 - val_auc_84: 0.9132\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2108 - auc_84: 0.9175 - val_loss: 0.1741 - val_auc_84: 0.9073\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2047 - auc_84: 0.9183 - val_loss: 0.1470 - val_auc_84: 0.9175\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2048 - auc_84: 0.9240 - val_loss: 0.1603 - val_auc_84: 0.9138\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1973 - auc_84: 0.9219 - val_loss: 0.1551 - val_auc_84: 0.9159\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1939 - auc_84: 0.9250 - val_loss: 0.1636 - val_auc_84: 0.9123\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1908 - auc_84: 0.9261 - val_loss: 0.1899 - val_auc_84: 0.9049\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1918 - auc_84: 0.9206 - val_loss: 0.1658 - val_auc_84: 0.9116\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1832 - auc_84: 0.9309 - val_loss: 0.1696 - val_auc_84: 0.9099\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1810 - auc_84: 0.9289 - val_loss: 0.1708 - val_auc_84: 0.9089\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1785 - auc_84: 0.9318 - val_loss: 0.1798 - val_auc_84: 0.9080\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1738 - auc_84: 0.9323 - val_loss: 0.1491 - val_auc_84: 0.9171\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1696 - auc_84: 0.9370 - val_loss: 0.1502 - val_auc_84: 0.9167\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.5404 - auc_85: 0.6323 - val_loss: 0.4093 - val_auc_85: 0.7328\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3927 - auc_85: 0.7824 - val_loss: 0.3180 - val_auc_85: 0.7953\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3342 - auc_85: 0.8374 - val_loss: 0.2626 - val_auc_85: 0.8364\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3004 - auc_85: 0.8665 - val_loss: 0.2906 - val_auc_85: 0.8352\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2809 - auc_85: 0.8706 - val_loss: 0.2452 - val_auc_85: 0.8608\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2673 - auc_85: 0.8816 - val_loss: 0.2378 - val_auc_85: 0.8677\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2552 - auc_85: 0.8893 - val_loss: 0.2276 - val_auc_85: 0.8737\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2472 - auc_85: 0.8952 - val_loss: 0.2298 - val_auc_85: 0.8759\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2398 - auc_85: 0.8988 - val_loss: 0.2358 - val_auc_85: 0.8745\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2312 - auc_85: 0.9073 - val_loss: 0.2189 - val_auc_85: 0.8806\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2264 - auc_85: 0.9062 - val_loss: 0.1850 - val_auc_85: 0.8928\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2191 - auc_85: 0.9142 - val_loss: 0.2069 - val_auc_85: 0.8884\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2141 - auc_85: 0.9139 - val_loss: 0.1753 - val_auc_85: 0.8963\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2078 - auc_85: 0.9183 - val_loss: 0.1738 - val_auc_85: 0.8974\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2024 - auc_85: 0.9207 - val_loss: 0.1822 - val_auc_85: 0.8964\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1974 - auc_85: 0.9230 - val_loss: 0.1797 - val_auc_85: 0.8982\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1950 - auc_85: 0.9259 - val_loss: 0.1538 - val_auc_85: 0.9026\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1888 - auc_85: 0.9287 - val_loss: 0.1638 - val_auc_85: 0.9026\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1836 - auc_85: 0.9296 - val_loss: 0.1562 - val_auc_85: 0.9035\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1799 - auc_85: 0.9338 - val_loss: 0.1551 - val_auc_85: 0.9028\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1758 - auc_85: 0.9312 - val_loss: 0.1582 - val_auc_85: 0.9053\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1711 - auc_85: 0.9351 - val_loss: 0.1674 - val_auc_85: 0.9025\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1788 - auc_85: 0.9276 - val_loss: 0.1788 - val_auc_85: 0.8991\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1652 - auc_85: 0.9376 - val_loss: 0.1530 - val_auc_85: 0.9044\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1604 - auc_85: 0.9417 - val_loss: 0.1514 - val_auc_85: 0.9057\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1578 - auc_85: 0.9412 - val_loss: 0.1352 - val_auc_85: 0.9111\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1565 - auc_85: 0.9455 - val_loss: 0.1385 - val_auc_85: 0.9096\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1516 - auc_85: 0.9444 - val_loss: 0.1346 - val_auc_85: 0.9112\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1482 - auc_85: 0.9473 - val_loss: 0.1538 - val_auc_85: 0.9053\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1459 - auc_85: 0.9468 - val_loss: 0.1401 - val_auc_85: 0.9105\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1430 - auc_85: 0.9489 - val_loss: 0.1339 - val_auc_85: 0.9086\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1401 - auc_85: 0.9498 - val_loss: 0.1413 - val_auc_85: 0.9085\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1376 - auc_85: 0.9510 - val_loss: 0.1489 - val_auc_85: 0.9077\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1349 - auc_85: 0.9518 - val_loss: 0.1209 - val_auc_85: 0.9130\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1332 - auc_85: 0.9528 - val_loss: 0.1308 - val_auc_85: 0.9101\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1299 - auc_85: 0.9510 - val_loss: 0.1072 - val_auc_85: 0.9198\n",
      "Epoch 37/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1330 - auc_85: 0.9553 - val_loss: 0.1250 - val_auc_85: 0.9126\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1250 - auc_85: 0.9536 - val_loss: 0.1222 - val_auc_85: 0.9142\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1229 - auc_85: 0.9544 - val_loss: 0.1317 - val_auc_85: 0.9103\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1219 - auc_85: 0.9520 - val_loss: 0.1407 - val_auc_85: 0.9079\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1182 - auc_85: 0.9558 - val_loss: 0.1334 - val_auc_85: 0.9110\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1170 - auc_85: 0.9566 - val_loss: 0.1251 - val_auc_85: 0.9142\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1164 - auc_85: 0.9563 - val_loss: 0.1233 - val_auc_85: 0.9145\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1132 - auc_85: 0.9584 - val_loss: 0.1209 - val_auc_85: 0.9164\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1125 - auc_85: 0.9577 - val_loss: 0.1351 - val_auc_85: 0.9112\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1092 - auc_85: 0.9582 - val_loss: 0.1289 - val_auc_85: 0.9157\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 2s 20ms/step - loss: 0.5361 - auc_86: 0.6398 - val_loss: 0.4310 - val_auc_86: 0.6751\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.4033 - auc_86: 0.7834 - val_loss: 0.3371 - val_auc_86: 0.7726\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3373 - auc_86: 0.8441 - val_loss: 0.2911 - val_auc_86: 0.8117\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2950 - auc_86: 0.8689 - val_loss: 0.2878 - val_auc_86: 0.8218\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2663 - auc_86: 0.8809 - val_loss: 0.2485 - val_auc_86: 0.8315\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2444 - auc_86: 0.9029 - val_loss: 0.2351 - val_auc_86: 0.8407\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2339 - auc_86: 0.9154 - val_loss: 0.2290 - val_auc_86: 0.8449\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2192 - auc_86: 0.9135 - val_loss: 0.2113 - val_auc_86: 0.8522\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2095 - auc_86: 0.9238 - val_loss: 0.2028 - val_auc_86: 0.8571\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2011 - auc_86: 0.9287 - val_loss: 0.2140 - val_auc_86: 0.8548\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1933 - auc_86: 0.9305 - val_loss: 0.2006 - val_auc_86: 0.8626\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1865 - auc_86: 0.9347 - val_loss: 0.1745 - val_auc_86: 0.8554\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1830 - auc_86: 0.9392 - val_loss: 0.1985 - val_auc_86: 0.8484\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1750 - auc_86: 0.9404 - val_loss: 0.1963 - val_auc_86: 0.8476\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1702 - auc_86: 0.9432 - val_loss: 0.1998 - val_auc_86: 0.8485\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1651 - auc_86: 0.9417 - val_loss: 0.1858 - val_auc_86: 0.8528\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1608 - auc_86: 0.9453 - val_loss: 0.1747 - val_auc_86: 0.8592\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1564 - auc_86: 0.9457 - val_loss: 0.1785 - val_auc_86: 0.8583\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1518 - auc_86: 0.9486 - val_loss: 0.1918 - val_auc_86: 0.8543\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1484 - auc_86: 0.9484 - val_loss: 0.1791 - val_auc_86: 0.8448\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1446 - auc_86: 0.9505 - val_loss: 0.1712 - val_auc_86: 0.8484\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1422 - auc_86: 0.9500 - val_loss: 0.1726 - val_auc_86: 0.8497\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1383 - auc_86: 0.9533 - val_loss: 0.1728 - val_auc_86: 0.8492\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1355 - auc_86: 0.9540 - val_loss: 0.1645 - val_auc_86: 0.8517\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1331 - auc_86: 0.9554 - val_loss: 0.1511 - val_auc_86: 0.8561\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1295 - auc_86: 0.9574 - val_loss: 0.1681 - val_auc_86: 0.8527\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1268 - auc_86: 0.9578 - val_loss: 0.1866 - val_auc_86: 0.8479\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1257 - auc_86: 0.9558 - val_loss: 0.1706 - val_auc_86: 0.8540\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1222 - auc_86: 0.9577 - val_loss: 0.1622 - val_auc_86: 0.8542\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1191 - auc_86: 0.9605 - val_loss: 0.1747 - val_auc_86: 0.8544\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1169 - auc_86: 0.9622 - val_loss: 0.1801 - val_auc_86: 0.8533\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1159 - auc_86: 0.9590 - val_loss: 0.1619 - val_auc_86: 0.8549\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1128 - auc_86: 0.9620 - val_loss: 0.1399 - val_auc_86: 0.8602\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1139 - auc_86: 0.9644 - val_loss: 0.1596 - val_auc_86: 0.8549\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1083 - auc_86: 0.9646 - val_loss: 0.1556 - val_auc_86: 0.8575\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1064 - auc_86: 0.9654 - val_loss: 0.1556 - val_auc_86: 0.8569\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1051 - auc_86: 0.9651 - val_loss: 0.1556 - val_auc_86: 0.8578\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1031 - auc_86: 0.9658 - val_loss: 0.1480 - val_auc_86: 0.8615\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1012 - auc_86: 0.9656 - val_loss: 0.1322 - val_auc_86: 0.8479\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0999 - auc_86: 0.9699 - val_loss: 0.1531 - val_auc_86: 0.8606\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0981 - auc_86: 0.9666 - val_loss: 0.1527 - val_auc_86: 0.8617\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0963 - auc_86: 0.9685 - val_loss: 0.1435 - val_auc_86: 0.8459\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0946 - auc_86: 0.9697 - val_loss: 0.1552 - val_auc_86: 0.8623\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0997 - auc_86: 0.9640 - val_loss: 0.1516 - val_auc_86: 0.8471\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0922 - auc_86: 0.9703 - val_loss: 0.1314 - val_auc_86: 0.8531\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0914 - auc_86: 0.9695 - val_loss: 0.1392 - val_auc_86: 0.8505\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0892 - auc_86: 0.9710 - val_loss: 0.1326 - val_auc_86: 0.8525\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0882 - auc_86: 0.9713 - val_loss: 0.1440 - val_auc_86: 0.8485\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0875 - auc_86: 0.9710 - val_loss: 0.1450 - val_auc_86: 0.8474\n",
      "Epoch 50/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0857 - auc_86: 0.9713 - val_loss: 0.1301 - val_auc_86: 0.8542\n",
      "Epoch 51/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0841 - auc_86: 0.9733 - val_loss: 0.1412 - val_auc_86: 0.8517\n",
      "Epoch 52/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0831 - auc_86: 0.9722 - val_loss: 0.1327 - val_auc_86: 0.8545\n",
      "Epoch 53/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0819 - auc_86: 0.9727 - val_loss: 0.1417 - val_auc_86: 0.8516\n",
      "Epoch 54/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0812 - auc_86: 0.9722 - val_loss: 0.1280 - val_auc_86: 0.8366\n",
      "Epoch 55/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0794 - auc_86: 0.9735 - val_loss: 0.1260 - val_auc_86: 0.8377\n",
      "Epoch 56/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0788 - auc_86: 0.9740 - val_loss: 0.1319 - val_auc_86: 0.8355\n",
      "Epoch 57/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0772 - auc_86: 0.9732 - val_loss: 0.1218 - val_auc_86: 0.8374\n",
      "Epoch 58/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0763 - auc_86: 0.9745 - val_loss: 0.1222 - val_auc_86: 0.8378\n",
      "Epoch 59/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0751 - auc_86: 0.9743 - val_loss: 0.1051 - val_auc_86: 0.8393\n",
      "Epoch 60/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0957 - auc_86: 0.9761 - val_loss: 0.1267 - val_auc_86: 0.8349\n",
      "Epoch 61/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0751 - auc_86: 0.9755 - val_loss: 0.1211 - val_auc_86: 0.8369\n",
      "Epoch 62/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0728 - auc_86: 0.9750 - val_loss: 0.1263 - val_auc_86: 0.8375\n",
      "Epoch 63/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0719 - auc_86: 0.9750 - val_loss: 0.1229 - val_auc_86: 0.8383\n",
      "Epoch 64/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0708 - auc_86: 0.9760 - val_loss: 0.1185 - val_auc_86: 0.8396\n",
      "Epoch 65/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0699 - auc_86: 0.9758 - val_loss: 0.1220 - val_auc_86: 0.8387\n",
      "Epoch 66/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0691 - auc_86: 0.9760 - val_loss: 0.1223 - val_auc_86: 0.8392\n",
      "Epoch 67/300\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 0.0684 - auc_86: 0.9770 - val_loss: 0.1199 - val_auc_86: 0.8405\n",
      "Epoch 68/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0675 - auc_86: 0.9765 - val_loss: 0.1172 - val_auc_86: 0.8401\n",
      "Epoch 69/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0667 - auc_86: 0.9783 - val_loss: 0.1215 - val_auc_86: 0.8406\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.5636 - auc_87: 0.6101 - val_loss: 0.4145 - val_auc_87: 0.7284\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.4026 - auc_87: 0.7799 - val_loss: 0.3230 - val_auc_87: 0.7953\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3251 - auc_87: 0.8452 - val_loss: 0.2923 - val_auc_87: 0.8104\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2827 - auc_87: 0.8755 - val_loss: 0.2453 - val_auc_87: 0.8266\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2549 - auc_87: 0.8951 - val_loss: 0.2332 - val_auc_87: 0.8348\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2365 - auc_87: 0.8983 - val_loss: 0.1970 - val_auc_87: 0.8508\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2229 - auc_87: 0.9170 - val_loss: 0.2180 - val_auc_87: 0.8433\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2096 - auc_87: 0.9194 - val_loss: 0.2167 - val_auc_87: 0.8442\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1991 - auc_87: 0.9280 - val_loss: 0.2274 - val_auc_87: 0.8440\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1903 - auc_87: 0.9303 - val_loss: 0.2152 - val_auc_87: 0.8461\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1815 - auc_87: 0.9361 - val_loss: 0.1973 - val_auc_87: 0.8402\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.1743 - auc_87: 0.9396 - val_loss: 0.1849 - val_auc_87: 0.8451\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1676 - auc_87: 0.9435 - val_loss: 0.1892 - val_auc_87: 0.8442\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1617 - auc_87: 0.9443 - val_loss: 0.1933 - val_auc_87: 0.8449\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1559 - auc_87: 0.9461 - val_loss: 0.1823 - val_auc_87: 0.8492\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1507 - auc_87: 0.9472 - val_loss: 0.1618 - val_auc_87: 0.8549\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.1466 - auc_87: 0.9516 - val_loss: 0.1910 - val_auc_87: 0.8451\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.1462 - auc_87: 0.9464 - val_loss: 0.1960 - val_auc_87: 0.8451\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.1410 - auc_87: 0.9486 - val_loss: 0.1805 - val_auc_87: 0.8494\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.1340 - auc_87: 0.9542 - val_loss: 0.1715 - val_auc_87: 0.8544\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1305 - auc_87: 0.9552 - val_loss: 0.1676 - val_auc_87: 0.8573\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1272 - auc_87: 0.9553 - val_loss: 0.1771 - val_auc_87: 0.8548\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1250 - auc_87: 0.9575 - val_loss: 0.1769 - val_auc_87: 0.8556\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1209 - auc_87: 0.9600 - val_loss: 0.1656 - val_auc_87: 0.8298\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1185 - auc_87: 0.9594 - val_loss: 0.1479 - val_auc_87: 0.8309\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1159 - auc_87: 0.9607 - val_loss: 0.1710 - val_auc_87: 0.8458\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1132 - auc_87: 0.9621 - val_loss: 0.1516 - val_auc_87: 0.8320\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1105 - auc_87: 0.9638 - val_loss: 0.1686 - val_auc_87: 0.8307\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1099 - auc_87: 0.9617 - val_loss: 0.1554 - val_auc_87: 0.8340\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1066 - auc_87: 0.9660 - val_loss: 0.1490 - val_auc_87: 0.8352\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1035 - auc_87: 0.9654 - val_loss: 0.1604 - val_auc_87: 0.8327\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1013 - auc_87: 0.9650 - val_loss: 0.1396 - val_auc_87: 0.8405\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0993 - auc_87: 0.9676 - val_loss: 0.1540 - val_auc_87: 0.8352\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0978 - auc_87: 0.9661 - val_loss: 0.1464 - val_auc_87: 0.8391\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0961 - auc_87: 0.9676 - val_loss: 0.1359 - val_auc_87: 0.8069\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0936 - auc_87: 0.9680 - val_loss: 0.1432 - val_auc_87: 0.8235\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0918 - auc_87: 0.9690 - val_loss: 0.1198 - val_auc_87: 0.8143\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1005 - auc_87: 0.9711 - val_loss: 0.1301 - val_auc_87: 0.8104\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0897 - auc_87: 0.9695 - val_loss: 0.1392 - val_auc_87: 0.8074\n",
      "Epoch 40/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0901 - auc_87: 0.9711 - val_loss: 0.1222 - val_auc_87: 0.8150\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0863 - auc_87: 0.9727 - val_loss: 0.1419 - val_auc_87: 0.8084\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0854 - auc_87: 0.9722 - val_loss: 0.1302 - val_auc_87: 0.8135\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0836 - auc_87: 0.9725 - val_loss: 0.1397 - val_auc_87: 0.8103\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0830 - auc_87: 0.9725 - val_loss: 0.1231 - val_auc_87: 0.8168\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0813 - auc_87: 0.9735 - val_loss: 0.1263 - val_auc_87: 0.8153\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0801 - auc_87: 0.9737 - val_loss: 0.1398 - val_auc_87: 0.8115\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0795 - auc_87: 0.9720 - val_loss: 0.1277 - val_auc_87: 0.8155\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.6706 - auc_88: 0.5041 - val_loss: 0.5548 - val_auc_88: 0.5371\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.5141 - auc_88: 0.6371 - val_loss: 0.4313 - val_auc_88: 0.7222\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.4079 - auc_88: 0.7574 - val_loss: 0.3533 - val_auc_88: 0.7681\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3355 - auc_88: 0.8243 - val_loss: 0.3095 - val_auc_88: 0.8099\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2930 - auc_88: 0.8607 - val_loss: 0.2861 - val_auc_88: 0.8280\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2649 - auc_88: 0.8851 - val_loss: 0.2652 - val_auc_88: 0.8278\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2477 - auc_88: 0.9051 - val_loss: 0.2335 - val_auc_88: 0.8404\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2335 - auc_88: 0.9111 - val_loss: 0.2328 - val_auc_88: 0.8430\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2220 - auc_88: 0.9187 - val_loss: 0.2474 - val_auc_88: 0.8384\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2142 - auc_88: 0.9196 - val_loss: 0.2414 - val_auc_88: 0.8408\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2060 - auc_88: 0.9248 - val_loss: 0.2264 - val_auc_88: 0.8480\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1988 - auc_88: 0.9294 - val_loss: 0.2012 - val_auc_88: 0.8485\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1933 - auc_88: 0.9335 - val_loss: 0.2022 - val_auc_88: 0.8475\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1878 - auc_88: 0.9357 - val_loss: 0.2051 - val_auc_88: 0.8474\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1828 - auc_88: 0.9383 - val_loss: 0.2174 - val_auc_88: 0.8444\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1807 - auc_88: 0.9354 - val_loss: 0.1929 - val_auc_88: 0.8502\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1744 - auc_88: 0.9416 - val_loss: 0.2183 - val_auc_88: 0.8428\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1711 - auc_88: 0.9431 - val_loss: 0.2031 - val_auc_88: 0.8489\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1679 - auc_88: 0.9461 - val_loss: 0.2072 - val_auc_88: 0.8478\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1645 - auc_88: 0.9460 - val_loss: 0.1947 - val_auc_88: 0.8523\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1627 - auc_88: 0.9466 - val_loss: 0.1805 - val_auc_88: 0.8555\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1584 - auc_88: 0.9474 - val_loss: 0.1808 - val_auc_88: 0.8422\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1562 - auc_88: 0.9488 - val_loss: 0.1947 - val_auc_88: 0.8398\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1541 - auc_88: 0.9493 - val_loss: 0.1818 - val_auc_88: 0.8430\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1510 - auc_88: 0.9490 - val_loss: 0.1836 - val_auc_88: 0.8437\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1482 - auc_88: 0.9504 - val_loss: 0.1854 - val_auc_88: 0.8439\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1456 - auc_88: 0.9520 - val_loss: 0.1757 - val_auc_88: 0.8465\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1439 - auc_88: 0.9531 - val_loss: 0.1771 - val_auc_88: 0.8482\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1413 - auc_88: 0.9532 - val_loss: 0.1770 - val_auc_88: 0.8450\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1391 - auc_88: 0.9539 - val_loss: 0.1845 - val_auc_88: 0.8426\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1373 - auc_88: 0.9531 - val_loss: 0.1956 - val_auc_88: 0.8441\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1375 - auc_88: 0.9527 - val_loss: 0.1697 - val_auc_88: 0.8443\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1346 - auc_88: 0.9590 - val_loss: 0.1690 - val_auc_88: 0.8458\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1307 - auc_88: 0.9566 - val_loss: 0.1679 - val_auc_88: 0.8478\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1292 - auc_88: 0.9565 - val_loss: 0.1661 - val_auc_88: 0.8498\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1274 - auc_88: 0.9586 - val_loss: 0.1725 - val_auc_88: 0.8483\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1261 - auc_88: 0.9588 - val_loss: 0.1627 - val_auc_88: 0.8529\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1241 - auc_88: 0.9601 - val_loss: 0.1573 - val_auc_88: 0.8358\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1253 - auc_88: 0.9604 - val_loss: 0.1575 - val_auc_88: 0.8545\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1211 - auc_88: 0.9606 - val_loss: 0.1602 - val_auc_88: 0.8381\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1204 - auc_88: 0.9623 - val_loss: 0.1545 - val_auc_88: 0.8208\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1185 - auc_88: 0.9628 - val_loss: 0.1514 - val_auc_88: 0.8204\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1171 - auc_88: 0.9635 - val_loss: 0.1640 - val_auc_88: 0.8196\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1164 - auc_88: 0.9618 - val_loss: 0.1671 - val_auc_88: 0.8194\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1143 - auc_88: 0.9640 - val_loss: 0.1648 - val_auc_88: 0.8191\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1130 - auc_88: 0.9648 - val_loss: 0.1859 - val_auc_88: 0.8176\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1129 - auc_88: 0.9637 - val_loss: 0.1606 - val_auc_88: 0.8211\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1100 - auc_88: 0.9647 - val_loss: 0.1393 - val_auc_88: 0.8257\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1143 - auc_88: 0.9661 - val_loss: 0.1420 - val_auc_88: 0.8254\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1089 - auc_88: 0.9680 - val_loss: 0.1604 - val_auc_88: 0.8221\n",
      "Epoch 51/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1067 - auc_88: 0.9668 - val_loss: 0.1581 - val_auc_88: 0.8212\n",
      "Epoch 52/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1061 - auc_88: 0.9665 - val_loss: 0.1521 - val_auc_88: 0.8231\n",
      "Epoch 53/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1045 - auc_88: 0.9668 - val_loss: 0.1555 - val_auc_88: 0.8227\n",
      "Epoch 54/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1034 - auc_88: 0.9670 - val_loss: 0.1545 - val_auc_88: 0.8234\n",
      "Epoch 55/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1021 - auc_88: 0.9673 - val_loss: 0.1548 - val_auc_88: 0.8238\n",
      "Epoch 56/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1012 - auc_88: 0.9683 - val_loss: 0.1670 - val_auc_88: 0.8236\n",
      "Epoch 57/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1054 - auc_88: 0.9643 - val_loss: 0.1507 - val_auc_88: 0.8229\n",
      "Epoch 58/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0995 - auc_88: 0.9690 - val_loss: 0.1485 - val_auc_88: 0.8245\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.7276 - auc_89: 0.5027 - val_loss: 0.5381 - val_auc_89: 0.5401\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.4949 - auc_89: 0.6622 - val_loss: 0.4003 - val_auc_89: 0.7253\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3686 - auc_89: 0.7993 - val_loss: 0.3220 - val_auc_89: 0.7775\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3153 - auc_89: 0.8533 - val_loss: 0.3002 - val_auc_89: 0.7972\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2821 - auc_89: 0.8695 - val_loss: 0.2558 - val_auc_89: 0.8225\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2584 - auc_89: 0.8860 - val_loss: 0.2339 - val_auc_89: 0.8352\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2411 - auc_89: 0.9053 - val_loss: 0.2347 - val_auc_89: 0.8373\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2273 - auc_89: 0.9125 - val_loss: 0.2260 - val_auc_89: 0.8458\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2165 - auc_89: 0.9183 - val_loss: 0.1985 - val_auc_89: 0.8507\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2082 - auc_89: 0.9271 - val_loss: 0.2267 - val_auc_89: 0.8426\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2006 - auc_89: 0.9273 - val_loss: 0.2119 - val_auc_89: 0.8464\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1932 - auc_89: 0.9324 - val_loss: 0.2009 - val_auc_89: 0.8510\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1884 - auc_89: 0.9329 - val_loss: 0.1984 - val_auc_89: 0.8527\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1831 - auc_89: 0.9382 - val_loss: 0.1941 - val_auc_89: 0.8570\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1783 - auc_89: 0.9396 - val_loss: 0.1936 - val_auc_89: 0.8558\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1749 - auc_89: 0.9415 - val_loss: 0.2113 - val_auc_89: 0.8505\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1700 - auc_89: 0.9411 - val_loss: 0.1847 - val_auc_89: 0.8595\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1668 - auc_89: 0.9457 - val_loss: 0.1795 - val_auc_89: 0.8621\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1626 - auc_89: 0.9446 - val_loss: 0.1806 - val_auc_89: 0.8635\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1590 - auc_89: 0.9465 - val_loss: 0.1825 - val_auc_89: 0.8639\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1564 - auc_89: 0.9492 - val_loss: 0.1916 - val_auc_89: 0.8620\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1532 - auc_89: 0.9482 - val_loss: 0.1856 - val_auc_89: 0.8623\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1495 - auc_89: 0.9508 - val_loss: 0.1859 - val_auc_89: 0.8633\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1465 - auc_89: 0.9523 - val_loss: 0.1979 - val_auc_89: 0.8591\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1432 - auc_89: 0.9508 - val_loss: 0.1527 - val_auc_89: 0.8565\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1407 - auc_89: 0.9575 - val_loss: 0.1934 - val_auc_89: 0.8495\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1371 - auc_89: 0.9539 - val_loss: 0.1610 - val_auc_89: 0.8560\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1354 - auc_89: 0.9550 - val_loss: 0.1537 - val_auc_89: 0.8612\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1317 - auc_89: 0.9584 - val_loss: 0.1595 - val_auc_89: 0.8593\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1293 - auc_89: 0.9596 - val_loss: 0.1673 - val_auc_89: 0.8567\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1269 - auc_89: 0.9590 - val_loss: 0.1706 - val_auc_89: 0.8568\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1239 - auc_89: 0.9596 - val_loss: 0.1644 - val_auc_89: 0.8434\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1223 - auc_89: 0.9583 - val_loss: 0.1611 - val_auc_89: 0.8463\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1187 - auc_89: 0.9623 - val_loss: 0.1754 - val_auc_89: 0.8439\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1182 - auc_89: 0.9608 - val_loss: 0.1654 - val_auc_89: 0.8440\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.5931 - auc_90: 0.5668 - val_loss: 0.4493 - val_auc_90: 0.6501\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.4175 - auc_90: 0.7723 - val_loss: 0.3548 - val_auc_90: 0.7469\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3314 - auc_90: 0.8329 - val_loss: 0.2775 - val_auc_90: 0.7927\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2875 - auc_90: 0.8784 - val_loss: 0.2749 - val_auc_90: 0.8042\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2595 - auc_90: 0.8902 - val_loss: 0.2220 - val_auc_90: 0.8330\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2409 - auc_90: 0.9103 - val_loss: 0.2351 - val_auc_90: 0.8272\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2232 - auc_90: 0.9115 - val_loss: 0.1883 - val_auc_90: 0.8446\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2126 - auc_90: 0.9207 - val_loss: 0.1965 - val_auc_90: 0.8441\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1999 - auc_90: 0.9278 - val_loss: 0.2225 - val_auc_90: 0.8351\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1914 - auc_90: 0.9278 - val_loss: 0.2154 - val_auc_90: 0.8395\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1829 - auc_90: 0.9339 - val_loss: 0.2220 - val_auc_90: 0.8384\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1759 - auc_90: 0.9377 - val_loss: 0.1840 - val_auc_90: 0.8541\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1707 - auc_90: 0.9434 - val_loss: 0.1953 - val_auc_90: 0.8486\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1642 - auc_90: 0.9437 - val_loss: 0.2145 - val_auc_90: 0.8443\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1598 - auc_90: 0.9441 - val_loss: 0.2145 - val_auc_90: 0.8460\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1577 - auc_90: 0.9433 - val_loss: 0.1941 - val_auc_90: 0.8531\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1533 - auc_90: 0.9455 - val_loss: 0.1841 - val_auc_90: 0.8577\n",
      "Epoch 18/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1474 - auc_90: 0.9499 - val_loss: 0.1938 - val_auc_90: 0.8549\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1444 - auc_90: 0.9505 - val_loss: 0.1706 - val_auc_90: 0.8508\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1414 - auc_90: 0.9512 - val_loss: 0.1784 - val_auc_90: 0.8510\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1381 - auc_90: 0.9535 - val_loss: 0.1794 - val_auc_90: 0.8499\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1355 - auc_90: 0.9548 - val_loss: 0.1967 - val_auc_90: 0.8619\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1334 - auc_90: 0.9532 - val_loss: 0.1854 - val_auc_90: 0.8662\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1296 - auc_90: 0.9557 - val_loss: 0.1729 - val_auc_90: 0.8361\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1274 - auc_90: 0.9554 - val_loss: 0.1837 - val_auc_90: 0.8380\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1255 - auc_90: 0.9569 - val_loss: 0.1665 - val_auc_90: 0.8434\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1226 - auc_90: 0.9592 - val_loss: 0.1596 - val_auc_90: 0.8452\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1226 - auc_90: 0.9610 - val_loss: 0.1497 - val_auc_90: 0.8308\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1240 - auc_90: 0.9615 - val_loss: 0.1586 - val_auc_90: 0.8293\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1163 - auc_90: 0.9601 - val_loss: 0.1576 - val_auc_90: 0.8321\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1142 - auc_90: 0.9628 - val_loss: 0.1666 - val_auc_90: 0.8302\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1135 - auc_90: 0.9610 - val_loss: 0.1646 - val_auc_90: 0.8307\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1106 - auc_90: 0.9630 - val_loss: 0.1551 - val_auc_90: 0.8365\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1088 - auc_90: 0.9651 - val_loss: 0.1558 - val_auc_90: 0.8365\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1070 - auc_90: 0.9655 - val_loss: 0.1557 - val_auc_90: 0.8367\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1056 - auc_90: 0.9661 - val_loss: 0.1638 - val_auc_90: 0.8339\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1042 - auc_90: 0.9662 - val_loss: 0.1581 - val_auc_90: 0.8375\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1036 - auc_90: 0.9646 - val_loss: 0.1494 - val_auc_90: 0.8199\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1009 - auc_90: 0.9672 - val_loss: 0.1387 - val_auc_90: 0.8243\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0995 - auc_90: 0.9678 - val_loss: 0.1389 - val_auc_90: 0.8253\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0983 - auc_90: 0.9678 - val_loss: 0.1399 - val_auc_90: 0.8253\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0969 - auc_90: 0.9687 - val_loss: 0.1381 - val_auc_90: 0.8265\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0950 - auc_90: 0.9695 - val_loss: 0.1446 - val_auc_90: 0.8247\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0938 - auc_90: 0.9695 - val_loss: 0.1446 - val_auc_90: 0.8251\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0928 - auc_90: 0.9698 - val_loss: 0.1604 - val_auc_90: 0.8201\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0949 - auc_90: 0.9658 - val_loss: 0.1465 - val_auc_90: 0.8243\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0902 - auc_90: 0.9705 - val_loss: 0.1488 - val_auc_90: 0.8242\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0888 - auc_90: 0.9702 - val_loss: 0.1402 - val_auc_90: 0.8278\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0876 - auc_90: 0.9712 - val_loss: 0.1397 - val_auc_90: 0.8090\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0869 - auc_90: 0.9728 - val_loss: 0.1500 - val_auc_90: 0.8252\n",
      "Epoch 51/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0853 - auc_90: 0.9710 - val_loss: 0.1363 - val_auc_90: 0.8117\n",
      "Epoch 52/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0854 - auc_90: 0.9720 - val_loss: 0.1330 - val_auc_90: 0.8138\n",
      "Epoch 53/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0826 - auc_90: 0.9740 - val_loss: 0.1451 - val_auc_90: 0.8279\n",
      "Epoch 54/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0827 - auc_90: 0.9733 - val_loss: 0.1365 - val_auc_90: 0.8311\n",
      "Epoch 55/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0817 - auc_90: 0.9752 - val_loss: 0.1321 - val_auc_90: 0.8138\n",
      "Epoch 56/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0796 - auc_90: 0.9738 - val_loss: 0.1301 - val_auc_90: 0.8154\n",
      "Epoch 57/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0788 - auc_90: 0.9753 - val_loss: 0.1327 - val_auc_90: 0.8146\n",
      "Epoch 58/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0775 - auc_90: 0.9752 - val_loss: 0.1251 - val_auc_90: 0.8157\n",
      "Epoch 59/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0761 - auc_90: 0.9752 - val_loss: 0.1251 - val_auc_90: 0.8157\n",
      "Epoch 60/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0752 - auc_90: 0.9757 - val_loss: 0.1268 - val_auc_90: 0.8158\n",
      "Epoch 61/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0744 - auc_90: 0.9765 - val_loss: 0.1177 - val_auc_90: 0.8162\n",
      "Epoch 62/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0843 - auc_90: 0.9741 - val_loss: 0.1049 - val_auc_90: 0.8183\n",
      "Epoch 63/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0735 - auc_90: 0.9773 - val_loss: 0.1261 - val_auc_90: 0.8153\n",
      "Epoch 64/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0719 - auc_90: 0.9767 - val_loss: 0.1356 - val_auc_90: 0.8145\n",
      "Epoch 65/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0713 - auc_90: 0.9765 - val_loss: 0.1201 - val_auc_90: 0.8183\n",
      "Epoch 66/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0702 - auc_90: 0.9772 - val_loss: 0.1262 - val_auc_90: 0.8167\n",
      "Epoch 67/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0695 - auc_90: 0.9767 - val_loss: 0.1243 - val_auc_90: 0.8171\n",
      "Epoch 68/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0683 - auc_90: 0.9783 - val_loss: 0.1286 - val_auc_90: 0.8164\n",
      "Epoch 69/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0676 - auc_90: 0.9775 - val_loss: 0.1209 - val_auc_90: 0.8187\n",
      "Epoch 70/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0667 - auc_90: 0.9780 - val_loss: 0.1185 - val_auc_90: 0.8183\n",
      "Epoch 71/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0660 - auc_90: 0.9778 - val_loss: 0.1141 - val_auc_90: 0.8200\n",
      "Epoch 72/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0654 - auc_90: 0.9792 - val_loss: 0.1174 - val_auc_90: 0.8193\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.6020 - auc_91: 0.5590 - val_loss: 0.5133 - val_auc_91: 0.6358\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.4526 - auc_91: 0.7234 - val_loss: 0.3785 - val_auc_91: 0.7580\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3650 - auc_91: 0.8079 - val_loss: 0.3189 - val_auc_91: 0.7964\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3148 - auc_91: 0.8394 - val_loss: 0.3031 - val_auc_91: 0.8131\n",
      "Epoch 5/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2808 - auc_91: 0.8677 - val_loss: 0.2689 - val_auc_91: 0.8380\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2578 - auc_91: 0.8858 - val_loss: 0.2427 - val_auc_91: 0.8479\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2418 - auc_91: 0.8974 - val_loss: 0.1881 - val_auc_91: 0.8673\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2326 - auc_91: 0.9112 - val_loss: 0.2075 - val_auc_91: 0.8524\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2227 - auc_91: 0.9085 - val_loss: 0.1917 - val_auc_91: 0.8593\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2188 - auc_91: 0.9206 - val_loss: 0.2023 - val_auc_91: 0.8550\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2097 - auc_91: 0.9175 - val_loss: 0.2043 - val_auc_91: 0.8565\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2044 - auc_91: 0.9216 - val_loss: 0.2236 - val_auc_91: 0.8524\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2011 - auc_91: 0.9201 - val_loss: 0.1844 - val_auc_91: 0.8651\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1969 - auc_91: 0.9247 - val_loss: 0.1912 - val_auc_91: 0.8641\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1923 - auc_91: 0.9262 - val_loss: 0.1883 - val_auc_91: 0.8654\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1901 - auc_91: 0.9281 - val_loss: 0.2284 - val_auc_91: 0.8550\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1885 - auc_91: 0.9292 - val_loss: 0.2125 - val_auc_91: 0.8586\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1860 - auc_91: 0.9256 - val_loss: 0.1843 - val_auc_91: 0.8687\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1807 - auc_91: 0.9388 - val_loss: 0.1907 - val_auc_91: 0.8673\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1761 - auc_91: 0.9357 - val_loss: 0.1656 - val_auc_91: 0.8744\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1739 - auc_91: 0.9401 - val_loss: 0.1617 - val_auc_91: 0.8771\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1720 - auc_91: 0.9420 - val_loss: 0.1627 - val_auc_91: 0.8771\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1696 - auc_91: 0.9448 - val_loss: 0.1831 - val_auc_91: 0.8736\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1656 - auc_91: 0.9424 - val_loss: 0.1721 - val_auc_91: 0.8763\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1633 - auc_91: 0.9428 - val_loss: 0.1614 - val_auc_91: 0.8792\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1607 - auc_91: 0.9475 - val_loss: 0.1789 - val_auc_91: 0.8755\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1584 - auc_91: 0.9461 - val_loss: 0.1716 - val_auc_91: 0.8776\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1548 - auc_91: 0.9458 - val_loss: 0.1577 - val_auc_91: 0.8815\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1524 - auc_91: 0.9491 - val_loss: 0.1516 - val_auc_91: 0.8839\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1537 - auc_91: 0.9527 - val_loss: 0.1563 - val_auc_91: 0.8830\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1495 - auc_91: 0.9479 - val_loss: 0.1619 - val_auc_91: 0.8818\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1444 - auc_91: 0.9521 - val_loss: 0.1647 - val_auc_91: 0.8829\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1420 - auc_91: 0.9534 - val_loss: 0.1608 - val_auc_91: 0.8833\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1392 - auc_91: 0.9536 - val_loss: 0.1546 - val_auc_91: 0.8850\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1366 - auc_91: 0.9547 - val_loss: 0.1514 - val_auc_91: 0.8875\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1346 - auc_91: 0.9546 - val_loss: 0.1434 - val_auc_91: 0.8911\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1319 - auc_91: 0.9570 - val_loss: 0.1581 - val_auc_91: 0.8864\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1297 - auc_91: 0.9566 - val_loss: 0.1349 - val_auc_91: 0.8955\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1300 - auc_91: 0.9601 - val_loss: 0.1421 - val_auc_91: 0.8929\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1252 - auc_91: 0.9594 - val_loss: 0.1428 - val_auc_91: 0.8931\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1233 - auc_91: 0.9594 - val_loss: 0.1308 - val_auc_91: 0.8979\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1269 - auc_91: 0.9607 - val_loss: 0.1228 - val_auc_91: 0.8999\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1265 - auc_91: 0.9629 - val_loss: 0.1308 - val_auc_91: 0.8962\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1180 - auc_91: 0.9609 - val_loss: 0.1330 - val_auc_91: 0.8976\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1162 - auc_91: 0.9616 - val_loss: 0.1406 - val_auc_91: 0.8945\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1145 - auc_91: 0.9617 - val_loss: 0.1277 - val_auc_91: 0.8988\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1127 - auc_91: 0.9634 - val_loss: 0.1333 - val_auc_91: 0.8978\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1145 - auc_91: 0.9586 - val_loss: 0.1381 - val_auc_91: 0.8976\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1102 - auc_91: 0.9637 - val_loss: 0.1314 - val_auc_91: 0.8996\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1082 - auc_91: 0.9637 - val_loss: 0.1171 - val_auc_91: 0.9023\n",
      "Epoch 51/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1067 - auc_91: 0.9649 - val_loss: 0.1202 - val_auc_91: 0.9012\n",
      "Epoch 52/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1052 - auc_91: 0.9651 - val_loss: 0.1110 - val_auc_91: 0.9020\n",
      "Epoch 53/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1039 - auc_91: 0.9676 - val_loss: 0.1412 - val_auc_91: 0.8981\n",
      "Epoch 54/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.1028 - auc_91: 0.9649 - val_loss: 0.1271 - val_auc_91: 0.9007\n",
      "Epoch 55/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1009 - auc_91: 0.9656 - val_loss: 0.1233 - val_auc_91: 0.9024\n",
      "Epoch 56/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1000 - auc_91: 0.9658 - val_loss: 0.1234 - val_auc_91: 0.9028\n",
      "Epoch 57/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.0988 - auc_91: 0.9673 - val_loss: 0.1189 - val_auc_91: 0.9015\n",
      "Epoch 58/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.0970 - auc_91: 0.9671 - val_loss: 0.1047 - val_auc_91: 0.9030\n",
      "Epoch 59/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1026 - auc_91: 0.9682 - val_loss: 0.1091 - val_auc_91: 0.9005\n",
      "Epoch 60/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0947 - auc_91: 0.9675 - val_loss: 0.1222 - val_auc_91: 0.9003\n",
      "Epoch 61/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0932 - auc_91: 0.9682 - val_loss: 0.1265 - val_auc_91: 0.8995\n",
      "Epoch 62/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0925 - auc_91: 0.9668 - val_loss: 0.1083 - val_auc_91: 0.9031\n",
      "Epoch 63/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0954 - auc_91: 0.9704 - val_loss: 0.1101 - val_auc_91: 0.9021\n",
      "Epoch 64/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0894 - auc_91: 0.9705 - val_loss: 0.1168 - val_auc_91: 0.9027\n",
      "Epoch 65/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0880 - auc_91: 0.9704 - val_loss: 0.1118 - val_auc_91: 0.9029\n",
      "Epoch 66/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0870 - auc_91: 0.9707 - val_loss: 0.1089 - val_auc_91: 0.9028\n",
      "Epoch 67/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0864 - auc_91: 0.9724 - val_loss: 0.1147 - val_auc_91: 0.9047\n",
      "Epoch 68/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0845 - auc_91: 0.9719 - val_loss: 0.1071 - val_auc_91: 0.9041\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.4732 - auc_92: 0.6956 - val_loss: 0.4140 - val_auc_92: 0.7255\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3640 - auc_92: 0.8026 - val_loss: 0.3068 - val_auc_92: 0.8031\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3159 - auc_92: 0.8435 - val_loss: 0.3026 - val_auc_92: 0.8141\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2918 - auc_92: 0.8748 - val_loss: 0.2652 - val_auc_92: 0.8266\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2719 - auc_92: 0.8802 - val_loss: 0.2370 - val_auc_92: 0.8415\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2551 - auc_92: 0.8872 - val_loss: 0.2506 - val_auc_92: 0.8404\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2446 - auc_92: 0.8922 - val_loss: 0.2345 - val_auc_92: 0.8412\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2335 - auc_92: 0.9058 - val_loss: 0.2220 - val_auc_92: 0.8484\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2254 - auc_92: 0.9085 - val_loss: 0.2263 - val_auc_92: 0.8500\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2180 - auc_92: 0.9123 - val_loss: 0.2409 - val_auc_92: 0.8468\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2153 - auc_92: 0.9093 - val_loss: 0.2010 - val_auc_92: 0.8509\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2067 - auc_92: 0.9160 - val_loss: 0.1949 - val_auc_92: 0.8540\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2018 - auc_92: 0.9211 - val_loss: 0.1785 - val_auc_92: 0.8634\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1976 - auc_92: 0.9229 - val_loss: 0.2112 - val_auc_92: 0.8509\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1934 - auc_92: 0.9241 - val_loss: 0.2005 - val_auc_92: 0.8587\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1884 - auc_92: 0.9296 - val_loss: 0.1870 - val_auc_92: 0.8648\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1843 - auc_92: 0.9335 - val_loss: 0.1873 - val_auc_92: 0.8655\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1808 - auc_92: 0.9372 - val_loss: 0.1838 - val_auc_92: 0.8676\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1767 - auc_92: 0.9360 - val_loss: 0.1901 - val_auc_92: 0.8671\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1736 - auc_92: 0.9359 - val_loss: 0.1743 - val_auc_92: 0.8699\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1715 - auc_92: 0.9415 - val_loss: 0.1564 - val_auc_92: 0.8756\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1681 - auc_92: 0.9425 - val_loss: 0.1661 - val_auc_92: 0.8745\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1634 - auc_92: 0.9421 - val_loss: 0.1671 - val_auc_92: 0.8745\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1601 - auc_92: 0.9440 - val_loss: 0.1731 - val_auc_92: 0.8741\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1568 - auc_92: 0.9456 - val_loss: 0.1648 - val_auc_92: 0.8777\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1543 - auc_92: 0.9486 - val_loss: 0.1592 - val_auc_92: 0.8778\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1543 - auc_92: 0.9491 - val_loss: 0.1315 - val_auc_92: 0.8883\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1504 - auc_92: 0.9490 - val_loss: 0.1548 - val_auc_92: 0.8827\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1459 - auc_92: 0.9515 - val_loss: 0.1607 - val_auc_92: 0.8820\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1429 - auc_92: 0.9507 - val_loss: 0.1673 - val_auc_92: 0.8810\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1409 - auc_92: 0.9495 - val_loss: 0.1742 - val_auc_92: 0.8782\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1377 - auc_92: 0.9517 - val_loss: 0.1497 - val_auc_92: 0.8855\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1346 - auc_92: 0.9541 - val_loss: 0.1394 - val_auc_92: 0.8891\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1320 - auc_92: 0.9533 - val_loss: 0.1363 - val_auc_92: 0.8907\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1297 - auc_92: 0.9569 - val_loss: 0.1491 - val_auc_92: 0.8888\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1291 - auc_92: 0.9542 - val_loss: 0.1503 - val_auc_92: 0.8892\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1246 - auc_92: 0.9582 - val_loss: 0.1386 - val_auc_92: 0.8929\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 2s 21ms/step - loss: 0.5858 - auc_93: 0.5909 - val_loss: 0.4621 - val_auc_93: 0.6485\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.4524 - auc_93: 0.7347 - val_loss: 0.3796 - val_auc_93: 0.7297\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3783 - auc_93: 0.7937 - val_loss: 0.3062 - val_auc_93: 0.7838\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3271 - auc_93: 0.8349 - val_loss: 0.2951 - val_auc_93: 0.8015\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2909 - auc_93: 0.8575 - val_loss: 0.2560 - val_auc_93: 0.8258\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2630 - auc_93: 0.8848 - val_loss: 0.2100 - val_auc_93: 0.8484\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2437 - auc_93: 0.9016 - val_loss: 0.2355 - val_auc_93: 0.8405\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2276 - auc_93: 0.9061 - val_loss: 0.2158 - val_auc_93: 0.8514\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2168 - auc_93: 0.9125 - val_loss: 0.2014 - val_auc_93: 0.8517\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2066 - auc_93: 0.9224 - val_loss: 0.1947 - val_auc_93: 0.8568\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1977 - auc_93: 0.9221 - val_loss: 0.1822 - val_auc_93: 0.8611\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1906 - auc_93: 0.9266 - val_loss: 0.1681 - val_auc_93: 0.8643\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1856 - auc_93: 0.9348 - val_loss: 0.1849 - val_auc_93: 0.8592\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1781 - auc_93: 0.9319 - val_loss: 0.1745 - val_auc_93: 0.8644\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1758 - auc_93: 0.9401 - val_loss: 0.1679 - val_auc_93: 0.8665\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1726 - auc_93: 0.9296 - val_loss: 0.1547 - val_auc_93: 0.8701\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1647 - auc_93: 0.9413 - val_loss: 0.1668 - val_auc_93: 0.8681\n",
      "Epoch 18/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1595 - auc_93: 0.9444 - val_loss: 0.1614 - val_auc_93: 0.8725\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1561 - auc_93: 0.9486 - val_loss: 0.1612 - val_auc_93: 0.8736\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1520 - auc_93: 0.9475 - val_loss: 0.1315 - val_auc_93: 0.8859\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1478 - auc_93: 0.9497 - val_loss: 0.1598 - val_auc_93: 0.8759\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1450 - auc_93: 0.9500 - val_loss: 0.1397 - val_auc_93: 0.8835\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1409 - auc_93: 0.9539 - val_loss: 0.1376 - val_auc_93: 0.8854\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1383 - auc_93: 0.9546 - val_loss: 0.1407 - val_auc_93: 0.8853\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1344 - auc_93: 0.9550 - val_loss: 0.1395 - val_auc_93: 0.8889\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1309 - auc_93: 0.9563 - val_loss: 0.1331 - val_auc_93: 0.8912\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1293 - auc_93: 0.9539 - val_loss: 0.1437 - val_auc_93: 0.8883\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1246 - auc_93: 0.9587 - val_loss: 0.1400 - val_auc_93: 0.8904\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1218 - auc_93: 0.9589 - val_loss: 0.1349 - val_auc_93: 0.8917\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1189 - auc_93: 0.9592 - val_loss: 0.1249 - val_auc_93: 0.8961\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1164 - auc_93: 0.9616 - val_loss: 0.1222 - val_auc_93: 0.8968\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1137 - auc_93: 0.9614 - val_loss: 0.1295 - val_auc_93: 0.8961\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1108 - auc_93: 0.9639 - val_loss: 0.1208 - val_auc_93: 0.8988\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1083 - auc_93: 0.9660 - val_loss: 0.1401 - val_auc_93: 0.8938\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1063 - auc_93: 0.9648 - val_loss: 0.1216 - val_auc_93: 0.8995\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1032 - auc_93: 0.9685 - val_loss: 0.1217 - val_auc_93: 0.9003\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1010 - auc_93: 0.9664 - val_loss: 0.1149 - val_auc_93: 0.9010\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0982 - auc_93: 0.9704 - val_loss: 0.1194 - val_auc_93: 0.9005\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0984 - auc_93: 0.9658 - val_loss: 0.1209 - val_auc_93: 0.9006\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0939 - auc_93: 0.9719 - val_loss: 0.1007 - val_auc_93: 0.9083\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0912 - auc_93: 0.9726 - val_loss: 0.1151 - val_auc_93: 0.9033\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0895 - auc_93: 0.9733 - val_loss: 0.1178 - val_auc_93: 0.9029\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0883 - auc_93: 0.9707 - val_loss: 0.1037 - val_auc_93: 0.9071\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0860 - auc_93: 0.9732 - val_loss: 0.1134 - val_auc_93: 0.9051\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0875 - auc_93: 0.9705 - val_loss: 0.1162 - val_auc_93: 0.9046\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.0822 - auc_93: 0.9735 - val_loss: 0.1007 - val_auc_93: 0.9092\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.0799 - auc_93: 0.9748 - val_loss: 0.1057 - val_auc_93: 0.9071\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0783 - auc_93: 0.9748 - val_loss: 0.0929 - val_auc_93: 0.9100\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0773 - auc_93: 0.9759 - val_loss: 0.1024 - val_auc_93: 0.9075\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.0754 - auc_93: 0.9760 - val_loss: 0.0859 - val_auc_93: 0.9106\n",
      "Epoch 51/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0743 - auc_93: 0.9774 - val_loss: 0.1142 - val_auc_93: 0.9062\n",
      "Epoch 52/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0723 - auc_93: 0.9765 - val_loss: 0.0941 - val_auc_93: 0.9083\n",
      "Epoch 53/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0709 - auc_93: 0.9767 - val_loss: 0.0950 - val_auc_93: 0.9086\n",
      "Epoch 54/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0703 - auc_93: 0.9771 - val_loss: 0.0999 - val_auc_93: 0.9094\n",
      "Epoch 55/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0678 - auc_93: 0.9780 - val_loss: 0.0833 - val_auc_93: 0.9072\n",
      "Epoch 56/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0713 - auc_93: 0.9786 - val_loss: 0.0817 - val_auc_93: 0.9062\n",
      "Epoch 57/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0652 - auc_93: 0.9786 - val_loss: 0.0931 - val_auc_93: 0.9050\n",
      "Epoch 58/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0650 - auc_93: 0.9778 - val_loss: 0.0940 - val_auc_93: 0.9049\n",
      "Epoch 59/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0621 - auc_93: 0.9793 - val_loss: 0.0922 - val_auc_93: 0.9049\n",
      "Epoch 60/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0611 - auc_93: 0.9793 - val_loss: 0.0948 - val_auc_93: 0.9048\n",
      "Epoch 61/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0600 - auc_93: 0.9790 - val_loss: 0.0971 - val_auc_93: 0.9044\n",
      "Epoch 62/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0622 - auc_93: 0.9783 - val_loss: 0.0981 - val_auc_93: 0.9027\n",
      "Epoch 63/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0583 - auc_93: 0.9798 - val_loss: 0.0847 - val_auc_93: 0.9070\n",
      "Epoch 64/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0564 - auc_93: 0.9803 - val_loss: 0.0805 - val_auc_93: 0.9067\n",
      "Epoch 65/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0556 - auc_93: 0.9813 - val_loss: 0.0785 - val_auc_93: 0.9075\n",
      "Epoch 66/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0543 - auc_93: 0.9815 - val_loss: 0.0772 - val_auc_93: 0.9082\n",
      "Epoch 67/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0529 - auc_93: 0.9823 - val_loss: 0.0809 - val_auc_93: 0.9080\n",
      "Epoch 68/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0538 - auc_93: 0.9815 - val_loss: 0.0838 - val_auc_93: 0.9080\n",
      "Epoch 69/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0514 - auc_93: 0.9818 - val_loss: 0.0848 - val_auc_93: 0.9069\n",
      "Epoch 70/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0501 - auc_93: 0.9822 - val_loss: 0.0781 - val_auc_93: 0.8884\n",
      "Epoch 71/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0492 - auc_93: 0.9825 - val_loss: 0.0776 - val_auc_93: 0.8891\n",
      "Epoch 72/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0486 - auc_93: 0.9825 - val_loss: 0.0783 - val_auc_93: 0.8890\n",
      "Epoch 73/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0474 - auc_93: 0.9827 - val_loss: 0.0854 - val_auc_93: 0.9062\n",
      "Epoch 74/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0482 - auc_93: 0.9822 - val_loss: 0.0764 - val_auc_93: 0.8878\n",
      "Epoch 75/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0459 - auc_93: 0.9842 - val_loss: 0.0766 - val_auc_93: 0.8884\n",
      "Epoch 76/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0451 - auc_93: 0.9837 - val_loss: 0.0750 - val_auc_93: 0.8872\n",
      "Epoch 77/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0442 - auc_93: 0.9838 - val_loss: 0.0862 - val_auc_93: 0.9059\n",
      "Epoch 78/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0435 - auc_93: 0.9842 - val_loss: 0.0769 - val_auc_93: 0.8654\n",
      "Epoch 79/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0426 - auc_93: 0.9847 - val_loss: 0.0731 - val_auc_93: 0.8663\n",
      "Epoch 80/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0432 - auc_93: 0.9843 - val_loss: 0.0812 - val_auc_93: 0.8866\n",
      "Epoch 81/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0410 - auc_93: 0.9853 - val_loss: 0.0721 - val_auc_93: 0.8669\n",
      "Epoch 82/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0404 - auc_93: 0.9850 - val_loss: 0.0729 - val_auc_93: 0.8669\n",
      "Epoch 83/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0396 - auc_93: 0.9850 - val_loss: 0.0818 - val_auc_93: 0.8648\n",
      "Epoch 84/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0390 - auc_93: 0.9852 - val_loss: 0.0707 - val_auc_93: 0.8672\n",
      "Epoch 85/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.0383 - auc_93: 0.9867 - val_loss: 0.0764 - val_auc_93: 0.8666\n",
      "Epoch 86/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.0375 - auc_93: 0.9863 - val_loss: 0.0747 - val_auc_93: 0.8673\n",
      "Epoch 87/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.0371 - auc_93: 0.9860 - val_loss: 0.0765 - val_auc_93: 0.8668\n",
      "Epoch 88/300\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 0.0363 - auc_93: 0.9863 - val_loss: 0.0677 - val_auc_93: 0.8688\n",
      "Epoch 89/300\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.0357 - auc_93: 0.9878 - val_loss: 0.0759 - val_auc_93: 0.8659\n",
      "Epoch 90/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.0349 - auc_93: 0.9863 - val_loss: 0.0630 - val_auc_93: 0.8694\n",
      "Epoch 91/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.0408 - auc_93: 0.9878 - val_loss: 0.0719 - val_auc_93: 0.8650\n",
      "Epoch 92/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0340 - auc_93: 0.9872 - val_loss: 0.0721 - val_auc_93: 0.8676\n",
      "Epoch 93/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0334 - auc_93: 0.9882 - val_loss: 0.0756 - val_auc_93: 0.8660\n",
      "Epoch 94/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0329 - auc_93: 0.9875 - val_loss: 0.0725 - val_auc_93: 0.8681\n",
      "Epoch 95/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0324 - auc_93: 0.9887 - val_loss: 0.0752 - val_auc_93: 0.8672\n",
      "Epoch 96/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.0321 - auc_93: 0.9878 - val_loss: 0.0750 - val_auc_93: 0.8681\n",
      "Epoch 97/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.0315 - auc_93: 0.9877 - val_loss: 0.0842 - val_auc_93: 0.8653\n",
      "Epoch 98/300\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.0308 - auc_93: 0.9880 - val_loss: 0.0770 - val_auc_93: 0.8676\n",
      "Epoch 99/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.0303 - auc_93: 0.9887 - val_loss: 0.0773 - val_auc_93: 0.8675\n",
      "Epoch 100/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.0300 - auc_93: 0.9885 - val_loss: 0.0739 - val_auc_93: 0.8692\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 2s 34ms/step - loss: 0.6356 - auc_94: 0.5651 - val_loss: 0.4404 - val_auc_94: 0.6413\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.4746 - auc_94: 0.7094 - val_loss: 0.4157 - val_auc_94: 0.7212\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3931 - auc_94: 0.7739 - val_loss: 0.3427 - val_auc_94: 0.7718\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.3418 - auc_94: 0.8158 - val_loss: 0.2986 - val_auc_94: 0.8058\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.3070 - auc_94: 0.8471 - val_loss: 0.2840 - val_auc_94: 0.8203\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.2824 - auc_94: 0.8603 - val_loss: 0.2638 - val_auc_94: 0.8351\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2627 - auc_94: 0.8816 - val_loss: 0.2526 - val_auc_94: 0.8426\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2469 - auc_94: 0.8882 - val_loss: 0.2436 - val_auc_94: 0.8465\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2349 - auc_94: 0.8964 - val_loss: 0.1873 - val_auc_94: 0.8560\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2313 - auc_94: 0.9128 - val_loss: 0.1963 - val_auc_94: 0.8555\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2187 - auc_94: 0.9122 - val_loss: 0.2140 - val_auc_94: 0.8500\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2122 - auc_94: 0.9140 - val_loss: 0.1775 - val_auc_94: 0.8620\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2118 - auc_94: 0.9246 - val_loss: 0.2013 - val_auc_94: 0.8564\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2018 - auc_94: 0.9222 - val_loss: 0.2060 - val_auc_94: 0.8549\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1968 - auc_94: 0.9226 - val_loss: 0.1991 - val_auc_94: 0.8581\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1922 - auc_94: 0.9256 - val_loss: 0.2003 - val_auc_94: 0.8588\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1884 - auc_94: 0.9266 - val_loss: 0.1783 - val_auc_94: 0.8652\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1863 - auc_94: 0.9357 - val_loss: 0.1879 - val_auc_94: 0.8612\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1808 - auc_94: 0.9346 - val_loss: 0.1760 - val_auc_94: 0.8661\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1762 - auc_94: 0.9360 - val_loss: 0.1786 - val_auc_94: 0.8669\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1731 - auc_94: 0.9372 - val_loss: 0.1605 - val_auc_94: 0.8717\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1721 - auc_94: 0.9419 - val_loss: 0.1740 - val_auc_94: 0.8679\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1666 - auc_94: 0.9387 - val_loss: 0.1700 - val_auc_94: 0.8696\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1638 - auc_94: 0.9410 - val_loss: 0.1654 - val_auc_94: 0.8715\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1606 - auc_94: 0.9435 - val_loss: 0.1587 - val_auc_94: 0.8746\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1582 - auc_94: 0.9453 - val_loss: 0.1476 - val_auc_94: 0.8802\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1580 - auc_94: 0.9483 - val_loss: 0.1573 - val_auc_94: 0.8775\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1522 - auc_94: 0.9480 - val_loss: 0.1588 - val_auc_94: 0.8763\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1492 - auc_94: 0.9482 - val_loss: 0.1543 - val_auc_94: 0.8787\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1467 - auc_94: 0.9509 - val_loss: 0.1708 - val_auc_94: 0.8742\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1439 - auc_94: 0.9506 - val_loss: 0.1693 - val_auc_94: 0.8759\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1419 - auc_94: 0.9500 - val_loss: 0.1508 - val_auc_94: 0.8834\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1403 - auc_94: 0.9541 - val_loss: 0.1235 - val_auc_94: 0.8897\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1366 - auc_94: 0.9536 - val_loss: 0.1576 - val_auc_94: 0.8802\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1366 - auc_94: 0.9504 - val_loss: 0.1435 - val_auc_94: 0.8864\n",
      "Epoch 36/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1314 - auc_94: 0.9546 - val_loss: 0.1358 - val_auc_94: 0.8898\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1292 - auc_94: 0.9571 - val_loss: 0.1414 - val_auc_94: 0.8874\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1275 - auc_94: 0.9568 - val_loss: 0.1451 - val_auc_94: 0.8866\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1249 - auc_94: 0.9578 - val_loss: 0.1580 - val_auc_94: 0.8832\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1296 - auc_94: 0.9514 - val_loss: 0.1646 - val_auc_94: 0.8816\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1210 - auc_94: 0.9589 - val_loss: 0.1311 - val_auc_94: 0.8904\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1206 - auc_94: 0.9614 - val_loss: 0.1160 - val_auc_94: 0.8982\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1191 - auc_94: 0.9611 - val_loss: 0.1255 - val_auc_94: 0.8941\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1159 - auc_94: 0.9616 - val_loss: 0.1337 - val_auc_94: 0.8930\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1132 - auc_94: 0.9615 - val_loss: 0.1283 - val_auc_94: 0.8927\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1118 - auc_94: 0.9618 - val_loss: 0.1317 - val_auc_94: 0.8941\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1130 - auc_94: 0.9640 - val_loss: 0.1195 - val_auc_94: 0.8996\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1078 - auc_94: 0.9655 - val_loss: 0.1409 - val_auc_94: 0.8922\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1070 - auc_94: 0.9637 - val_loss: 0.1177 - val_auc_94: 0.9011\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1117 - auc_94: 0.9648 - val_loss: 0.0963 - val_auc_94: 0.9016\n",
      "Epoch 51/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1139 - auc_94: 0.9643 - val_loss: 0.1044 - val_auc_94: 0.9008\n",
      "Epoch 52/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1028 - auc_94: 0.9638 - val_loss: 0.1213 - val_auc_94: 0.8977\n",
      "Epoch 53/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1001 - auc_94: 0.9653 - val_loss: 0.1332 - val_auc_94: 0.8958\n",
      "Epoch 54/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0988 - auc_94: 0.9644 - val_loss: 0.1217 - val_auc_94: 0.8982\n",
      "Epoch 55/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0972 - auc_94: 0.9658 - val_loss: 0.1186 - val_auc_94: 0.8978\n",
      "Epoch 56/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0955 - auc_94: 0.9665 - val_loss: 0.1202 - val_auc_94: 0.9003\n",
      "Epoch 57/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0942 - auc_94: 0.9665 - val_loss: 0.1099 - val_auc_94: 0.9021\n",
      "Epoch 58/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0930 - auc_94: 0.9681 - val_loss: 0.1214 - val_auc_94: 0.9000\n",
      "Epoch 59/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0915 - auc_94: 0.9685 - val_loss: 0.1095 - val_auc_94: 0.9028\n",
      "Epoch 60/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0900 - auc_94: 0.9687 - val_loss: 0.1104 - val_auc_94: 0.9031\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.6613 - auc_95: 0.4991 - val_loss: 0.5391 - val_auc_95: 0.5831\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.4942 - auc_95: 0.6677 - val_loss: 0.3844 - val_auc_95: 0.7441\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3921 - auc_95: 0.7812 - val_loss: 0.2978 - val_auc_95: 0.8026\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3301 - auc_95: 0.8375 - val_loss: 0.3173 - val_auc_95: 0.8033\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2937 - auc_95: 0.8571 - val_loss: 0.2399 - val_auc_95: 0.8435\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2684 - auc_95: 0.8815 - val_loss: 0.2883 - val_auc_95: 0.8302\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2466 - auc_95: 0.8909 - val_loss: 0.2307 - val_auc_95: 0.8486\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2296 - auc_95: 0.9055 - val_loss: 0.1873 - val_auc_95: 0.8678\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2175 - auc_95: 0.9154 - val_loss: 0.2134 - val_auc_95: 0.8619\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2066 - auc_95: 0.9176 - val_loss: 0.2034 - val_auc_95: 0.8665\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1980 - auc_95: 0.9220 - val_loss: 0.2064 - val_auc_95: 0.8541\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1908 - auc_95: 0.9273 - val_loss: 0.1920 - val_auc_95: 0.8622\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1844 - auc_95: 0.9277 - val_loss: 0.1884 - val_auc_95: 0.8621\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1776 - auc_95: 0.9334 - val_loss: 0.1803 - val_auc_95: 0.8651\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1725 - auc_95: 0.9369 - val_loss: 0.1660 - val_auc_95: 0.8706\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1671 - auc_95: 0.9395 - val_loss: 0.1662 - val_auc_95: 0.8715\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1623 - auc_95: 0.9435 - val_loss: 0.1634 - val_auc_95: 0.8741\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1588 - auc_95: 0.9420 - val_loss: 0.1610 - val_auc_95: 0.8753\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1527 - auc_95: 0.9473 - val_loss: 0.1554 - val_auc_95: 0.8790\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1497 - auc_95: 0.9511 - val_loss: 0.1508 - val_auc_95: 0.8814\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1447 - auc_95: 0.9521 - val_loss: 0.1571 - val_auc_95: 0.8806\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1426 - auc_95: 0.9493 - val_loss: 0.1735 - val_auc_95: 0.8740\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1388 - auc_95: 0.9516 - val_loss: 0.1336 - val_auc_95: 0.8861\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1342 - auc_95: 0.9565 - val_loss: 0.1487 - val_auc_95: 0.8860\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1306 - auc_95: 0.9581 - val_loss: 0.1353 - val_auc_95: 0.8878\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1274 - auc_95: 0.9572 - val_loss: 0.1247 - val_auc_95: 0.8925\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1241 - auc_95: 0.9597 - val_loss: 0.1358 - val_auc_95: 0.8894\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1218 - auc_95: 0.9588 - val_loss: 0.1287 - val_auc_95: 0.8930\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1184 - auc_95: 0.9608 - val_loss: 0.1384 - val_auc_95: 0.8917\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1157 - auc_95: 0.9622 - val_loss: 0.1354 - val_auc_95: 0.8938\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.1130 - auc_95: 0.9627 - val_loss: 0.1231 - val_auc_95: 0.8938\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.1103 - auc_95: 0.9635 - val_loss: 0.1379 - val_auc_95: 0.8936\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.1081 - auc_95: 0.9641 - val_loss: 0.1201 - val_auc_95: 0.8948\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1059 - auc_95: 0.9671 - val_loss: 0.1279 - val_auc_95: 0.8925\n",
      "Epoch 35/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1027 - auc_95: 0.9676 - val_loss: 0.1290 - val_auc_95: 0.8917\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1009 - auc_95: 0.9670 - val_loss: 0.1390 - val_auc_95: 0.8942\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1004 - auc_95: 0.9651 - val_loss: 0.1209 - val_auc_95: 0.8932\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0961 - auc_95: 0.9694 - val_loss: 0.1177 - val_auc_95: 0.8938\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0936 - auc_95: 0.9693 - val_loss: 0.1087 - val_auc_95: 0.8962\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0919 - auc_95: 0.9713 - val_loss: 0.1095 - val_auc_95: 0.8950\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0901 - auc_95: 0.9716 - val_loss: 0.1122 - val_auc_95: 0.8945\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0875 - auc_95: 0.9716 - val_loss: 0.1086 - val_auc_95: 0.8972\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0856 - auc_95: 0.9730 - val_loss: 0.1150 - val_auc_95: 0.8970\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0846 - auc_95: 0.9717 - val_loss: 0.1199 - val_auc_95: 0.8954\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0822 - auc_95: 0.9742 - val_loss: 0.1210 - val_auc_95: 0.8949\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0804 - auc_95: 0.9729 - val_loss: 0.0896 - val_auc_95: 0.9004\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0871 - auc_95: 0.9749 - val_loss: 0.1050 - val_auc_95: 0.8957\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0781 - auc_95: 0.9744 - val_loss: 0.1229 - val_auc_95: 0.8931\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0764 - auc_95: 0.9738 - val_loss: 0.0967 - val_auc_95: 0.8983\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0742 - auc_95: 0.9764 - val_loss: 0.1180 - val_auc_95: 0.8958\n",
      "Epoch 51/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0752 - auc_95: 0.9728 - val_loss: 0.1043 - val_auc_95: 0.8970\n",
      "Epoch 52/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0713 - auc_95: 0.9764 - val_loss: 0.0927 - val_auc_95: 0.8994\n",
      "Epoch 53/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0705 - auc_95: 0.9773 - val_loss: 0.0985 - val_auc_95: 0.8972\n",
      "Epoch 54/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0685 - auc_95: 0.9771 - val_loss: 0.1052 - val_auc_95: 0.8962\n",
      "Epoch 55/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0672 - auc_95: 0.9771 - val_loss: 0.0946 - val_auc_95: 0.8987\n",
      "Epoch 56/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0661 - auc_95: 0.9770 - val_loss: 0.0953 - val_auc_95: 0.8983\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 2s 24ms/step - loss: 0.6143 - auc_96: 0.5775 - val_loss: 0.4543 - val_auc_96: 0.6639\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.4682 - auc_96: 0.7231 - val_loss: 0.3880 - val_auc_96: 0.7499\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3763 - auc_96: 0.7946 - val_loss: 0.3296 - val_auc_96: 0.7923\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3251 - auc_96: 0.8439 - val_loss: 0.2542 - val_auc_96: 0.8283\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2956 - auc_96: 0.8705 - val_loss: 0.2396 - val_auc_96: 0.8406\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2719 - auc_96: 0.8829 - val_loss: 0.2531 - val_auc_96: 0.8401\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2541 - auc_96: 0.8916 - val_loss: 0.2505 - val_auc_96: 0.8450\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2405 - auc_96: 0.8979 - val_loss: 0.2372 - val_auc_96: 0.8529\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2299 - auc_96: 0.9083 - val_loss: 0.2113 - val_auc_96: 0.8625\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2212 - auc_96: 0.9160 - val_loss: 0.2209 - val_auc_96: 0.8614\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2115 - auc_96: 0.9174 - val_loss: 0.2264 - val_auc_96: 0.8625\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2058 - auc_96: 0.9223 - val_loss: 0.2154 - val_auc_96: 0.8584\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1991 - auc_96: 0.9237 - val_loss: 0.1945 - val_auc_96: 0.8680\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1933 - auc_96: 0.9272 - val_loss: 0.2093 - val_auc_96: 0.8644\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1873 - auc_96: 0.9290 - val_loss: 0.2004 - val_auc_96: 0.8696\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1831 - auc_96: 0.9316 - val_loss: 0.1938 - val_auc_96: 0.8677\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1774 - auc_96: 0.9314 - val_loss: 0.1918 - val_auc_96: 0.8687\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1726 - auc_96: 0.9369 - val_loss: 0.1964 - val_auc_96: 0.8681\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1695 - auc_96: 0.9415 - val_loss: 0.1694 - val_auc_96: 0.8765\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1672 - auc_96: 0.9418 - val_loss: 0.1786 - val_auc_96: 0.8717\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1606 - auc_96: 0.9410 - val_loss: 0.1733 - val_auc_96: 0.8766\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1562 - auc_96: 0.9442 - val_loss: 0.1821 - val_auc_96: 0.8750\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1527 - auc_96: 0.9445 - val_loss: 0.1793 - val_auc_96: 0.8773\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1488 - auc_96: 0.9482 - val_loss: 0.1689 - val_auc_96: 0.8772\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1455 - auc_96: 0.9482 - val_loss: 0.1752 - val_auc_96: 0.8756\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1419 - auc_96: 0.9503 - val_loss: 0.1724 - val_auc_96: 0.8763\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1383 - auc_96: 0.9519 - val_loss: 0.1739 - val_auc_96: 0.8594\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1350 - auc_96: 0.9525 - val_loss: 0.1529 - val_auc_96: 0.8652\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1336 - auc_96: 0.9570 - val_loss: 0.1659 - val_auc_96: 0.8609\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1296 - auc_96: 0.9535 - val_loss: 0.1578 - val_auc_96: 0.8632\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1259 - auc_96: 0.9563 - val_loss: 0.1619 - val_auc_96: 0.8628\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1231 - auc_96: 0.9560 - val_loss: 0.1763 - val_auc_96: 0.8586\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1226 - auc_96: 0.9545 - val_loss: 0.1548 - val_auc_96: 0.8615\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1178 - auc_96: 0.9575 - val_loss: 0.1446 - val_auc_96: 0.8635\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1155 - auc_96: 0.9608 - val_loss: 0.1367 - val_auc_96: 0.8663\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1127 - auc_96: 0.9615 - val_loss: 0.1457 - val_auc_96: 0.8651\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1106 - auc_96: 0.9637 - val_loss: 0.1458 - val_auc_96: 0.8665\n",
      "Epoch 38/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1076 - auc_96: 0.9633 - val_loss: 0.1314 - val_auc_96: 0.8653\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1063 - auc_96: 0.9652 - val_loss: 0.1561 - val_auc_96: 0.8620\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1044 - auc_96: 0.9642 - val_loss: 0.1365 - val_auc_96: 0.8657\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1015 - auc_96: 0.9670 - val_loss: 0.1322 - val_auc_96: 0.8673\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1002 - auc_96: 0.9642 - val_loss: 0.1245 - val_auc_96: 0.8690\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1009 - auc_96: 0.9680 - val_loss: 0.1200 - val_auc_96: 0.8498\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1050 - auc_96: 0.9673 - val_loss: 0.1244 - val_auc_96: 0.8521\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0958 - auc_96: 0.9678 - val_loss: 0.1320 - val_auc_96: 0.8514\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0936 - auc_96: 0.9670 - val_loss: 0.1227 - val_auc_96: 0.8344\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0915 - auc_96: 0.9695 - val_loss: 0.1465 - val_auc_96: 0.8485\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0910 - auc_96: 0.9685 - val_loss: 0.1415 - val_auc_96: 0.8505\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0900 - auc_96: 0.9682 - val_loss: 0.1465 - val_auc_96: 0.8500\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0888 - auc_96: 0.9690 - val_loss: 0.1324 - val_auc_96: 0.8353\n",
      "Epoch 51/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0863 - auc_96: 0.9698 - val_loss: 0.1165 - val_auc_96: 0.8365\n",
      "Epoch 52/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0857 - auc_96: 0.9710 - val_loss: 0.1206 - val_auc_96: 0.8363\n",
      "Epoch 53/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0837 - auc_96: 0.9712 - val_loss: 0.1230 - val_auc_96: 0.8374\n",
      "Epoch 54/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0830 - auc_96: 0.9720 - val_loss: 0.1370 - val_auc_96: 0.8361\n",
      "Epoch 55/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0818 - auc_96: 0.9712 - val_loss: 0.1302 - val_auc_96: 0.8379\n",
      "Epoch 56/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0806 - auc_96: 0.9730 - val_loss: 0.1226 - val_auc_96: 0.8368\n",
      "Epoch 57/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0793 - auc_96: 0.9723 - val_loss: 0.1276 - val_auc_96: 0.8389\n",
      "Epoch 58/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0779 - auc_96: 0.9738 - val_loss: 0.1140 - val_auc_96: 0.8407\n",
      "Epoch 59/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0773 - auc_96: 0.9745 - val_loss: 0.1242 - val_auc_96: 0.8390\n",
      "Epoch 60/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0758 - auc_96: 0.9733 - val_loss: 0.1230 - val_auc_96: 0.8389\n",
      "Epoch 61/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0750 - auc_96: 0.9735 - val_loss: 0.1097 - val_auc_96: 0.8425\n",
      "Epoch 62/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0736 - auc_96: 0.9755 - val_loss: 0.1153 - val_auc_96: 0.8416\n",
      "Epoch 63/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0731 - auc_96: 0.9745 - val_loss: 0.1232 - val_auc_96: 0.8395\n",
      "Epoch 64/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0726 - auc_96: 0.9750 - val_loss: 0.1084 - val_auc_96: 0.8443\n",
      "Epoch 65/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0706 - auc_96: 0.9762 - val_loss: 0.1152 - val_auc_96: 0.8425\n",
      "Epoch 66/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0696 - auc_96: 0.9757 - val_loss: 0.1106 - val_auc_96: 0.8437\n",
      "Epoch 67/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0686 - auc_96: 0.9767 - val_loss: 0.1102 - val_auc_96: 0.8439\n",
      "Epoch 68/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0676 - auc_96: 0.9765 - val_loss: 0.1090 - val_auc_96: 0.8448\n",
      "Epoch 69/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0665 - auc_96: 0.9777 - val_loss: 0.1128 - val_auc_96: 0.8439\n",
      "Epoch 70/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0657 - auc_96: 0.9772 - val_loss: 0.1009 - val_auc_96: 0.8457\n",
      "Epoch 71/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0713 - auc_96: 0.9772 - val_loss: 0.0926 - val_auc_96: 0.8461\n",
      "Epoch 72/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0649 - auc_96: 0.9782 - val_loss: 0.1008 - val_auc_96: 0.8468\n",
      "Epoch 73/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0632 - auc_96: 0.9785 - val_loss: 0.0973 - val_auc_96: 0.8473\n",
      "Epoch 74/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0626 - auc_96: 0.9785 - val_loss: 0.0981 - val_auc_96: 0.8465\n",
      "Epoch 75/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0611 - auc_96: 0.9795 - val_loss: 0.1253 - val_auc_96: 0.8422\n",
      "Epoch 76/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0610 - auc_96: 0.9790 - val_loss: 0.1014 - val_auc_96: 0.8476\n",
      "Epoch 77/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0634 - auc_96: 0.9802 - val_loss: 0.1018 - val_auc_96: 0.8493\n",
      "Epoch 78/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0593 - auc_96: 0.9792 - val_loss: 0.1016 - val_auc_96: 0.8469\n",
      "Epoch 79/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0584 - auc_96: 0.9797 - val_loss: 0.0976 - val_auc_96: 0.8476\n",
      "Epoch 80/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0581 - auc_96: 0.9800 - val_loss: 0.1047 - val_auc_96: 0.8477\n",
      "Epoch 81/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0564 - auc_96: 0.9800 - val_loss: 0.1044 - val_auc_96: 0.8479\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.5847 - auc_97: 0.5622 - val_loss: 0.4594 - val_auc_97: 0.6607\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.4292 - auc_97: 0.7577 - val_loss: 0.3574 - val_auc_97: 0.7611\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3528 - auc_97: 0.8224 - val_loss: 0.3202 - val_auc_97: 0.7981\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3101 - auc_97: 0.8534 - val_loss: 0.2820 - val_auc_97: 0.8167\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2811 - auc_97: 0.8770 - val_loss: 0.2901 - val_auc_97: 0.8205\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2605 - auc_97: 0.8861 - val_loss: 0.2356 - val_auc_97: 0.8385\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2449 - auc_97: 0.9004 - val_loss: 0.2549 - val_auc_97: 0.8279\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2326 - auc_97: 0.9010 - val_loss: 0.2379 - val_auc_97: 0.8356\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2219 - auc_97: 0.9102 - val_loss: 0.2064 - val_auc_97: 0.8471\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2119 - auc_97: 0.9169 - val_loss: 0.2143 - val_auc_97: 0.8467\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2060 - auc_97: 0.9163 - val_loss: 0.2185 - val_auc_97: 0.8450\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1971 - auc_97: 0.9260 - val_loss: 0.2399 - val_auc_97: 0.8415\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1915 - auc_97: 0.9247 - val_loss: 0.1852 - val_auc_97: 0.8624\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1876 - auc_97: 0.9309 - val_loss: 0.1907 - val_auc_97: 0.8624\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1799 - auc_97: 0.9321 - val_loss: 0.2085 - val_auc_97: 0.8570\n",
      "Epoch 16/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1752 - auc_97: 0.9342 - val_loss: 0.1918 - val_auc_97: 0.8587\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1700 - auc_97: 0.9373 - val_loss: 0.1817 - val_auc_97: 0.8631\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1653 - auc_97: 0.9403 - val_loss: 0.2028 - val_auc_97: 0.8573\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1596 - auc_97: 0.9427 - val_loss: 0.2091 - val_auc_97: 0.8560\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1602 - auc_97: 0.9351 - val_loss: 0.1750 - val_auc_97: 0.8669\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1517 - auc_97: 0.9451 - val_loss: 0.1936 - val_auc_97: 0.8615\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1485 - auc_97: 0.9467 - val_loss: 0.1811 - val_auc_97: 0.8497\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1461 - auc_97: 0.9486 - val_loss: 0.1800 - val_auc_97: 0.8493\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1414 - auc_97: 0.9499 - val_loss: 0.1714 - val_auc_97: 0.8512\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1377 - auc_97: 0.9520 - val_loss: 0.1613 - val_auc_97: 0.8533\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1345 - auc_97: 0.9533 - val_loss: 0.1764 - val_auc_97: 0.8487\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1323 - auc_97: 0.9542 - val_loss: 0.1691 - val_auc_97: 0.8528\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1300 - auc_97: 0.9537 - val_loss: 0.1651 - val_auc_97: 0.8527\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1271 - auc_97: 0.9585 - val_loss: 0.1557 - val_auc_97: 0.8526\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1250 - auc_97: 0.9560 - val_loss: 0.1579 - val_auc_97: 0.8526\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1230 - auc_97: 0.9563 - val_loss: 0.1685 - val_auc_97: 0.8512\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1212 - auc_97: 0.9578 - val_loss: 0.1673 - val_auc_97: 0.8515\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1176 - auc_97: 0.9597 - val_loss: 0.1539 - val_auc_97: 0.8555\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1152 - auc_97: 0.9610 - val_loss: 0.1451 - val_auc_97: 0.8409\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1132 - auc_97: 0.9622 - val_loss: 0.1529 - val_auc_97: 0.8574\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1111 - auc_97: 0.9622 - val_loss: 0.1317 - val_auc_97: 0.8450\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1095 - auc_97: 0.9638 - val_loss: 0.1418 - val_auc_97: 0.8438\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1080 - auc_97: 0.9630 - val_loss: 0.1487 - val_auc_97: 0.8411\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1053 - auc_97: 0.9652 - val_loss: 0.1383 - val_auc_97: 0.8453\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1034 - auc_97: 0.9660 - val_loss: 0.1485 - val_auc_97: 0.8423\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1019 - auc_97: 0.9653 - val_loss: 0.1328 - val_auc_97: 0.8463\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1001 - auc_97: 0.9667 - val_loss: 0.1251 - val_auc_97: 0.8486\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0991 - auc_97: 0.9662 - val_loss: 0.1459 - val_auc_97: 0.8449\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0968 - auc_97: 0.9680 - val_loss: 0.1366 - val_auc_97: 0.8447\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0950 - auc_97: 0.9687 - val_loss: 0.1442 - val_auc_97: 0.8448\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0935 - auc_97: 0.9680 - val_loss: 0.1284 - val_auc_97: 0.8498\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0920 - auc_97: 0.9692 - val_loss: 0.1254 - val_auc_97: 0.8515\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0907 - auc_97: 0.9693 - val_loss: 0.1394 - val_auc_97: 0.8466\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0889 - auc_97: 0.9697 - val_loss: 0.1324 - val_auc_97: 0.8500\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0882 - auc_97: 0.9697 - val_loss: 0.1209 - val_auc_97: 0.8352\n",
      "Epoch 51/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0867 - auc_97: 0.9712 - val_loss: 0.1450 - val_auc_97: 0.8459\n",
      "Epoch 52/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0855 - auc_97: 0.9703 - val_loss: 0.1266 - val_auc_97: 0.8535\n",
      "Epoch 53/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0831 - auc_97: 0.9728 - val_loss: 0.1383 - val_auc_97: 0.8506\n",
      "Epoch 54/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0827 - auc_97: 0.9715 - val_loss: 0.1296 - val_auc_97: 0.8539\n",
      "Epoch 55/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0807 - auc_97: 0.9728 - val_loss: 0.1258 - val_auc_97: 0.8551\n",
      "Epoch 56/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0796 - auc_97: 0.9730 - val_loss: 0.1192 - val_auc_97: 0.8183\n",
      "Epoch 57/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0786 - auc_97: 0.9735 - val_loss: 0.1184 - val_auc_97: 0.8189\n",
      "Epoch 58/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0772 - auc_97: 0.9733 - val_loss: 0.1184 - val_auc_97: 0.8173\n",
      "Epoch 59/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0758 - auc_97: 0.9752 - val_loss: 0.1157 - val_auc_97: 0.8178\n",
      "Epoch 60/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0745 - auc_97: 0.9745 - val_loss: 0.1209 - val_auc_97: 0.8172\n",
      "Epoch 61/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0736 - auc_97: 0.9740 - val_loss: 0.1012 - val_auc_97: 0.8222\n",
      "Epoch 62/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0730 - auc_97: 0.9767 - val_loss: 0.1119 - val_auc_97: 0.8199\n",
      "Epoch 63/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0713 - auc_97: 0.9758 - val_loss: 0.1186 - val_auc_97: 0.8180\n",
      "Epoch 64/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0701 - auc_97: 0.9757 - val_loss: 0.1120 - val_auc_97: 0.8200\n",
      "Epoch 65/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0693 - auc_97: 0.9763 - val_loss: 0.1003 - val_auc_97: 0.8231\n",
      "Epoch 66/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0683 - auc_97: 0.9787 - val_loss: 0.1114 - val_auc_97: 0.8208\n",
      "Epoch 67/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0667 - auc_97: 0.9775 - val_loss: 0.1106 - val_auc_97: 0.8216\n",
      "Epoch 68/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0657 - auc_97: 0.9775 - val_loss: 0.1093 - val_auc_97: 0.8228\n",
      "Epoch 69/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0651 - auc_97: 0.9780 - val_loss: 0.1185 - val_auc_97: 0.8193\n",
      "Epoch 70/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0662 - auc_97: 0.9765 - val_loss: 0.1048 - val_auc_97: 0.8230\n",
      "Epoch 71/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0631 - auc_97: 0.9788 - val_loss: 0.1054 - val_auc_97: 0.8231\n",
      "Epoch 72/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0620 - auc_97: 0.9780 - val_loss: 0.1184 - val_auc_97: 0.8209\n",
      "Epoch 73/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0623 - auc_97: 0.9775 - val_loss: 0.1088 - val_auc_97: 0.8225\n",
      "Epoch 74/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0603 - auc_97: 0.9802 - val_loss: 0.1049 - val_auc_97: 0.8238\n",
      "Epoch 75/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0592 - auc_97: 0.9795 - val_loss: 0.1017 - val_auc_97: 0.8245\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.6387 - auc_98: 0.5430 - val_loss: 0.4676 - val_auc_98: 0.6010\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.4703 - auc_98: 0.7341 - val_loss: 0.3868 - val_auc_98: 0.7103\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3801 - auc_98: 0.8089 - val_loss: 0.3520 - val_auc_98: 0.7463\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3300 - auc_98: 0.8385 - val_loss: 0.3145 - val_auc_98: 0.7808\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2972 - auc_98: 0.8651 - val_loss: 0.2709 - val_auc_98: 0.8027\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2737 - auc_98: 0.8739 - val_loss: 0.2790 - val_auc_98: 0.8106\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2558 - auc_98: 0.8880 - val_loss: 0.2642 - val_auc_98: 0.8172\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2401 - auc_98: 0.8977 - val_loss: 0.2218 - val_auc_98: 0.8279\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2275 - auc_98: 0.9042 - val_loss: 0.2325 - val_auc_98: 0.8265\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2157 - auc_98: 0.9110 - val_loss: 0.2352 - val_auc_98: 0.8303\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2074 - auc_98: 0.9129 - val_loss: 0.2173 - val_auc_98: 0.8389\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1983 - auc_98: 0.9224 - val_loss: 0.2028 - val_auc_98: 0.8454\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1911 - auc_98: 0.9280 - val_loss: 0.2056 - val_auc_98: 0.8477\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1854 - auc_98: 0.9287 - val_loss: 0.2100 - val_auc_98: 0.8476\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1793 - auc_98: 0.9351 - val_loss: 0.1794 - val_auc_98: 0.8611\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1731 - auc_98: 0.9351 - val_loss: 0.1883 - val_auc_98: 0.8577\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1679 - auc_98: 0.9398 - val_loss: 0.2200 - val_auc_98: 0.8481\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1637 - auc_98: 0.9382 - val_loss: 0.1967 - val_auc_98: 0.8439\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1578 - auc_98: 0.9418 - val_loss: 0.1739 - val_auc_98: 0.8521\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1537 - auc_98: 0.9438 - val_loss: 0.1825 - val_auc_98: 0.8501\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1496 - auc_98: 0.9456 - val_loss: 0.1600 - val_auc_98: 0.8545\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1463 - auc_98: 0.9498 - val_loss: 0.1751 - val_auc_98: 0.8529\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1436 - auc_98: 0.9473 - val_loss: 0.1680 - val_auc_98: 0.8535\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1382 - auc_98: 0.9508 - val_loss: 0.1683 - val_auc_98: 0.8554\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1346 - auc_98: 0.9510 - val_loss: 0.1665 - val_auc_98: 0.8560\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1316 - auc_98: 0.9535 - val_loss: 0.1797 - val_auc_98: 0.8523\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1299 - auc_98: 0.9517 - val_loss: 0.1596 - val_auc_98: 0.8432\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1256 - auc_98: 0.9557 - val_loss: 0.1694 - val_auc_98: 0.8578\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1232 - auc_98: 0.9552 - val_loss: 0.1595 - val_auc_98: 0.8443\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1204 - auc_98: 0.9585 - val_loss: 0.1723 - val_auc_98: 0.8580\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1183 - auc_98: 0.9575 - val_loss: 0.1593 - val_auc_98: 0.8446\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1154 - auc_98: 0.9607 - val_loss: 0.1574 - val_auc_98: 0.8456\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1129 - auc_98: 0.9603 - val_loss: 0.1378 - val_auc_98: 0.8499\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1125 - auc_98: 0.9628 - val_loss: 0.1397 - val_auc_98: 0.8508\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1089 - auc_98: 0.9625 - val_loss: 0.1434 - val_auc_98: 0.8506\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1083 - auc_98: 0.9613 - val_loss: 0.1495 - val_auc_98: 0.8473\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1047 - auc_98: 0.9637 - val_loss: 0.1376 - val_auc_98: 0.8508\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1028 - auc_98: 0.9650 - val_loss: 0.1211 - val_auc_98: 0.8553\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1018 - auc_98: 0.9662 - val_loss: 0.1407 - val_auc_98: 0.8489\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0991 - auc_98: 0.9658 - val_loss: 0.1473 - val_auc_98: 0.8489\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1024 - auc_98: 0.9648 - val_loss: 0.1459 - val_auc_98: 0.8476\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0985 - auc_98: 0.9665 - val_loss: 0.1408 - val_auc_98: 0.8497\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0941 - auc_98: 0.9687 - val_loss: 0.1259 - val_auc_98: 0.8573\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0927 - auc_98: 0.9685 - val_loss: 0.1339 - val_auc_98: 0.8541\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0918 - auc_98: 0.9693 - val_loss: 0.1355 - val_auc_98: 0.8548\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0898 - auc_98: 0.9693 - val_loss: 0.1339 - val_auc_98: 0.8550\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0887 - auc_98: 0.9703 - val_loss: 0.1162 - val_auc_98: 0.8401\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0873 - auc_98: 0.9707 - val_loss: 0.1294 - val_auc_98: 0.8582\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0861 - auc_98: 0.9717 - val_loss: 0.1258 - val_auc_98: 0.8388\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0847 - auc_98: 0.9713 - val_loss: 0.1262 - val_auc_98: 0.8405\n",
      "Epoch 51/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0848 - auc_98: 0.9702 - val_loss: 0.1259 - val_auc_98: 0.8379\n",
      "Epoch 52/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0827 - auc_98: 0.9720 - val_loss: 0.1306 - val_auc_98: 0.8394\n",
      "Epoch 53/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0822 - auc_98: 0.9715 - val_loss: 0.1329 - val_auc_98: 0.8388\n",
      "Epoch 54/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0802 - auc_98: 0.9723 - val_loss: 0.1132 - val_auc_98: 0.8423\n",
      "Epoch 55/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0790 - auc_98: 0.9740 - val_loss: 0.1220 - val_auc_98: 0.8401\n",
      "Epoch 56/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0778 - auc_98: 0.9733 - val_loss: 0.1169 - val_auc_98: 0.8427\n",
      "Epoch 57/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0768 - auc_98: 0.9745 - val_loss: 0.1205 - val_auc_98: 0.8415\n",
      "Epoch 58/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0760 - auc_98: 0.9752 - val_loss: 0.1215 - val_auc_98: 0.8415\n",
      "Epoch 59/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0746 - auc_98: 0.9748 - val_loss: 0.1157 - val_auc_98: 0.8436\n",
      "Epoch 60/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0738 - auc_98: 0.9763 - val_loss: 0.1249 - val_auc_98: 0.8414\n",
      "Epoch 61/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0735 - auc_98: 0.9747 - val_loss: 0.1119 - val_auc_98: 0.8454\n",
      "Epoch 62/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0717 - auc_98: 0.9758 - val_loss: 0.1146 - val_auc_98: 0.8451\n",
      "Epoch 63/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0705 - auc_98: 0.9765 - val_loss: 0.1155 - val_auc_98: 0.8451\n",
      "Epoch 64/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0697 - auc_98: 0.9767 - val_loss: 0.1148 - val_auc_98: 0.8455\n",
      "Epoch 65/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0685 - auc_98: 0.9770 - val_loss: 0.1238 - val_auc_98: 0.8439\n",
      "Epoch 66/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0679 - auc_98: 0.9770 - val_loss: 0.1227 - val_auc_98: 0.8446\n",
      "Epoch 67/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0680 - auc_98: 0.9778 - val_loss: 0.1242 - val_auc_98: 0.8448\n",
      "Epoch 68/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0663 - auc_98: 0.9765 - val_loss: 0.1060 - val_auc_98: 0.8498\n",
      "Epoch 69/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0651 - auc_98: 0.9785 - val_loss: 0.1148 - val_auc_98: 0.8474\n",
      "Epoch 70/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0640 - auc_98: 0.9787 - val_loss: 0.1083 - val_auc_98: 0.8493\n",
      "Epoch 71/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0630 - auc_98: 0.9785 - val_loss: 0.1029 - val_auc_98: 0.8514\n",
      "Epoch 72/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0623 - auc_98: 0.9797 - val_loss: 0.1083 - val_auc_98: 0.8503\n",
      "Epoch 73/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0611 - auc_98: 0.9798 - val_loss: 0.1065 - val_auc_98: 0.8519\n",
      "Epoch 74/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0607 - auc_98: 0.9798 - val_loss: 0.1133 - val_auc_98: 0.8493\n",
      "Epoch 75/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0598 - auc_98: 0.9800 - val_loss: 0.1006 - val_auc_98: 0.8531\n",
      "Epoch 76/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0590 - auc_98: 0.9803 - val_loss: 0.1132 - val_auc_98: 0.8495\n",
      "Epoch 77/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0588 - auc_98: 0.9805 - val_loss: 0.1099 - val_auc_98: 0.8525\n",
      "Epoch 78/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0573 - auc_98: 0.9802 - val_loss: 0.1100 - val_auc_98: 0.8514\n",
      "Epoch 79/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0558 - auc_98: 0.9808 - val_loss: 0.0958 - val_auc_98: 0.8573\n",
      "Epoch 80/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0554 - auc_98: 0.9817 - val_loss: 0.1060 - val_auc_98: 0.8529\n",
      "Epoch 81/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0547 - auc_98: 0.9810 - val_loss: 0.1039 - val_auc_98: 0.8546\n",
      "Epoch 82/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0536 - auc_98: 0.9815 - val_loss: 0.1035 - val_auc_98: 0.8543\n",
      "Epoch 83/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0522 - auc_98: 0.9820 - val_loss: 0.0943 - val_auc_98: 0.8581\n",
      "Epoch 84/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0520 - auc_98: 0.9825 - val_loss: 0.0930 - val_auc_98: 0.8583\n",
      "Epoch 85/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0510 - auc_98: 0.9815 - val_loss: 0.0964 - val_auc_98: 0.8573\n",
      "Epoch 86/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0500 - auc_98: 0.9820 - val_loss: 0.0971 - val_auc_98: 0.8585\n",
      "Epoch 87/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0496 - auc_98: 0.9825 - val_loss: 0.0945 - val_auc_98: 0.8586\n",
      "Epoch 88/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0484 - auc_98: 0.9825 - val_loss: 0.1005 - val_auc_98: 0.8585\n",
      "Epoch 89/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0481 - auc_98: 0.9822 - val_loss: 0.0994 - val_auc_98: 0.8578\n",
      "Epoch 90/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0472 - auc_98: 0.9832 - val_loss: 0.1011 - val_auc_98: 0.8573\n",
      "Epoch 91/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0464 - auc_98: 0.9825 - val_loss: 0.0857 - val_auc_98: 0.8420\n",
      "Epoch 92/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0457 - auc_98: 0.9840 - val_loss: 0.0941 - val_auc_98: 0.8613\n",
      "Epoch 93/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0449 - auc_98: 0.9828 - val_loss: 0.0911 - val_auc_98: 0.8628\n",
      "Epoch 94/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0442 - auc_98: 0.9833 - val_loss: 0.0884 - val_auc_98: 0.8425\n",
      "Epoch 95/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0437 - auc_98: 0.9833 - val_loss: 0.0889 - val_auc_98: 0.8420\n",
      "Epoch 96/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0533 - auc_98: 0.9840 - val_loss: 0.0774 - val_auc_98: 0.8666\n",
      "Epoch 97/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0438 - auc_98: 0.9850 - val_loss: 0.0890 - val_auc_98: 0.8624\n",
      "Epoch 98/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0418 - auc_98: 0.9848 - val_loss: 0.0921 - val_auc_98: 0.8620\n",
      "Epoch 99/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0410 - auc_98: 0.9850 - val_loss: 0.0887 - val_auc_98: 0.8422\n",
      "Epoch 100/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0406 - auc_98: 0.9855 - val_loss: 0.0965 - val_auc_98: 0.8618\n",
      "Epoch 101/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0401 - auc_98: 0.9847 - val_loss: 0.0958 - val_auc_98: 0.8612\n",
      "Epoch 102/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0392 - auc_98: 0.9858 - val_loss: 0.0902 - val_auc_98: 0.8419\n",
      "Epoch 103/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0387 - auc_98: 0.9857 - val_loss: 0.0888 - val_auc_98: 0.8426\n",
      "Epoch 104/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0405 - auc_98: 0.9867 - val_loss: 0.0806 - val_auc_98: 0.8465\n",
      "Epoch 105/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0378 - auc_98: 0.9860 - val_loss: 0.0903 - val_auc_98: 0.8628\n",
      "Epoch 106/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0373 - auc_98: 0.9855 - val_loss: 0.0869 - val_auc_98: 0.8439\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.5920 - auc_99: 0.5623 - val_loss: 0.4463 - val_auc_99: 0.6882\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.4229 - auc_99: 0.7811 - val_loss: 0.3776 - val_auc_99: 0.7587\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3434 - auc_99: 0.8356 - val_loss: 0.3147 - val_auc_99: 0.7983\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2981 - auc_99: 0.8647 - val_loss: 0.2727 - val_auc_99: 0.8246\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2690 - auc_99: 0.8848 - val_loss: 0.2530 - val_auc_99: 0.8386\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2488 - auc_99: 0.8982 - val_loss: 0.2561 - val_auc_99: 0.8405\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2337 - auc_99: 0.9039 - val_loss: 0.2232 - val_auc_99: 0.8551\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2217 - auc_99: 0.9096 - val_loss: 0.2256 - val_auc_99: 0.8564\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2101 - auc_99: 0.9145 - val_loss: 0.2099 - val_auc_99: 0.8546\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1999 - auc_99: 0.9256 - val_loss: 0.2274 - val_auc_99: 0.8496\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1909 - auc_99: 0.9245 - val_loss: 0.2256 - val_auc_99: 0.8520\n",
      "Epoch 12/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1865 - auc_99: 0.9266 - val_loss: 0.2106 - val_auc_99: 0.8595\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1758 - auc_99: 0.9357 - val_loss: 0.1839 - val_auc_99: 0.8653\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1714 - auc_99: 0.9404 - val_loss: 0.2010 - val_auc_99: 0.8621\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1648 - auc_99: 0.9383 - val_loss: 0.1802 - val_auc_99: 0.8674\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1588 - auc_99: 0.9414 - val_loss: 0.2022 - val_auc_99: 0.8645\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1564 - auc_99: 0.9389 - val_loss: 0.1982 - val_auc_99: 0.8473\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1493 - auc_99: 0.9452 - val_loss: 0.1738 - val_auc_99: 0.8554\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1438 - auc_99: 0.9485 - val_loss: 0.1788 - val_auc_99: 0.8547\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1396 - auc_99: 0.9503 - val_loss: 0.1463 - val_auc_99: 0.8646\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1393 - auc_99: 0.9537 - val_loss: 0.1659 - val_auc_99: 0.8561\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1322 - auc_99: 0.9514 - val_loss: 0.1499 - val_auc_99: 0.8610\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.1283 - auc_99: 0.9555 - val_loss: 0.1593 - val_auc_99: 0.8592\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1250 - auc_99: 0.9573 - val_loss: 0.1534 - val_auc_99: 0.8624\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1218 - auc_99: 0.9572 - val_loss: 0.1648 - val_auc_99: 0.8589\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1186 - auc_99: 0.9580 - val_loss: 0.1669 - val_auc_99: 0.8584\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1151 - auc_99: 0.9595 - val_loss: 0.1507 - val_auc_99: 0.8652\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1124 - auc_99: 0.9622 - val_loss: 0.1601 - val_auc_99: 0.8630\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1096 - auc_99: 0.9622 - val_loss: 0.1509 - val_auc_99: 0.8656\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.1108 - auc_99: 0.9607 - val_loss: 0.1495 - val_auc_99: 0.8672\n",
      "Epoch 1/300\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.5882 - auc_100: 0.5743 - val_loss: 0.4568 - val_auc_100: 0.6916\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.4312 - auc_100: 0.7564 - val_loss: 0.3734 - val_auc_100: 0.7444\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3559 - auc_100: 0.8175 - val_loss: 0.3375 - val_auc_100: 0.7794\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3112 - auc_100: 0.8512 - val_loss: 0.3095 - val_auc_100: 0.8008\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2811 - auc_100: 0.8743 - val_loss: 0.2842 - val_auc_100: 0.8165\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2602 - auc_100: 0.8865 - val_loss: 0.2552 - val_auc_100: 0.8318\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2436 - auc_100: 0.8971 - val_loss: 0.2490 - val_auc_100: 0.8375\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2363 - auc_100: 0.8941 - val_loss: 0.2561 - val_auc_100: 0.8368\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2275 - auc_100: 0.9004 - val_loss: 0.2486 - val_auc_100: 0.8376\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2179 - auc_100: 0.9105 - val_loss: 0.2387 - val_auc_100: 0.8347\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2114 - auc_100: 0.9144 - val_loss: 0.2142 - val_auc_100: 0.8448\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2062 - auc_100: 0.9188 - val_loss: 0.2091 - val_auc_100: 0.8479\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2005 - auc_100: 0.9225 - val_loss: 0.2178 - val_auc_100: 0.8470\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1955 - auc_100: 0.9242 - val_loss: 0.2034 - val_auc_100: 0.8544\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1906 - auc_100: 0.9273 - val_loss: 0.2021 - val_auc_100: 0.8557\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1863 - auc_100: 0.9307 - val_loss: 0.2016 - val_auc_100: 0.8546\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1821 - auc_100: 0.9318 - val_loss: 0.2065 - val_auc_100: 0.8546\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.1789 - auc_100: 0.9323 - val_loss: 0.1796 - val_auc_100: 0.8595\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1808 - auc_100: 0.9391 - val_loss: 0.1995 - val_auc_100: 0.8546\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1721 - auc_100: 0.9385 - val_loss: 0.1785 - val_auc_100: 0.8603\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1721 - auc_100: 0.9395 - val_loss: 0.1783 - val_auc_100: 0.8611\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1660 - auc_100: 0.9405 - val_loss: 0.1927 - val_auc_100: 0.8593\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1630 - auc_100: 0.9421 - val_loss: 0.1781 - val_auc_100: 0.8475\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1631 - auc_100: 0.9425 - val_loss: 0.1667 - val_auc_100: 0.8513\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1637 - auc_100: 0.9446 - val_loss: 0.1857 - val_auc_100: 0.8463\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1558 - auc_100: 0.9432 - val_loss: 0.1742 - val_auc_100: 0.8485\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1528 - auc_100: 0.9445 - val_loss: 0.1716 - val_auc_100: 0.8508\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1506 - auc_100: 0.9477 - val_loss: 0.2033 - val_auc_100: 0.8447\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1501 - auc_100: 0.9446 - val_loss: 0.1894 - val_auc_100: 0.8501\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1474 - auc_100: 0.9458 - val_loss: 0.1918 - val_auc_100: 0.8487\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.1441 - auc_100: 0.9482 - val_loss: 0.1866 - val_auc_100: 0.8480\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1415 - auc_100: 0.9503 - val_loss: 0.1956 - val_auc_100: 0.8489\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1397 - auc_100: 0.9497 - val_loss: 0.1815 - val_auc_100: 0.8528\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.1406 - auc_100: 0.9484 - val_loss: 0.1767 - val_auc_100: 0.8370\n"
     ]
    }
   ],
   "source": [
    "S = pd.DataFrame()\n",
    "for i in np.arange(20):\n",
    "    X_tra, X_val, y_tra, y_val = tts(X_tr, y_tr, \n",
    "                                    test_size = 0.25, \n",
    "                                    stratify = y_tr)\n",
    "    X_tra_pp = sampler.fit_resample(X_tra, y_tra)\n",
    "    transformer.fit(X_tra)\n",
    "    X_val_pp = transformer.transform(X_val)\n",
    "    val = (X_val_pp, y_val)\n",
    "    for j in np.arange(5):\n",
    "        net = create_net_sal()\n",
    "        net.fit(X_tra_pp[0], X_tra_pp[1], validation_data = val, \n",
    "                epochs = 300, verbose = 1, batch_size = 128,\n",
    "                callbacks = [callback])\n",
    "        ind = saliency(net).nlargest(20).index\n",
    "        S = S.append(pd.Series(ind), ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1b65610c",
   "metadata": {
    "id": "PyxSHWK0EJu0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V3 V40 V42 V43 V44 V45 V48 V17 V50 V55 V23 "
     ]
    }
   ],
   "source": [
    "vals = S.stack().value_counts() \n",
    "at70 = set(vals[vals >= 70].index.values)\n",
    "for i in at70:\n",
    "    print('V%d' % i, end = ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ef4f65ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr_pp = transformer.fit_transform(X_tr)\n",
    "r = abs(pd.DataFrame(X_tr_pp).corr()) >= 0.8\n",
    "G = []\n",
    "for i in np.arange(60):\n",
    "    k = set(r.iloc[:,i][r.iloc[:,i]].index.values)\n",
    "    if len(k.intersection(at70)) == 0 and len(k) > 1:\n",
    "        if not(k in G): G.append(k) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ff9cc67e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "G_inst = []\n",
    "for i in np.arange(len(G)):\n",
    "    temp = 0\n",
    "    for j in np.arange(S.shape[0]):\n",
    "        if len(set(S.iloc[j,:]).intersection(G[i])) != 0:\n",
    "            temp = temp+1\n",
    "    G_inst.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bccaaf72",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 2): 5,\n",
       " (10, 34, 14): 0,\n",
       " (11, 12): 4,\n",
       " (18, 38): 26,\n",
       " (20, 22): 22,\n",
       " (49, 29): 37,\n",
       " (33, 53): 14,\n",
       " (54, 10, 34, 14): 20,\n",
       " (18, 58, 38): 29,\n",
       " (34, 54): 20,\n",
       " (58, 38): 18}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc = dict(zip([tuple(i) for i in G], G_inst))\n",
    "dc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877820f8",
   "metadata": {},
   "source": [
    "## Conclusion \n",
    "In this project, I tried to concisely describe the process of working with real world data, creating a machine learning pipeline with various preprocessing steps and ultimately training and evaluating various ML models. My main aim was to create a bankruptcy model using a neural network, but other models were also trained and some of them even achieved better results than the neural network. Some concepts were described very shortly and some of them were not described at all; however this project is used mainly to demonstrate the coding part of a practical project; the mathematical and statistical concepts as well as the theory of feedforward neural networks are thoroughly described in my Master's thesis, which can be found on my github page (written in Slovak). "
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DPdata.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
